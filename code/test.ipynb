{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kks/anaconda3/envs/video_mamba/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, SequentialSampler, DataLoader\n",
    "from torchvision import transforms\n",
    "from decord import VideoReader, cpu\n",
    "from datasets.random_erasing import RandomErasing\n",
    "from datasets.video_transforms import (\n",
    "    Compose, Resize, CenterCrop, Normalize,\n",
    "    create_random_augment, random_short_side_scale_jitter, \n",
    "    random_crop, random_resized_crop_with_shift, random_resized_crop,\n",
    "    horizontal_flip, random_short_side_scale_jitter, uniform_crop, \n",
    ")\n",
    "from datasets.volume_transforms import ClipToTensor\n",
    "import utils\n",
    "\n",
    "class CondensedMovies(Dataset):\n",
    "    def __init__(\n",
    "        self, anno_path: str, data_path: str='', split: str=',', mode: str='train', clip_len: int=64,\n",
    "        frame_sample_rate: int=2, aug_size: tuple=(720, 1280), target_size: tuple=(480, 854), n_seg: int=1, n_crop: int=1,\n",
    "        test_n_seg: int=10, test_n_crop: int=3, min_duration=60, trimmed: int=180, time_stride: int=60\n",
    "    ):\n",
    "        self.anno_path = anno_path # meta data(duration.csv) path\n",
    "        self.data_path = data_path # video path\n",
    "        self.split = split # seperator in csv\n",
    "        self.mode = mode\n",
    "        self.clip_len = clip_len # kernel size in frame axis\n",
    "        self.frame_sample_rate = frame_sample_rate\n",
    "        self.aug_size = aug_size # Augementation size\n",
    "        self.target_size = target_size # Video size\n",
    "        self.n_seg = n_seg # 학습 시 비디오를 시간 축으로 몇 개의 segment로 나눌 것인지\n",
    "        self.n_crop = n_crop # 각 segment에서 공간적으로 몇 개를 crop할 것인지\n",
    "        self.test_n_seg = test_n_seg\n",
    "        self.test_n_crop = test_n_crop\n",
    "        self.trimmed = trimmed # 사용할 비디오 길이\n",
    "        self.time_stride = time_stride\n",
    "        self.aug = False # 데이터 증강 여부\n",
    "\n",
    "        assert n_seg == 1\n",
    "\n",
    "        # 학습 과정시\n",
    "        if self.mode == 'train':\n",
    "            self.aug = True # 데이터 증강 사용\n",
    "            self.rand_erase = True # random erasing 사용\n",
    "        \n",
    "        import pandas as pd\n",
    "        import ast\n",
    "\n",
    "        df = pd.read_csv(self.anno_path, delimiter=self.split)\n",
    "        df.iloc[:, 1] = df.iloc[:, 1].apply(ast.literal_eval)\n",
    "\n",
    "        self.ori_ids = list(df.iloc[:, 0])\n",
    "        self.ori_labels = list(df.iloc[:, 1])\n",
    "        self.ori_durations = list(df.iloc[:, 2])\n",
    "\n",
    "        self.ids = []\n",
    "        self.labels = []\n",
    "        self.starts = []\n",
    "        self.ends = []\n",
    "\n",
    "        # 비디오 길이 조절\n",
    "        for idx, duration in enumerate(self.ori_durations):\n",
    "            # 최소 min_duration 이상인 비디오만 사용\n",
    "            if duration < min_duration:\n",
    "                continue\n",
    "\n",
    "            if duration < trimmed:\n",
    "                self.ids.append(self.ori_ids[idx])\n",
    "                self.labels.append(self.ori_labels[idx])\n",
    "                self.starts.append(0)\n",
    "                self.ends.append(duration)\n",
    "            else:\n",
    "                # 너무 긴 경우, 비디오를 잘라서 사용\n",
    "                starts = [i for i in range(0, int(duration), time_stride)]\n",
    "\n",
    "                # trimmed보다 긴 경우, time_stride 간격으로 비디오를 자름\n",
    "                for start in starts:\n",
    "                    end = start + trimmed\n",
    "                    # 계산된 종료 시각이 실제 비디오 running time보다 길 경우\n",
    "                    if end > duration:\n",
    "                        if duration - start >= trimmed / 2: # 남은 비디오의 시간이 trimmed의 절반 이상인 경우\n",
    "                            end = duration\n",
    "                        else: # 그렇지 않으면 사용하지 않음\n",
    "                            continue\n",
    "                    \n",
    "                    self.ids.append(self.ori_ids[idx])\n",
    "                    self.labels.append(self.ori_labels[idx])\n",
    "                    self.starts.append(start)\n",
    "                    self.ends.append(end)\n",
    "        \n",
    "        # 개수가 많은 학습용 데이터만 제외해 전처리\n",
    "        if mode == 'train':\n",
    "            pass\n",
    "\n",
    "        elif mode == 'validation':\n",
    "            self.data_transform = Compose([\n",
    "                Resize(self.aug_size, interpolation='bilinear'),\n",
    "                CenterCrop(size=target_size),\n",
    "                ClipToTensor(),\n",
    "                Normalize(mean=[.485, .456, .406], std=[.229, .224, .225]) # ImageNet\n",
    "            ])\n",
    "        elif mode == 'test':\n",
    "            self.data_resize = Compose([\n",
    "                Resize(self.target_size, interpolation='bilinear')\n",
    "            ])\n",
    "            self.data_transform = Compose([\n",
    "                ClipToTensor(),\n",
    "                Normalize(mean=[.485, .456, .406], std=[.229, .224, .225]) # ImageNet\n",
    "            ])\n",
    "\n",
    "            self.test_seg = []\n",
    "            self.test_ids = []\n",
    "            self.test_labels = []\n",
    "            self.test_starts = []\n",
    "            self.test_ends = []\n",
    "            # TTA(Test Time Arguementation)\n",
    "            for ck in range(self.test_n_seg):\n",
    "                for cp in range(self.test_n_crop):\n",
    "                    for idx in range(len(self.labels)):\n",
    "                        self.test_ids.append(self.ids[idx])\n",
    "                        self.test_labels.append(self.labels[idx])\n",
    "                        self.test_starts.append(self.starts[idx])\n",
    "                        self.test_ends.append(self.ends[idx])\n",
    "                        self.test_seg.append((ck, cp))\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        if self.mode == 'train':\n",
    "            # Video informations\n",
    "            id = self.ids[idx]\n",
    "            start = self.starts[idx]\n",
    "            end = self.ends[idx]\n",
    "            buffer = self.loadvideo_decord(id, start, end, chunk_nb=-1) # (T, H, W, C) ndarray\n",
    "            if len(buffer) == 0:\n",
    "                while len(buffer) == 0:\n",
    "                    warnings.warn(\"video {} not correctly loaded during training\".format(id))\n",
    "                    index = np.random.randint(self.__len__())\n",
    "                    id = self.ids[index]\n",
    "                    start = self.starts[index]\n",
    "                    end = self.ends[index]\n",
    "                    buffer = self.loadvideo_decord(id, start, end, chunk_nb=-1)\n",
    "\n",
    "            # 증강 여부\n",
    "            frames = []\n",
    "            labels = []\n",
    "            indices = []\n",
    "            # 데이터 증강\n",
    "            for _ in range(2):\n",
    "                new_frames = self._aug_frame(buffer) # (C, T, H, W)\n",
    "                frames.append(new_frames)\n",
    "                labels.append(self.labels[idx])\n",
    "                indices.append(idx)\n",
    "            \n",
    "            return frames, torch.tensor(labels, dtype=torch.int32), indices, {}\n",
    "        \n",
    "        elif self.mode == 'validation':\n",
    "            id = self.ids[idx]\n",
    "            start = self.starts[idx]\n",
    "            end = self.ends[idx]\n",
    "            buffer = self.loadvideo_decord(id, start, end, chunk_nb=0)\n",
    "            if len(buffer) == 0:\n",
    "                while len(buffer) == 0:\n",
    "                    warnings.warn(\"video {} not correctly loaded during training\".format(id))\n",
    "                    index = np.random.randint(self.__len__())\n",
    "                    id = self.ids[index]\n",
    "                    start = self.starts[index]\n",
    "                    end = self.ends[index]\n",
    "                    buffer = self.loadvideo_decord(id, start, end, chunk_nb=0)\n",
    "\n",
    "            # 입력을 위한 transform\n",
    "            buffer = self.data_transform(buffer) # Resize, CenterCrop, ClipToTensor, Normalize\n",
    "\n",
    "            return buffer, torch.tensor(self.labels[idx], dtype=torch.int32), id\n",
    "        \n",
    "        elif self.mode == 'test':\n",
    "            id = self.test_ids[idx]\n",
    "            start = self.test_ids[idx]\n",
    "            end = self.test_ids[idx]\n",
    "            chunk_nb, split_nb = self.test_seg[idx]\n",
    "            buffer = self.loadvideo_decord(id, start, end, chunk_nb=chunk_nb)\n",
    "            \n",
    "            while len(buffer) == 0:\n",
    "                warnings.warn(\"video {}, temporal {}, spatial {} not found during testing\".format(\\\n",
    "                    str(self.test_ids[idx]), chunk_nb, split_nb))\n",
    "                idx = np.random.randint(self.__len__())\n",
    "                sample = self.test_ids[idx]\n",
    "                start = self.test_starts[idx]\n",
    "                end = self.test_ends[idx]\n",
    "                chunk_nb, split_nb = self.test_seg[idx]\n",
    "                buffer = self.loadvideo_decord(sample, start, end, chunk_nb=chunk_nb)\n",
    "\n",
    "            buffer = self.data_resize(buffer)\n",
    "            if isinstance(buffer, list): # 비디오를 불러오지 못한 경우\n",
    "                buffer = np.stack(buffer, 0)\n",
    "            if self.test_n_crop == 1:\n",
    "                spatial_step = int((max(buffer.shape[1], buffer.shape[2]) - self.target_size[0]) / 2) # 420 pixel\n",
    "                spatial_start = spatial_step\n",
    "            else:\n",
    "                spatial_step = int((max(buffer.shape[1], buffer.shape[2]) - self.target_size[0]) / (self.test_n_crop - 1))\n",
    "                spatial_start = spatial_step * split_nb \n",
    "            buffer = buffer[:, :, spatial_start:spatial_start + self.target_size[0], :] # Sampling\n",
    "            buffer = self.data_transform(buffer) # ClipToTensor, Normalize\n",
    "\n",
    "            return buffer, torch.tensor(self.test_labels[idx], dtype=torch.int32), self.test_ids[idx], chunk_nb, split_nb\n",
    "        \n",
    "    def _aug_frame(self, buffer):\n",
    "        \"\"\"\n",
    "        데이터 증강\n",
    "\n",
    "        buffer: Video tensor(T, H, W, C)\n",
    "        \"\"\"\n",
    "        aug_transform = create_random_augment(\n",
    "            input_size=self.aug_size,\n",
    "            auto_augment=\"rand-m5-n2-mstd0.25-inc1\",\n",
    "            interpolation='bicubic'\n",
    "        )\n",
    "        # 변환을 위해 Tensor -> Image\n",
    "        buffer = [transforms.ToPILImage()(frame) for frame in buffer] # (T, H, W, C)\n",
    "        buffer = aug_transform(buffer)\n",
    "\n",
    "        # 입력을 위해 Image -> Tensor\n",
    "        buffer = [transforms.ToTensor()(img) for img in buffer] # (T, C, H, W)\n",
    "        buffer = torch.stack(buffer) # (T, C, H, W)\n",
    "        # 정규화를 위해 shape 변형\n",
    "        buffer = buffer.permute(0, 2, 3, 1) # (T, H, W, C)\n",
    "        buffer = tensor_normalize(buffer, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        # spatial sampling을 위해 shape 변형\n",
    "        buffer = buffer.permute(3, 0, 1, 2) # (C, T, H, W)\n",
    "\n",
    "        scl, asp = (\n",
    "            [0.5, 1.0],\n",
    "            [0.75, 1.3333],\n",
    "        )\n",
    "\n",
    "        buffer = spatial_sampling(\n",
    "            frames=buffer, target_height=self.target_size[0], target_width=self.target_size[1],\n",
    "            random_horizontal_flip=True, scale=scl, aspect_ratio=asp\n",
    "        )\n",
    "        \n",
    "        if self.rand_erase:\n",
    "            random_erasing = RandomErasing(\n",
    "                .25, mode='pixel', max_count=1,\n",
    "                num_splits=1, device='cpu'\n",
    "            )\n",
    "            # random erasing을 위해 shape 변형\n",
    "            buffer = buffer.permute(1, 0, 2, 3) # (T, C, H, W)\n",
    "            buffer = random_erasing(buffer)\n",
    "            # 모델의 입력값으로 사용하기 위해 shape 변형\n",
    "            buffer = buffer.permute(1, 0, 2, 3) # (C, T, H, W)\n",
    "        \n",
    "        return buffer\n",
    "    \n",
    "    def _get_seq_frames(self, video_size: int, start: int, end: int, n_frames: int, clip_idx=-1):\n",
    "        \"\"\"\n",
    "        비디오에서 프레임을 샘플링\n",
    "        \n",
    "        video_size: 비디오의 프레임 수\n",
    "        start: 시작 프레임\n",
    "        end: 마지막 프레임\n",
    "        n_frames: 추출할 프레임 수\n",
    "        clip_idx: mode 확인\n",
    "        \"\"\"\n",
    "        # 시작 및 끝 시간 확인\n",
    "        start = max(0, min(start, video_size - 1))\n",
    "        end = max(start, min(end, video_size - 1))\n",
    "\n",
    "        clipped_video_size = end - start + 1\n",
    "        seg_size = max(0., (clipped_video_size - 1) / n_frames) # segment 크기\n",
    "        seq = []\n",
    "\n",
    "        # 비디오를 같은 시간 간격으로 잘라 segment 생성\n",
    "        # 각 segment마다 랜덤으로 프레임을 샘플링\n",
    "        if clip_idx == -1: # Train\n",
    "            for i in range(n_frames):\n",
    "                start_frame = int(np.round(seg_size * i)) + start # 각 segment의 첫 프레임\n",
    "                end_frame = int(np.round(seg_size * (i + 1))) + start # 각 segment의 마지막 프레임\n",
    "                idx = min(random.randint(start_frame, end_frame), end) # 각 segment에서 임의로 샘플링한 프레임\n",
    "                seq.append(idx)\n",
    "        else: # Eval\n",
    "            n_seg = 1\n",
    "            if self.mode == 'test':\n",
    "                n_seg = self.test_n_seg\n",
    "            duration = seg_size / (n_seg + 1)\n",
    "            for i in range(n_frames):\n",
    "                start_frame = int(np.round(seg_size * i)) + start\n",
    "                idx = min(start_frame + int(duration * (clip_idx + 1)), end) # 샘플링할 프레임\n",
    "                seq.append(idx)\n",
    "        \n",
    "        return seq\n",
    "\n",
    "\n",
    "\n",
    "    def loadvideo_decord(self, id: str, start: int, end: int, chunk_nb=0):\n",
    "        \"\"\"\n",
    "        비디오를 ndarray 형태로 로드\n",
    "        \n",
    "        id: Video id\n",
    "        start: 시작 시간\n",
    "        end: 끝 시간\n",
    "        chunk_nb: -1이면 학습 모드, 0이면 검증 모드, 그 이외의 정수 값은 테스트 모드에서의 chunk idx\n",
    "        \"\"\"\n",
    "        f_name = os.path.join(self.data_path, id)\n",
    "        try:\n",
    "            vr = VideoReader(f_name + '.mp4', ctx=cpu(0), num_threads=1)\n",
    "            fps = vr.get_avg_fps()\n",
    "            all_indices = self._get_seq_frames(len(vr), int(start * fps), int(end * fps), self.clip_len, clip_idx=chunk_nb)\n",
    "            \n",
    "            while len(all_indices) < self.clip_len:\n",
    "                print(f\"Some frame is not loaded in video({id})\")\n",
    "                all_indices = self._get_seq_frames(len(vr), int(start * fps), int(end * fps), self.clip_len, clip_idx=chunk_nb)\n",
    "\n",
    "            vr.seek(0) # 시작 지점으로 읽는 지점 초기화\n",
    "\n",
    "            return vr.get_batch(all_indices).asnumpy() # (T, H, W, C)의 tensor로 반환\n",
    "        except:\n",
    "            print(f\"Video cannot be loaded by decord: {f_name}\")\n",
    "            return []\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.mode != 'test':\n",
    "            return len(self.ids)\n",
    "        else:\n",
    "            return len(self.test_ids)\n",
    "        \n",
    "def spatial_sampling(\n",
    "        frames: torch.Tensor, target_height: int=720, target_width: int=1080,\n",
    "        random_horizontal_flip: bool=True, scale: Optional[list]=None, aspect_ratio: Optional[list]=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Random resized crop -> Horizontal flip\n",
    "    \"\"\"\n",
    "    transform_func = random_resized_crop_with_shift\n",
    "    frames = transform_func(\n",
    "        images=frames, target_height=target_height, target_width=target_width, scale=scale, ratio=aspect_ratio\n",
    "    )\n",
    "    if random_horizontal_flip:\n",
    "        frames, _ = horizontal_flip(.5, frames)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "\n",
    "def tensor_normalize(tensor: torch.Tensor, mean, std):\n",
    "    tensor = tensor.float()\n",
    "    if type(mean) == list:\n",
    "        mean = torch.tensor(mean)\n",
    "    if type(std) == list:\n",
    "        std = torch.tensor(std)\n",
    "    tensor = tensor - mean\n",
    "    tensor = tensor / std\n",
    "    return tensor\n",
    "\n",
    "def build_dataset(is_train, is_test):\n",
    "\n",
    "    mode = None\n",
    "    anno_path = None\n",
    "\n",
    "    if is_train == True:\n",
    "        mode = 'train'\n",
    "        anno_path = os.path.join('/nas/kks/data/condensed_movies/metadata', 'train_sample.csv')\n",
    "    elif is_test == True:\n",
    "        mode = 'test'\n",
    "        anno_path = os.path.join('/nas/kks/data/condensed_movies/metadata', 'test.csv')\n",
    "    else:\n",
    "        mode = 'validation'\n",
    "        anno_path = os.path.join('/nas/kks/data/condensed_movies/metadata', 'val.csv')\n",
    "    \n",
    "    dataset = CondensedMovies(\n",
    "        anno_path=anno_path, data_path='/nas/kks/data/condensed_movies/videos', split=',', mode=mode, clip_len=64,\n",
    "        frame_sample_rate=2, aug_size=(720, 1280), target_size=(480, 854), \n",
    "        n_seg=1, n_crop=1 if not is_train else 3, test_n_seg=4, test_n_crop=3,\n",
    "        min_duration=60, trimmed=180, time_stride=60\n",
    "    )\n",
    "    all_genres = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western']\n",
    "    cls_cnt_list = [3796, 2876, 661, 739, 6502, 2728, 109, 6389, 877, 1401, 149, 301, 1752, 422, 259, 1131, 2695, 1432, 7, 357, 2099, 265, 282]\n",
    "\n",
    "    print(f\"# of classes: {len(all_genres)}\")\n",
    "\n",
    "    return dataset, all_genres, cls_cnt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of classes: 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CondensedMovies at 0x7a93a4777280>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, _, _ = build_dataset(is_train=True, is_test=False)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing num_workers:   0%|          | 0/35 [00:00<?, ?it/s][h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9b033c0] mmco: unref short failure\n",
      "[h264 @ 0x9b033c0] mmco: unref short failure\n",
      "[h264 @ 0x9b033c0] mmco: unref short failure\n",
      "[h264 @ 0x9b033c0] mmco: unref short failure\n",
      "[h264 @ 0x9b033c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9abd540] mmco: unref short failure\n",
      "[h264 @ 0x9abd540] mmco: unref short failure\n",
      "[h264 @ 0xa110f00] mmco: unref short failure\n",
      "[h264 @ 0xa110f00] mmco: unref short failure\n",
      "[h264 @ 0xa110f00] mmco: unref short failure\n",
      "[h264 @ 0xa110f00] mmco: unref short failure\n",
      "[h264 @ 0x9cbefc0] mmco: unref short failure\n",
      "[h264 @ 0x9cbefc0] mmco: unref short failure\n",
      "[h264 @ 0x9afd100] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x2acabb40] mmco: unref short failure\n",
      "[h264 @ 0x2acabb40] mmco: unref short failure\n",
      "[h264 @ 0x2acabb40] mmco: unref short failure\n",
      "[h264 @ 0x2acabb40] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0xb0479c0] mmco: unref short failure\n",
      "[h264 @ 0xb0479c0] mmco: unref short failure\n",
      "[h264 @ 0xb0479c0] mmco: unref short failure\n",
      "Testing num_workers:   3%|▎         | 1/35 [17:51<10:07:21, 1071.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 1071.80 second, num_workers=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x4c876d80] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0xa28afc0] mmco: unref short failure\n",
      "[h264 @ 0xa28afc0] mmco: unref short failure\n",
      "[h264 @ 0xa3dfa80] mmco: unref short failure\n",
      "[h264 @ 0xa3dfa80] mmco: unref short failure\n",
      "[h264 @ 0xa3dfa80] mmco: unref short failure\n",
      "[h264 @ 0xa3dfa80] mmco: unref short failure\n",
      "[h264 @ 0xa3dfa80] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9bfda40] mmco: unref short failure\n",
      "[h264 @ 0x9bfda40] mmco: unref short failure\n",
      "[h264 @ 0x9bfda40] mmco: unref short failure\n",
      "[h264 @ 0x9bfda40] mmco: unref short failure\n",
      "[h264 @ 0x9bc1200] mmco: unref short failure\n",
      "[h264 @ 0x9bc1200] mmco: unref short failure\n",
      "[h264 @ 0x9bc1200] mmco: unref short failure\n",
      "[h264 @ 0x9acc100] mmco: unref short failure\n",
      "[h264 @ 0x9acc100] mmco: unref short failure\n",
      "[h264 @ 0x9c0dd80] mmco: unref short failure\n",
      "[h264 @ 0x9c0dd80] mmco: unref short failure\n",
      "[h264 @ 0x9c0dd80] mmco: unref short failure\n",
      "[h264 @ 0x9bf3c80] mmco: unref short failure\n",
      "[h264 @ 0x9bf3c80] mmco: unref short failure\n",
      "[h264 @ 0x9b73200] mmco: unref short failure\n",
      "[h264 @ 0x9b73200] mmco: unref short failure\n",
      "[h264 @ 0x9b73200] mmco: unref short failure\n",
      "[h264 @ 0x9b73200] mmco: unref short failure\n",
      "[h264 @ 0x9b73200] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "Testing num_workers:   6%|▌         | 2/35 [27:28<7:09:19, 780.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 576.71 second, num_workers=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0xa299b80] mmco: unref short failure\n",
      "[h264 @ 0xa299b80] mmco: unref short failure\n",
      "[h264 @ 0x9c06d40] mmco: unref short failure\n",
      "[h264 @ 0x9c06d40] mmco: unref short failure\n",
      "[h264 @ 0x9c06d40] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b5c300] mmco: unref short failure\n",
      "[h264 @ 0x9b5c300] mmco: unref short failure\n",
      "[h264 @ 0x9b5c300] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0xa03f5c0] mmco: unref short failure\n",
      "[h264 @ 0xa03f5c0] mmco: unref short failure\n",
      "[h264 @ 0xa1d8640] mmco: unref short failure\n",
      "[h264 @ 0xa1d8640] mmco: unref short failure\n",
      "[h264 @ 0xa1d8640] mmco: unref short failure\n",
      "[h264 @ 0xa1d8640] mmco: unref short failure\n",
      "[h264 @ 0xaa91cc0] mmco: unref short failure\n",
      "[h264 @ 0xaa91cc0] mmco: unref short failure\n",
      "Testing num_workers:   9%|▊         | 3/35 [34:41<5:31:44, 622.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 433.34 second, num_workers=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9b07e40] mmco: unref short failure\n",
      "[h264 @ 0x9b07e40] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9bb37c0] mmco: unref short failure\n",
      "[h264 @ 0x9bb37c0] mmco: unref short failure\n",
      "[h264 @ 0x9bb37c0] mmco: unref short failure\n",
      "[h264 @ 0x9bb37c0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9cd2ec0] mmco: unref short failure\n",
      "[h264 @ 0x9cd2ec0] mmco: unref short failure\n",
      "[h264 @ 0x9cd2ec0] mmco: unref short failure\n",
      "[h264 @ 0x9cd2ec0] mmco: unref short failure\n",
      "[h264 @ 0xa2a4300] mmco: unref short failure\n",
      "[h264 @ 0xa2a4300] mmco: unref short failure\n",
      "[h264 @ 0xa2a4300] mmco: unref short failure\n",
      "[h264 @ 0xe400800] mmco: unref short failure\n",
      "[h264 @ 0x1d9d3b40] mmco: unref short failure\n",
      "[h264 @ 0x1d9d3b40] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9ae5340] mmco: unref short failure\n",
      "[h264 @ 0x9ae5340] mmco: unref short failure\n",
      "[h264 @ 0x9ae5340] mmco: unref short failure\n",
      "Testing num_workers:  11%|█▏        | 4/35 [41:00<4:31:39, 525.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 378.30 second, num_workers=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x8a51dc0] mmco: unref short failure\n",
      "[h264 @ 0x8a51dc0] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9a796c0] mmco: unref short failure\n",
      "[h264 @ 0x9a796c0] mmco: unref short failure\n",
      "[h264 @ 0x9a796c0] mmco: unref short failure\n",
      "[h264 @ 0x9a796c0] mmco: unref short failure\n",
      "[h264 @ 0xaaad740] mmco: unref short failure\n",
      "[h264 @ 0xaaad740] mmco: unref short failure\n",
      "[h264 @ 0xaaad740] mmco: unref short failure\n",
      "[h264 @ 0x9ada800] mmco: unref short failure\n",
      "[h264 @ 0x9ada800] mmco: unref short failure\n",
      "[h264 @ 0x9ada800] mmco: unref short failure\n",
      "[h264 @ 0x9ada800] mmco: unref short failure\n",
      "[h264 @ 0x9ada800] mmco: unref short failure\n",
      "[h264 @ 0x9ea0340] mmco: unref short failure\n",
      "[h264 @ 0x9ea0340] mmco: unref short failure\n",
      "[h264 @ 0xc152980] mmco: unref short failure\n",
      "[h264 @ 0xc152980] mmco: unref short failure\n",
      "Testing num_workers:  14%|█▍        | 5/35 [46:00<3:42:19, 444.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 300.79 second, num_workers=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0xa86e140] mmco: unref short failure\n",
      "[h264 @ 0xa86e140] mmco: unref short failure\n",
      "[h264 @ 0xa86e140] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9ae2c00] mmco: unref short failure\n",
      "[h264 @ 0x9ae2c00] mmco: unref short failure\n",
      "[h264 @ 0x9ae2c00] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9b08340] mmco: unref short failure\n",
      "[h264 @ 0x9b08300] mmco: unref short failure\n",
      "[h264 @ 0x9b08300] mmco: unref short failure\n",
      "[h264 @ 0x69c73340] mmco: unref short failure\n",
      "[h264 @ 0x69c73340] mmco: unref short failure\n",
      "[h264 @ 0x69c73340] mmco: unref short failure\n",
      "[h264 @ 0x69c73340] mmco: unref short failure\n",
      "[h264 @ 0xb16de40] mmco: unref short failure\n",
      "[h264 @ 0xb16de40] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "Testing num_workers:  17%|█▋        | 6/35 [50:54<3:10:05, 393.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 293.62 second, num_workers=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9ae29c0] mmco: unref short failure\n",
      "[h264 @ 0x9ae29c0] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9cf50c0] mmco: unref short failure\n",
      "[h264 @ 0x9cf50c0] mmco: unref short failure\n",
      "[h264 @ 0x9cf50c0] mmco: unref short failure\n",
      "[h264 @ 0x9cf50c0] mmco: unref short failure\n",
      "[h264 @ 0x9cf50c0] mmco: unref short failure\n",
      "[h264 @ 0x9cd2000] mmco: unref short failure\n",
      "[h264 @ 0x9cd2000] mmco: unref short failure\n",
      "[h264 @ 0x9cd2000] mmco: unref short failure\n",
      "[h264 @ 0x9cd2000] mmco: unref short failure\n",
      "[h264 @ 0x9b08140] mmco: unref short failure\n",
      "[h264 @ 0x9b08140] mmco: unref short failure\n",
      "[h264 @ 0x9ad9600] mmco: unref short failure\n",
      "[h264 @ 0x9ad9600] mmco: unref short failure\n",
      "[h264 @ 0x9ad5f00] mmco: unref short failure\n",
      "[h264 @ 0x9ad5f00] mmco: unref short failure\n",
      "[h264 @ 0x9ad5f00] mmco: unref short failure\n",
      "[h264 @ 0x9ad5f00] mmco: unref short failure\n",
      "[h264 @ 0x9ad5f00] mmco: unref short failure\n",
      "[h264 @ 0xa344540] mmco: unref short failure\n",
      "[h264 @ 0xa344540] mmco: unref short failure\n",
      "[h264 @ 0x9fdf540] mmco: unref short failure\n",
      "[h264 @ 0x9b5ca80] mmco: unref short failure\n",
      "[h264 @ 0x9b5ca80] mmco: unref short failure\n",
      "Testing num_workers:  20%|██        | 7/35 [55:50<2:48:44, 361.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 296.24 second, num_workers=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9ad7640] mmco: unref short failure\n",
      "[h264 @ 0x9ad7640] mmco: unref short failure\n",
      "[h264 @ 0x9aeeb40] mmco: unref short failure\n",
      "[h264 @ 0x9aeeb40] mmco: unref short failure\n",
      "[h264 @ 0x9beaa80] mmco: unref short failure\n",
      "[h264 @ 0x9beaa80] mmco: unref short failure\n",
      "[h264 @ 0x9beaa80] mmco: unref short failure\n",
      "[h264 @ 0x9beaa80] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9418fc0] mmco: unref short failure\n",
      "[h264 @ 0x9418fc0] mmco: unref short failure\n",
      "[h264 @ 0x9ae8580] mmco: unref short failure\n",
      "[h264 @ 0x9ae8580] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0xa321300] mmco: unref short failure\n",
      "[h264 @ 0xa321300] mmco: unref short failure\n",
      "[h264 @ 0xa321300] mmco: unref short failure\n",
      "Testing num_workers:  23%|██▎       | 8/35 [1:02:52<2:51:17, 380.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 421.52 second, num_workers=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9b5c340] mmco: unref short failure\n",
      "[h264 @ 0x9b5c340] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9419c80] mmco: unref short failure\n",
      "[h264 @ 0x9419c80] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9fd8280] mmco: unref short failure\n",
      "[h264 @ 0x9fd8280] mmco: unref short failure\n",
      "[h264 @ 0xa826440] mmco: unref short failure\n",
      "[h264 @ 0xa826440] mmco: unref short failure\n",
      "[h264 @ 0xa826440] mmco: unref short failure\n",
      "[h264 @ 0x9b5c6c0] mmco: unref short failure\n",
      "[h264 @ 0x9b5c6c0] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9fd98c0] mmco: unref short failure\n",
      "[h264 @ 0x9fd98c0] mmco: unref short failure\n",
      "[h264 @ 0x9fd98c0] mmco: unref short failure\n",
      "[h264 @ 0x9fd98c0] mmco: unref short failure\n",
      "[h264 @ 0x9ae7200] mmco: unref short failure\n",
      "[h264 @ 0x9ae7200] mmco: unref short failure\n",
      "[h264 @ 0x9b5c200] mmco: unref short failure\n",
      "[h264 @ 0x9b5c200] mmco: unref short failure\n",
      "[h264 @ 0x9b5c200] mmco: unref short failure\n",
      "[h264 @ 0x9b5c200] mmco: unref short failure\n",
      "[h264 @ 0x9b5c200] mmco: unref short failure\n",
      "Testing num_workers:  26%|██▌       | 9/35 [1:13:04<3:16:15, 452.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 611.66 second, num_workers=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9eb4980] mmco: unref short failure\n",
      "[h264 @ 0x9eb4980] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9f79b40] mmco: unref short failure\n",
      "[h264 @ 0x9f79b40] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0xa512f40] mmco: unref short failure\n",
      "[h264 @ 0xa512f40] mmco: unref short failure\n",
      "[h264 @ 0xa512f40] mmco: unref short failure\n",
      "[h264 @ 0x9ae4d40] mmco: unref short failure\n",
      "[h264 @ 0x9ae4d40] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9c59d80] mmco: unref short failure\n",
      "[h264 @ 0x9c59d80] mmco: unref short failure\n",
      "Testing num_workers:  29%|██▊       | 10/35 [1:23:32<3:31:16, 507.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 628.22 second, num_workers=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9ae4880] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9ae79c0] mmco: unref short failure\n",
      "[h264 @ 0x9ae79c0] mmco: unref short failure\n",
      "[h264 @ 0x9ae79c0] mmco: unref short failure\n",
      "[h264 @ 0x9d08700] mmco: unref short failure\n",
      "[h264 @ 0x9d08700] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9aeaa40] mmco: unref short failure\n",
      "[h264 @ 0x9aeaa40] mmco: unref short failure\n",
      "[h264 @ 0x9aeaa40] mmco: unref short failure\n",
      "[h264 @ 0x9ae8e80] mmco: unref short failure\n",
      "[h264 @ 0x9ae8e80] mmco: unref short failure\n",
      "[h264 @ 0x9ae8e80] mmco: unref short failure\n",
      "[h264 @ 0x9ae8e80] mmco: unref short failure\n",
      "[h264 @ 0x9ae8e80] mmco: unref short failure\n",
      "[h264 @ 0x9901f40] mmco: unref short failure\n",
      "[h264 @ 0x9901f40] mmco: unref short failure\n",
      "[h264 @ 0x9aeb380] mmco: unref short failure\n",
      "[h264 @ 0x9aeb380] mmco: unref short failure\n",
      "[h264 @ 0x9aeb380] mmco: unref short failure\n",
      "[h264 @ 0x9aeb380] mmco: unref short failure\n",
      "[h264 @ 0x9aebec0] mmco: unref short failure\n",
      "Testing num_workers:  31%|███▏      | 11/35 [1:36:42<3:57:30, 593.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 790.21 second, num_workers=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0xa021680] mmco: unref short failure\n",
      "[h264 @ 0xa021680] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x1e3904c0] mmco: unref short failure\n",
      "[h264 @ 0x1e3904c0] mmco: unref short failure\n",
      "[h264 @ 0x1e3904c0] mmco: unref short failure\n",
      "[h264 @ 0x9acbe00] mmco: unref short failure\n",
      "[h264 @ 0x9acbe00] mmco: unref short failure\n",
      "[h264 @ 0x9acbe00] mmco: unref short failure\n",
      "[h264 @ 0x9ae5440] mmco: unref short failure\n",
      "[h264 @ 0x9ae5440] mmco: unref short failure\n",
      "[h264 @ 0x9ae5440] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad69c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad69c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad69c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad69c0] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "Testing num_workers:  34%|███▍      | 12/35 [1:48:46<4:02:47, 633.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 723.91 second, num_workers=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9af0f80] mmco: unref short failure\n",
      "[h264 @ 0x9af0f80] mmco: unref short failure\n",
      "[h264 @ 0x9af0f80] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0xa0b2d80] mmco: unref short failure\n",
      "[h264 @ 0xa0b2d80] mmco: unref short failure\n",
      "[h264 @ 0xa0b2d80] mmco: unref short failure\n",
      "[h264 @ 0xa0b2d80] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0xa8b7780] mmco: unref short failure\n",
      "[h264 @ 0xa8b7780] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9ae6140] mmco: unref short failure\n",
      "[h264 @ 0x9ae6140] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9aeb500] mmco: unref short failure\n",
      "[h264 @ 0x9aeb500] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "Testing num_workers:  37%|███▋      | 13/35 [2:00:39<4:01:03, 657.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 712.75 second, num_workers=26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9af0f80] mmco: unref short failure\n",
      "[h264 @ 0x9af0f80] mmco: unref short failure\n",
      "[h264 @ 0xa41e840] mmco: unref short failure\n",
      "[h264 @ 0xa41e840] mmco: unref short failure\n",
      "[h264 @ 0xa41e840] mmco: unref short failure\n",
      "[h264 @ 0x9c7a680] mmco: unref short failure\n",
      "[h264 @ 0x9c7a680] mmco: unref short failure\n",
      "[h264 @ 0x9c7a680] mmco: unref short failure\n",
      "[h264 @ 0x9c7a680] mmco: unref short failure\n",
      "[h264 @ 0x9ae5d80] mmco: unref short failure\n",
      "[h264 @ 0x9ae5d80] mmco: unref short failure\n",
      "[h264 @ 0x9ae79c0] mmco: unref short failure\n",
      "[h264 @ 0x9ae79c0] mmco: unref short failure\n",
      "[h264 @ 0x9ae79c0] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9bfe8c0] mmco: unref short failure\n",
      "[h264 @ 0x9bfe8c0] mmco: unref short failure\n",
      "[h264 @ 0x9bfe8c0] mmco: unref short failure\n",
      "[h264 @ 0x9bfe8c0] mmco: unref short failure\n",
      "[h264 @ 0x9bfe8c0] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9aec3c0] mmco: unref short failure\n",
      "[h264 @ 0x9aec3c0] mmco: unref short failure\n",
      "[h264 @ 0x9bfeec0] mmco: unref short failure\n",
      "[h264 @ 0x9bfeec0] mmco: unref short failure\n",
      "[h264 @ 0x9bfeec0] mmco: unref short failure\n",
      "[h264 @ 0x9bfeec0] mmco: unref short failure\n",
      "[h264 @ 0x9aec3c0] mmco: unref short failure\n",
      "[h264 @ 0x9aec3c0] mmco: unref short failure\n",
      "Testing num_workers:  40%|████      | 14/35 [2:11:44<3:50:50, 659.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 664.34 second, num_workers=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9ad67c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad67c0] mmco: unref short failure\n",
      "[h264 @ 0xa1af3c0] mmco: unref short failure\n",
      "[h264 @ 0xa868800] mmco: unref short failure\n",
      "[h264 @ 0xa868800] mmco: unref short failure\n",
      "[h264 @ 0xa1af3c0] mmco: unref short failure\n",
      "[h264 @ 0x9b5d240] mmco: unref short failure\n",
      "[h264 @ 0x9b5d240] mmco: unref short failure\n",
      "[h264 @ 0x9b5d240] mmco: unref short failure\n",
      "[h264 @ 0x9b5d240] mmco: unref short failure\n",
      "[h264 @ 0xa868800] mmco: unref short failure\n",
      "[h264 @ 0xa868800] mmco: unref short failure\n",
      "[h264 @ 0xa868800] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad77c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad77c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad77c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad77c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad77c0] mmco: unref short failure\n",
      "[h264 @ 0xa2db240] mmco: unref short failure\n",
      "[h264 @ 0xa2db240] mmco: unref short failure\n",
      "[h264 @ 0xa2db240] mmco: unref short failure\n",
      "[h264 @ 0xa2db240] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9ae89c0] mmco: unref short failure\n",
      "[h264 @ 0x9ae89c0] mmco: unref short failure\n",
      "[h264 @ 0x9ae89c0] mmco: unref short failure\n",
      "Testing num_workers:  43%|████▎     | 15/35 [2:24:10<3:48:36, 685.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 746.61 second, num_workers=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9c605c0] mmco: unref short failure\n",
      "[h264 @ 0x9c605c0] mmco: unref short failure\n",
      "[h264 @ 0xa5a7e40] mmco: unref short failure\n",
      "[h264 @ 0xa5a7e40] mmco: unref short failure\n",
      "[h264 @ 0xa5a7e40] mmco: unref short failure\n",
      "[h264 @ 0xa5a7e40] mmco: unref short failure\n",
      "[h264 @ 0xa5a7e40] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9ad2680] mmco: unref short failure\n",
      "[h264 @ 0x9ad2680] mmco: unref short failure\n",
      "[h264 @ 0x9ad2680] mmco: unref short failure\n",
      "[h264 @ 0x9ad2680] mmco: unref short failure\n",
      "[h264 @ 0x9ad2680] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9ce2d80] mmco: unref short failure\n",
      "[h264 @ 0x9ce2d80] mmco: unref short failure\n",
      "[h264 @ 0x9af4580] mmco: unref short failure\n",
      "[h264 @ 0x9af4580] mmco: unref short failure\n",
      "[h264 @ 0x9af4580] mmco: unref short failure\n",
      "[h264 @ 0x9af4580] mmco: unref short failure\n",
      "[h264 @ 0x9ad2680] mmco: unref short failure\n",
      "[h264 @ 0x9ad2680] mmco: unref short failure\n",
      "[h264 @ 0x9ad2680] mmco: unref short failure\n",
      "Testing num_workers:  46%|████▌     | 16/35 [2:36:05<3:39:56, 694.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 714.72 second, num_workers=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9adb080] mmco: unref short failure\n",
      "[h264 @ 0x9aea0c0] mmco: unref short failure\n",
      "[h264 @ 0x9aea0c0] mmco: unref short failure\n",
      "[h264 @ 0x9af1d80] mmco: unref short failure\n",
      "[h264 @ 0x9af1d80] mmco: unref short failure\n",
      "[h264 @ 0x9af1d80] mmco: unref short failure\n",
      "[h264 @ 0x9af1d80] mmco: unref short failure\n",
      "[h264 @ 0x9eaea80] mmco: unref short failure\n",
      "[h264 @ 0x9eaea80] mmco: unref short failure\n",
      "[h264 @ 0x9cd5f40] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9afa980] mmco: unref short failure\n",
      "[h264 @ 0x9af1d80] mmco: unref short failure\n",
      "[h264 @ 0x9af1d80] mmco: unref short failure\n",
      "[h264 @ 0x9afa980] mmco: unref short failure\n",
      "[h264 @ 0x9afa980] mmco: unref short failure\n",
      "[h264 @ 0x9afbfc0] mmco: unref short failure\n",
      "[h264 @ 0x9afbfc0] mmco: unref short failure\n",
      "[h264 @ 0x9afbfc0] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9b32600] mmco: unref short failure\n",
      "[h264 @ 0x9afbfc0] mmco: unref short failure\n",
      "[h264 @ 0x9afbfc0] mmco: unref short failure\n",
      "[h264 @ 0x9afbfc0] mmco: unref short failure\n",
      "[h264 @ 0x9afbfc0] mmco: unref short failure\n",
      "[h264 @ 0x9f82480] mmco: unref short failure\n",
      "[h264 @ 0x9f82480] mmco: unref short failure\n",
      "[h264 @ 0x9af7280] mmco: unref short failure\n",
      "[h264 @ 0x9af7280] mmco: unref short failure\n",
      "[h264 @ 0x9af7280] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "[h264 @ 0x9901ec0] mmco: unref short failure\n",
      "Testing num_workers:  49%|████▊     | 17/35 [2:49:08<3:36:21, 721.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with: 783.05 second, num_workers=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9ad77c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad77c0] mmco: unref short failure\n",
      "[h264 @ 0x9afdd00] mmco: unref short failure\n",
      "[h264 @ 0x9afdd00] mmco: unref short failure\n",
      "[h264 @ 0x9afdd00] mmco: unref short failure\n",
      "[h264 @ 0xa572340] mmco: unref short failure\n",
      "[h264 @ 0xa572340] mmco: unref short failure\n",
      "[h264 @ 0xa572340] mmco: unref short failure\n",
      "[h264 @ 0xa572340] mmco: unref short failure\n",
      "[h264 @ 0xa572340] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9ac7b40] mmco: unref short failure\n",
      "[h264 @ 0x9b5d240] mmco: unref short failure\n",
      "[h264 @ 0x9b5d240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9adcd80] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9b596c0] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9ad9400] mmco: unref short failure\n",
      "[h264 @ 0x9b5ca80] mmco: unref short failure\n",
      "[h264 @ 0x9b5ca80] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x9bcffc0] mmco: unref short failure\n",
      "[h264 @ 0x9bcffc0] mmco: unref short failure\n",
      "[h264 @ 0x9bcffc0] mmco: unref short failure\n",
      "[h264 @ 0x9bcffc0] mmco: unref short failure\n",
      "[h264 @ 0x9bcffc0] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "[h264 @ 0x986e240] mmco: unref short failure\n",
      "Testing num_workers:  49%|████▊     | 17/35 [2:59:03<3:09:35, 631.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     15\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/anaconda3/envs/video_mamba/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/video_mamba/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/video_mamba/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/video_mamba/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/video_mamba/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/video_mamba/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import multiprocessing as mp\n",
    "import traceback\n",
    "\n",
    "# 결과 저장을 위한 딕셔너리 생성\n",
    "results = {}\n",
    "for num_workers in tqdm(range(2, mp.cpu_count(), 2), desc=\"Testing num_workers\"):\n",
    "    train_loader = DataLoader(dataset, shuffle=True, num_workers=num_workers, batch_size=8\n",
    "    \n",
    "    , pin_memory=True)\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            pass\n",
    "    end = time()\n",
    "\n",
    "    # 결과 저장\n",
    "    results[num_workers] = end - start\n",
    "    print(f\"Finish with: {end - start:.2f} second, num_workers={num_workers}\")\n",
    "\n",
    "# 결과 출력 또는 저장\n",
    "print(results)  # 딕셔너리 형태로 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1824.2930824756622, 4: 1407.4671301841736, 6: 1825.0889151096344}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use chcekpoint: False\n",
      "Checkpoint number: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionMamba(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv3d(3, 576, kernel_size=(1, 16, 16), stride=(1, 16, 16))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=576, out_features=2, bias=True)\n",
       "  (head_drop): Dropout(p=0.3, inplace=False)\n",
       "  (drop_path): DropPath()\n",
       "  (layers): ModuleList(\n",
       "    (0): Block(\n",
       "      (mixer): Mamba(\n",
       "        (in_proj): Linear(in_features=576, out_features=2304, bias=False)\n",
       "        (conv1d): Conv1d(1152, 1152, kernel_size=(4,), stride=(1,), padding=(3,), groups=1152)\n",
       "        (act): SiLU()\n",
       "        (x_proj): Linear(in_features=1152, out_features=68, bias=False)\n",
       "        (dt_proj): Linear(in_features=36, out_features=1152, bias=True)\n",
       "        (conv1d_b): Conv1d(1152, 1152, kernel_size=(4,), stride=(1,), padding=(3,), groups=1152)\n",
       "        (x_proj_b): Linear(in_features=1152, out_features=68, bias=False)\n",
       "        (dt_proj_b): Linear(in_features=36, out_features=1152, bias=True)\n",
       "        (out_proj): Linear(in_features=1152, out_features=576, bias=False)\n",
       "      )\n",
       "      (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_path): Identity()\n",
       "    )\n",
       "    (1-31): 31 x Block(\n",
       "      (mixer): Mamba(\n",
       "        (in_proj): Linear(in_features=576, out_features=2304, bias=False)\n",
       "        (conv1d): Conv1d(1152, 1152, kernel_size=(4,), stride=(1,), padding=(3,), groups=1152)\n",
       "        (act): SiLU()\n",
       "        (x_proj): Linear(in_features=1152, out_features=68, bias=False)\n",
       "        (dt_proj): Linear(in_features=36, out_features=1152, bias=True)\n",
       "        (conv1d_b): Conv1d(1152, 1152, kernel_size=(4,), stride=(1,), padding=(3,), groups=1152)\n",
       "        (x_proj_b): Linear(in_features=1152, out_features=68, bias=False)\n",
       "        (dt_proj_b): Linear(in_features=36, out_features=1152, bias=True)\n",
       "        (out_proj): Linear(in_features=1152, out_features=576, bias=False)\n",
       "      )\n",
       "      (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_path): DropPath()\n",
       "    )\n",
       "  )\n",
       "  (norm_f): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from videomamba import VisionMamba\n",
    "\n",
    "def videomamba_middle(pretrained=False, **kwargs):\n",
    "    model = VisionMamba(\n",
    "        embed_dim=576,\n",
    "        depth=32,\n",
    "        residual_in_fp32=True,\n",
    "        # rms_norm=True,\n",
    "        # fused_add_norm=True,\n",
    "        rms_norm=False,\n",
    "        fused_add_norm=False,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = videomamba_middle(\n",
    "    pretrained=False, height=480, width=854, n_classes=2, fc_drop_rate=.3, drop_path_rate=.3, kernel_size=1,\n",
    "    n_frames=2, use_checkpoint=False, checkpoint_num=32\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token\n",
      "pos_embed\n",
      "temporal_pos_embedding\n",
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "head.weight\n",
      "head.bias\n",
      "layers.0.mixer.A_log\n",
      "layers.0.mixer.D\n",
      "layers.0.mixer.A_b_log\n",
      "layers.0.mixer.D_b\n",
      "layers.0.mixer.in_proj.weight\n",
      "layers.0.mixer.conv1d.weight\n",
      "layers.0.mixer.conv1d.bias\n",
      "layers.0.mixer.x_proj.weight\n",
      "layers.0.mixer.dt_proj.weight\n",
      "layers.0.mixer.dt_proj.bias\n",
      "layers.0.mixer.conv1d_b.weight\n",
      "layers.0.mixer.conv1d_b.bias\n",
      "layers.0.mixer.x_proj_b.weight\n",
      "layers.0.mixer.dt_proj_b.weight\n",
      "layers.0.mixer.dt_proj_b.bias\n",
      "layers.0.mixer.out_proj.weight\n",
      "layers.0.norm.weight\n",
      "layers.0.norm.bias\n",
      "layers.1.mixer.A_log\n",
      "layers.1.mixer.D\n",
      "layers.1.mixer.A_b_log\n",
      "layers.1.mixer.D_b\n",
      "layers.1.mixer.in_proj.weight\n",
      "layers.1.mixer.conv1d.weight\n",
      "layers.1.mixer.conv1d.bias\n",
      "layers.1.mixer.x_proj.weight\n",
      "layers.1.mixer.dt_proj.weight\n",
      "layers.1.mixer.dt_proj.bias\n",
      "layers.1.mixer.conv1d_b.weight\n",
      "layers.1.mixer.conv1d_b.bias\n",
      "layers.1.mixer.x_proj_b.weight\n",
      "layers.1.mixer.dt_proj_b.weight\n",
      "layers.1.mixer.dt_proj_b.bias\n",
      "layers.1.mixer.out_proj.weight\n",
      "layers.1.norm.weight\n",
      "layers.1.norm.bias\n",
      "layers.2.mixer.A_log\n",
      "layers.2.mixer.D\n",
      "layers.2.mixer.A_b_log\n",
      "layers.2.mixer.D_b\n",
      "layers.2.mixer.in_proj.weight\n",
      "layers.2.mixer.conv1d.weight\n",
      "layers.2.mixer.conv1d.bias\n",
      "layers.2.mixer.x_proj.weight\n",
      "layers.2.mixer.dt_proj.weight\n",
      "layers.2.mixer.dt_proj.bias\n",
      "layers.2.mixer.conv1d_b.weight\n",
      "layers.2.mixer.conv1d_b.bias\n",
      "layers.2.mixer.x_proj_b.weight\n",
      "layers.2.mixer.dt_proj_b.weight\n",
      "layers.2.mixer.dt_proj_b.bias\n",
      "layers.2.mixer.out_proj.weight\n",
      "layers.2.norm.weight\n",
      "layers.2.norm.bias\n",
      "layers.3.mixer.A_log\n",
      "layers.3.mixer.D\n",
      "layers.3.mixer.A_b_log\n",
      "layers.3.mixer.D_b\n",
      "layers.3.mixer.in_proj.weight\n",
      "layers.3.mixer.conv1d.weight\n",
      "layers.3.mixer.conv1d.bias\n",
      "layers.3.mixer.x_proj.weight\n",
      "layers.3.mixer.dt_proj.weight\n",
      "layers.3.mixer.dt_proj.bias\n",
      "layers.3.mixer.conv1d_b.weight\n",
      "layers.3.mixer.conv1d_b.bias\n",
      "layers.3.mixer.x_proj_b.weight\n",
      "layers.3.mixer.dt_proj_b.weight\n",
      "layers.3.mixer.dt_proj_b.bias\n",
      "layers.3.mixer.out_proj.weight\n",
      "layers.3.norm.weight\n",
      "layers.3.norm.bias\n",
      "layers.4.mixer.A_log\n",
      "layers.4.mixer.D\n",
      "layers.4.mixer.A_b_log\n",
      "layers.4.mixer.D_b\n",
      "layers.4.mixer.in_proj.weight\n",
      "layers.4.mixer.conv1d.weight\n",
      "layers.4.mixer.conv1d.bias\n",
      "layers.4.mixer.x_proj.weight\n",
      "layers.4.mixer.dt_proj.weight\n",
      "layers.4.mixer.dt_proj.bias\n",
      "layers.4.mixer.conv1d_b.weight\n",
      "layers.4.mixer.conv1d_b.bias\n",
      "layers.4.mixer.x_proj_b.weight\n",
      "layers.4.mixer.dt_proj_b.weight\n",
      "layers.4.mixer.dt_proj_b.bias\n",
      "layers.4.mixer.out_proj.weight\n",
      "layers.4.norm.weight\n",
      "layers.4.norm.bias\n",
      "layers.5.mixer.A_log\n",
      "layers.5.mixer.D\n",
      "layers.5.mixer.A_b_log\n",
      "layers.5.mixer.D_b\n",
      "layers.5.mixer.in_proj.weight\n",
      "layers.5.mixer.conv1d.weight\n",
      "layers.5.mixer.conv1d.bias\n",
      "layers.5.mixer.x_proj.weight\n",
      "layers.5.mixer.dt_proj.weight\n",
      "layers.5.mixer.dt_proj.bias\n",
      "layers.5.mixer.conv1d_b.weight\n",
      "layers.5.mixer.conv1d_b.bias\n",
      "layers.5.mixer.x_proj_b.weight\n",
      "layers.5.mixer.dt_proj_b.weight\n",
      "layers.5.mixer.dt_proj_b.bias\n",
      "layers.5.mixer.out_proj.weight\n",
      "layers.5.norm.weight\n",
      "layers.5.norm.bias\n",
      "layers.6.mixer.A_log\n",
      "layers.6.mixer.D\n",
      "layers.6.mixer.A_b_log\n",
      "layers.6.mixer.D_b\n",
      "layers.6.mixer.in_proj.weight\n",
      "layers.6.mixer.conv1d.weight\n",
      "layers.6.mixer.conv1d.bias\n",
      "layers.6.mixer.x_proj.weight\n",
      "layers.6.mixer.dt_proj.weight\n",
      "layers.6.mixer.dt_proj.bias\n",
      "layers.6.mixer.conv1d_b.weight\n",
      "layers.6.mixer.conv1d_b.bias\n",
      "layers.6.mixer.x_proj_b.weight\n",
      "layers.6.mixer.dt_proj_b.weight\n",
      "layers.6.mixer.dt_proj_b.bias\n",
      "layers.6.mixer.out_proj.weight\n",
      "layers.6.norm.weight\n",
      "layers.6.norm.bias\n",
      "layers.7.mixer.A_log\n",
      "layers.7.mixer.D\n",
      "layers.7.mixer.A_b_log\n",
      "layers.7.mixer.D_b\n",
      "layers.7.mixer.in_proj.weight\n",
      "layers.7.mixer.conv1d.weight\n",
      "layers.7.mixer.conv1d.bias\n",
      "layers.7.mixer.x_proj.weight\n",
      "layers.7.mixer.dt_proj.weight\n",
      "layers.7.mixer.dt_proj.bias\n",
      "layers.7.mixer.conv1d_b.weight\n",
      "layers.7.mixer.conv1d_b.bias\n",
      "layers.7.mixer.x_proj_b.weight\n",
      "layers.7.mixer.dt_proj_b.weight\n",
      "layers.7.mixer.dt_proj_b.bias\n",
      "layers.7.mixer.out_proj.weight\n",
      "layers.7.norm.weight\n",
      "layers.7.norm.bias\n",
      "layers.8.mixer.A_log\n",
      "layers.8.mixer.D\n",
      "layers.8.mixer.A_b_log\n",
      "layers.8.mixer.D_b\n",
      "layers.8.mixer.in_proj.weight\n",
      "layers.8.mixer.conv1d.weight\n",
      "layers.8.mixer.conv1d.bias\n",
      "layers.8.mixer.x_proj.weight\n",
      "layers.8.mixer.dt_proj.weight\n",
      "layers.8.mixer.dt_proj.bias\n",
      "layers.8.mixer.conv1d_b.weight\n",
      "layers.8.mixer.conv1d_b.bias\n",
      "layers.8.mixer.x_proj_b.weight\n",
      "layers.8.mixer.dt_proj_b.weight\n",
      "layers.8.mixer.dt_proj_b.bias\n",
      "layers.8.mixer.out_proj.weight\n",
      "layers.8.norm.weight\n",
      "layers.8.norm.bias\n",
      "layers.9.mixer.A_log\n",
      "layers.9.mixer.D\n",
      "layers.9.mixer.A_b_log\n",
      "layers.9.mixer.D_b\n",
      "layers.9.mixer.in_proj.weight\n",
      "layers.9.mixer.conv1d.weight\n",
      "layers.9.mixer.conv1d.bias\n",
      "layers.9.mixer.x_proj.weight\n",
      "layers.9.mixer.dt_proj.weight\n",
      "layers.9.mixer.dt_proj.bias\n",
      "layers.9.mixer.conv1d_b.weight\n",
      "layers.9.mixer.conv1d_b.bias\n",
      "layers.9.mixer.x_proj_b.weight\n",
      "layers.9.mixer.dt_proj_b.weight\n",
      "layers.9.mixer.dt_proj_b.bias\n",
      "layers.9.mixer.out_proj.weight\n",
      "layers.9.norm.weight\n",
      "layers.9.norm.bias\n",
      "layers.10.mixer.A_log\n",
      "layers.10.mixer.D\n",
      "layers.10.mixer.A_b_log\n",
      "layers.10.mixer.D_b\n",
      "layers.10.mixer.in_proj.weight\n",
      "layers.10.mixer.conv1d.weight\n",
      "layers.10.mixer.conv1d.bias\n",
      "layers.10.mixer.x_proj.weight\n",
      "layers.10.mixer.dt_proj.weight\n",
      "layers.10.mixer.dt_proj.bias\n",
      "layers.10.mixer.conv1d_b.weight\n",
      "layers.10.mixer.conv1d_b.bias\n",
      "layers.10.mixer.x_proj_b.weight\n",
      "layers.10.mixer.dt_proj_b.weight\n",
      "layers.10.mixer.dt_proj_b.bias\n",
      "layers.10.mixer.out_proj.weight\n",
      "layers.10.norm.weight\n",
      "layers.10.norm.bias\n",
      "layers.11.mixer.A_log\n",
      "layers.11.mixer.D\n",
      "layers.11.mixer.A_b_log\n",
      "layers.11.mixer.D_b\n",
      "layers.11.mixer.in_proj.weight\n",
      "layers.11.mixer.conv1d.weight\n",
      "layers.11.mixer.conv1d.bias\n",
      "layers.11.mixer.x_proj.weight\n",
      "layers.11.mixer.dt_proj.weight\n",
      "layers.11.mixer.dt_proj.bias\n",
      "layers.11.mixer.conv1d_b.weight\n",
      "layers.11.mixer.conv1d_b.bias\n",
      "layers.11.mixer.x_proj_b.weight\n",
      "layers.11.mixer.dt_proj_b.weight\n",
      "layers.11.mixer.dt_proj_b.bias\n",
      "layers.11.mixer.out_proj.weight\n",
      "layers.11.norm.weight\n",
      "layers.11.norm.bias\n",
      "layers.12.mixer.A_log\n",
      "layers.12.mixer.D\n",
      "layers.12.mixer.A_b_log\n",
      "layers.12.mixer.D_b\n",
      "layers.12.mixer.in_proj.weight\n",
      "layers.12.mixer.conv1d.weight\n",
      "layers.12.mixer.conv1d.bias\n",
      "layers.12.mixer.x_proj.weight\n",
      "layers.12.mixer.dt_proj.weight\n",
      "layers.12.mixer.dt_proj.bias\n",
      "layers.12.mixer.conv1d_b.weight\n",
      "layers.12.mixer.conv1d_b.bias\n",
      "layers.12.mixer.x_proj_b.weight\n",
      "layers.12.mixer.dt_proj_b.weight\n",
      "layers.12.mixer.dt_proj_b.bias\n",
      "layers.12.mixer.out_proj.weight\n",
      "layers.12.norm.weight\n",
      "layers.12.norm.bias\n",
      "layers.13.mixer.A_log\n",
      "layers.13.mixer.D\n",
      "layers.13.mixer.A_b_log\n",
      "layers.13.mixer.D_b\n",
      "layers.13.mixer.in_proj.weight\n",
      "layers.13.mixer.conv1d.weight\n",
      "layers.13.mixer.conv1d.bias\n",
      "layers.13.mixer.x_proj.weight\n",
      "layers.13.mixer.dt_proj.weight\n",
      "layers.13.mixer.dt_proj.bias\n",
      "layers.13.mixer.conv1d_b.weight\n",
      "layers.13.mixer.conv1d_b.bias\n",
      "layers.13.mixer.x_proj_b.weight\n",
      "layers.13.mixer.dt_proj_b.weight\n",
      "layers.13.mixer.dt_proj_b.bias\n",
      "layers.13.mixer.out_proj.weight\n",
      "layers.13.norm.weight\n",
      "layers.13.norm.bias\n",
      "layers.14.mixer.A_log\n",
      "layers.14.mixer.D\n",
      "layers.14.mixer.A_b_log\n",
      "layers.14.mixer.D_b\n",
      "layers.14.mixer.in_proj.weight\n",
      "layers.14.mixer.conv1d.weight\n",
      "layers.14.mixer.conv1d.bias\n",
      "layers.14.mixer.x_proj.weight\n",
      "layers.14.mixer.dt_proj.weight\n",
      "layers.14.mixer.dt_proj.bias\n",
      "layers.14.mixer.conv1d_b.weight\n",
      "layers.14.mixer.conv1d_b.bias\n",
      "layers.14.mixer.x_proj_b.weight\n",
      "layers.14.mixer.dt_proj_b.weight\n",
      "layers.14.mixer.dt_proj_b.bias\n",
      "layers.14.mixer.out_proj.weight\n",
      "layers.14.norm.weight\n",
      "layers.14.norm.bias\n",
      "layers.15.mixer.A_log\n",
      "layers.15.mixer.D\n",
      "layers.15.mixer.A_b_log\n",
      "layers.15.mixer.D_b\n",
      "layers.15.mixer.in_proj.weight\n",
      "layers.15.mixer.conv1d.weight\n",
      "layers.15.mixer.conv1d.bias\n",
      "layers.15.mixer.x_proj.weight\n",
      "layers.15.mixer.dt_proj.weight\n",
      "layers.15.mixer.dt_proj.bias\n",
      "layers.15.mixer.conv1d_b.weight\n",
      "layers.15.mixer.conv1d_b.bias\n",
      "layers.15.mixer.x_proj_b.weight\n",
      "layers.15.mixer.dt_proj_b.weight\n",
      "layers.15.mixer.dt_proj_b.bias\n",
      "layers.15.mixer.out_proj.weight\n",
      "layers.15.norm.weight\n",
      "layers.15.norm.bias\n",
      "layers.16.mixer.A_log\n",
      "layers.16.mixer.D\n",
      "layers.16.mixer.A_b_log\n",
      "layers.16.mixer.D_b\n",
      "layers.16.mixer.in_proj.weight\n",
      "layers.16.mixer.conv1d.weight\n",
      "layers.16.mixer.conv1d.bias\n",
      "layers.16.mixer.x_proj.weight\n",
      "layers.16.mixer.dt_proj.weight\n",
      "layers.16.mixer.dt_proj.bias\n",
      "layers.16.mixer.conv1d_b.weight\n",
      "layers.16.mixer.conv1d_b.bias\n",
      "layers.16.mixer.x_proj_b.weight\n",
      "layers.16.mixer.dt_proj_b.weight\n",
      "layers.16.mixer.dt_proj_b.bias\n",
      "layers.16.mixer.out_proj.weight\n",
      "layers.16.norm.weight\n",
      "layers.16.norm.bias\n",
      "layers.17.mixer.A_log\n",
      "layers.17.mixer.D\n",
      "layers.17.mixer.A_b_log\n",
      "layers.17.mixer.D_b\n",
      "layers.17.mixer.in_proj.weight\n",
      "layers.17.mixer.conv1d.weight\n",
      "layers.17.mixer.conv1d.bias\n",
      "layers.17.mixer.x_proj.weight\n",
      "layers.17.mixer.dt_proj.weight\n",
      "layers.17.mixer.dt_proj.bias\n",
      "layers.17.mixer.conv1d_b.weight\n",
      "layers.17.mixer.conv1d_b.bias\n",
      "layers.17.mixer.x_proj_b.weight\n",
      "layers.17.mixer.dt_proj_b.weight\n",
      "layers.17.mixer.dt_proj_b.bias\n",
      "layers.17.mixer.out_proj.weight\n",
      "layers.17.norm.weight\n",
      "layers.17.norm.bias\n",
      "layers.18.mixer.A_log\n",
      "layers.18.mixer.D\n",
      "layers.18.mixer.A_b_log\n",
      "layers.18.mixer.D_b\n",
      "layers.18.mixer.in_proj.weight\n",
      "layers.18.mixer.conv1d.weight\n",
      "layers.18.mixer.conv1d.bias\n",
      "layers.18.mixer.x_proj.weight\n",
      "layers.18.mixer.dt_proj.weight\n",
      "layers.18.mixer.dt_proj.bias\n",
      "layers.18.mixer.conv1d_b.weight\n",
      "layers.18.mixer.conv1d_b.bias\n",
      "layers.18.mixer.x_proj_b.weight\n",
      "layers.18.mixer.dt_proj_b.weight\n",
      "layers.18.mixer.dt_proj_b.bias\n",
      "layers.18.mixer.out_proj.weight\n",
      "layers.18.norm.weight\n",
      "layers.18.norm.bias\n",
      "layers.19.mixer.A_log\n",
      "layers.19.mixer.D\n",
      "layers.19.mixer.A_b_log\n",
      "layers.19.mixer.D_b\n",
      "layers.19.mixer.in_proj.weight\n",
      "layers.19.mixer.conv1d.weight\n",
      "layers.19.mixer.conv1d.bias\n",
      "layers.19.mixer.x_proj.weight\n",
      "layers.19.mixer.dt_proj.weight\n",
      "layers.19.mixer.dt_proj.bias\n",
      "layers.19.mixer.conv1d_b.weight\n",
      "layers.19.mixer.conv1d_b.bias\n",
      "layers.19.mixer.x_proj_b.weight\n",
      "layers.19.mixer.dt_proj_b.weight\n",
      "layers.19.mixer.dt_proj_b.bias\n",
      "layers.19.mixer.out_proj.weight\n",
      "layers.19.norm.weight\n",
      "layers.19.norm.bias\n",
      "layers.20.mixer.A_log\n",
      "layers.20.mixer.D\n",
      "layers.20.mixer.A_b_log\n",
      "layers.20.mixer.D_b\n",
      "layers.20.mixer.in_proj.weight\n",
      "layers.20.mixer.conv1d.weight\n",
      "layers.20.mixer.conv1d.bias\n",
      "layers.20.mixer.x_proj.weight\n",
      "layers.20.mixer.dt_proj.weight\n",
      "layers.20.mixer.dt_proj.bias\n",
      "layers.20.mixer.conv1d_b.weight\n",
      "layers.20.mixer.conv1d_b.bias\n",
      "layers.20.mixer.x_proj_b.weight\n",
      "layers.20.mixer.dt_proj_b.weight\n",
      "layers.20.mixer.dt_proj_b.bias\n",
      "layers.20.mixer.out_proj.weight\n",
      "layers.20.norm.weight\n",
      "layers.20.norm.bias\n",
      "layers.21.mixer.A_log\n",
      "layers.21.mixer.D\n",
      "layers.21.mixer.A_b_log\n",
      "layers.21.mixer.D_b\n",
      "layers.21.mixer.in_proj.weight\n",
      "layers.21.mixer.conv1d.weight\n",
      "layers.21.mixer.conv1d.bias\n",
      "layers.21.mixer.x_proj.weight\n",
      "layers.21.mixer.dt_proj.weight\n",
      "layers.21.mixer.dt_proj.bias\n",
      "layers.21.mixer.conv1d_b.weight\n",
      "layers.21.mixer.conv1d_b.bias\n",
      "layers.21.mixer.x_proj_b.weight\n",
      "layers.21.mixer.dt_proj_b.weight\n",
      "layers.21.mixer.dt_proj_b.bias\n",
      "layers.21.mixer.out_proj.weight\n",
      "layers.21.norm.weight\n",
      "layers.21.norm.bias\n",
      "layers.22.mixer.A_log\n",
      "layers.22.mixer.D\n",
      "layers.22.mixer.A_b_log\n",
      "layers.22.mixer.D_b\n",
      "layers.22.mixer.in_proj.weight\n",
      "layers.22.mixer.conv1d.weight\n",
      "layers.22.mixer.conv1d.bias\n",
      "layers.22.mixer.x_proj.weight\n",
      "layers.22.mixer.dt_proj.weight\n",
      "layers.22.mixer.dt_proj.bias\n",
      "layers.22.mixer.conv1d_b.weight\n",
      "layers.22.mixer.conv1d_b.bias\n",
      "layers.22.mixer.x_proj_b.weight\n",
      "layers.22.mixer.dt_proj_b.weight\n",
      "layers.22.mixer.dt_proj_b.bias\n",
      "layers.22.mixer.out_proj.weight\n",
      "layers.22.norm.weight\n",
      "layers.22.norm.bias\n",
      "layers.23.mixer.A_log\n",
      "layers.23.mixer.D\n",
      "layers.23.mixer.A_b_log\n",
      "layers.23.mixer.D_b\n",
      "layers.23.mixer.in_proj.weight\n",
      "layers.23.mixer.conv1d.weight\n",
      "layers.23.mixer.conv1d.bias\n",
      "layers.23.mixer.x_proj.weight\n",
      "layers.23.mixer.dt_proj.weight\n",
      "layers.23.mixer.dt_proj.bias\n",
      "layers.23.mixer.conv1d_b.weight\n",
      "layers.23.mixer.conv1d_b.bias\n",
      "layers.23.mixer.x_proj_b.weight\n",
      "layers.23.mixer.dt_proj_b.weight\n",
      "layers.23.mixer.dt_proj_b.bias\n",
      "layers.23.mixer.out_proj.weight\n",
      "layers.23.norm.weight\n",
      "layers.23.norm.bias\n",
      "layers.24.mixer.A_log\n",
      "layers.24.mixer.D\n",
      "layers.24.mixer.A_b_log\n",
      "layers.24.mixer.D_b\n",
      "layers.24.mixer.in_proj.weight\n",
      "layers.24.mixer.conv1d.weight\n",
      "layers.24.mixer.conv1d.bias\n",
      "layers.24.mixer.x_proj.weight\n",
      "layers.24.mixer.dt_proj.weight\n",
      "layers.24.mixer.dt_proj.bias\n",
      "layers.24.mixer.conv1d_b.weight\n",
      "layers.24.mixer.conv1d_b.bias\n",
      "layers.24.mixer.x_proj_b.weight\n",
      "layers.24.mixer.dt_proj_b.weight\n",
      "layers.24.mixer.dt_proj_b.bias\n",
      "layers.24.mixer.out_proj.weight\n",
      "layers.24.norm.weight\n",
      "layers.24.norm.bias\n",
      "layers.25.mixer.A_log\n",
      "layers.25.mixer.D\n",
      "layers.25.mixer.A_b_log\n",
      "layers.25.mixer.D_b\n",
      "layers.25.mixer.in_proj.weight\n",
      "layers.25.mixer.conv1d.weight\n",
      "layers.25.mixer.conv1d.bias\n",
      "layers.25.mixer.x_proj.weight\n",
      "layers.25.mixer.dt_proj.weight\n",
      "layers.25.mixer.dt_proj.bias\n",
      "layers.25.mixer.conv1d_b.weight\n",
      "layers.25.mixer.conv1d_b.bias\n",
      "layers.25.mixer.x_proj_b.weight\n",
      "layers.25.mixer.dt_proj_b.weight\n",
      "layers.25.mixer.dt_proj_b.bias\n",
      "layers.25.mixer.out_proj.weight\n",
      "layers.25.norm.weight\n",
      "layers.25.norm.bias\n",
      "layers.26.mixer.A_log\n",
      "layers.26.mixer.D\n",
      "layers.26.mixer.A_b_log\n",
      "layers.26.mixer.D_b\n",
      "layers.26.mixer.in_proj.weight\n",
      "layers.26.mixer.conv1d.weight\n",
      "layers.26.mixer.conv1d.bias\n",
      "layers.26.mixer.x_proj.weight\n",
      "layers.26.mixer.dt_proj.weight\n",
      "layers.26.mixer.dt_proj.bias\n",
      "layers.26.mixer.conv1d_b.weight\n",
      "layers.26.mixer.conv1d_b.bias\n",
      "layers.26.mixer.x_proj_b.weight\n",
      "layers.26.mixer.dt_proj_b.weight\n",
      "layers.26.mixer.dt_proj_b.bias\n",
      "layers.26.mixer.out_proj.weight\n",
      "layers.26.norm.weight\n",
      "layers.26.norm.bias\n",
      "layers.27.mixer.A_log\n",
      "layers.27.mixer.D\n",
      "layers.27.mixer.A_b_log\n",
      "layers.27.mixer.D_b\n",
      "layers.27.mixer.in_proj.weight\n",
      "layers.27.mixer.conv1d.weight\n",
      "layers.27.mixer.conv1d.bias\n",
      "layers.27.mixer.x_proj.weight\n",
      "layers.27.mixer.dt_proj.weight\n",
      "layers.27.mixer.dt_proj.bias\n",
      "layers.27.mixer.conv1d_b.weight\n",
      "layers.27.mixer.conv1d_b.bias\n",
      "layers.27.mixer.x_proj_b.weight\n",
      "layers.27.mixer.dt_proj_b.weight\n",
      "layers.27.mixer.dt_proj_b.bias\n",
      "layers.27.mixer.out_proj.weight\n",
      "layers.27.norm.weight\n",
      "layers.27.norm.bias\n",
      "layers.28.mixer.A_log\n",
      "layers.28.mixer.D\n",
      "layers.28.mixer.A_b_log\n",
      "layers.28.mixer.D_b\n",
      "layers.28.mixer.in_proj.weight\n",
      "layers.28.mixer.conv1d.weight\n",
      "layers.28.mixer.conv1d.bias\n",
      "layers.28.mixer.x_proj.weight\n",
      "layers.28.mixer.dt_proj.weight\n",
      "layers.28.mixer.dt_proj.bias\n",
      "layers.28.mixer.conv1d_b.weight\n",
      "layers.28.mixer.conv1d_b.bias\n",
      "layers.28.mixer.x_proj_b.weight\n",
      "layers.28.mixer.dt_proj_b.weight\n",
      "layers.28.mixer.dt_proj_b.bias\n",
      "layers.28.mixer.out_proj.weight\n",
      "layers.28.norm.weight\n",
      "layers.28.norm.bias\n",
      "layers.29.mixer.A_log\n",
      "layers.29.mixer.D\n",
      "layers.29.mixer.A_b_log\n",
      "layers.29.mixer.D_b\n",
      "layers.29.mixer.in_proj.weight\n",
      "layers.29.mixer.conv1d.weight\n",
      "layers.29.mixer.conv1d.bias\n",
      "layers.29.mixer.x_proj.weight\n",
      "layers.29.mixer.dt_proj.weight\n",
      "layers.29.mixer.dt_proj.bias\n",
      "layers.29.mixer.conv1d_b.weight\n",
      "layers.29.mixer.conv1d_b.bias\n",
      "layers.29.mixer.x_proj_b.weight\n",
      "layers.29.mixer.dt_proj_b.weight\n",
      "layers.29.mixer.dt_proj_b.bias\n",
      "layers.29.mixer.out_proj.weight\n",
      "layers.29.norm.weight\n",
      "layers.29.norm.bias\n",
      "layers.30.mixer.A_log\n",
      "layers.30.mixer.D\n",
      "layers.30.mixer.A_b_log\n",
      "layers.30.mixer.D_b\n",
      "layers.30.mixer.in_proj.weight\n",
      "layers.30.mixer.conv1d.weight\n",
      "layers.30.mixer.conv1d.bias\n",
      "layers.30.mixer.x_proj.weight\n",
      "layers.30.mixer.dt_proj.weight\n",
      "layers.30.mixer.dt_proj.bias\n",
      "layers.30.mixer.conv1d_b.weight\n",
      "layers.30.mixer.conv1d_b.bias\n",
      "layers.30.mixer.x_proj_b.weight\n",
      "layers.30.mixer.dt_proj_b.weight\n",
      "layers.30.mixer.dt_proj_b.bias\n",
      "layers.30.mixer.out_proj.weight\n",
      "layers.30.norm.weight\n",
      "layers.30.norm.bias\n",
      "layers.31.mixer.A_log\n",
      "layers.31.mixer.D\n",
      "layers.31.mixer.A_b_log\n",
      "layers.31.mixer.D_b\n",
      "layers.31.mixer.in_proj.weight\n",
      "layers.31.mixer.conv1d.weight\n",
      "layers.31.mixer.conv1d.bias\n",
      "layers.31.mixer.x_proj.weight\n",
      "layers.31.mixer.dt_proj.weight\n",
      "layers.31.mixer.dt_proj.bias\n",
      "layers.31.mixer.conv1d_b.weight\n",
      "layers.31.mixer.conv1d_b.bias\n",
      "layers.31.mixer.x_proj_b.weight\n",
      "layers.31.mixer.dt_proj_b.weight\n",
      "layers.31.mixer.dt_proj_b.bias\n",
      "layers.31.mixer.out_proj.weight\n",
      "layers.31.norm.weight\n",
      "layers.31.norm.bias\n",
      "norm_f.weight\n",
      "norm_f.bias\n"
     ]
    }
   ],
   "source": [
    "for name, val in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_groups(\n",
    "        model, weight_decay=1e-5, skip_list=(), get_num_layer=None, \n",
    "        get_layer_scale=None,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    paramters를 그룹으로 나누어 각 그룹별로 다른 weight decay와 lr을 적용하는 dictionary 생성 및 반환 \n",
    "    \"\"\"\n",
    "    parameter_group_names = {}\n",
    "    parameter_group_vars = {}\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # frozen weights\n",
    "        # bias이거나 decay를 적용하지 않는 파라미터인 경우\n",
    "        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list: \n",
    "            group_name = \"no_decay\"\n",
    "            this_weight_decay = 0.\n",
    "        else:\n",
    "            group_name = \"decay\"\n",
    "            this_weight_decay = weight_decay\n",
    "        if get_num_layer is not None:\n",
    "            layer_id = get_num_layer(name) # layer index\n",
    "            group_name = \"layer_%d_%s\" % (layer_id, group_name)\n",
    "        else:\n",
    "            layer_id = None\n",
    "\n",
    "        if group_name not in parameter_group_names:\n",
    "            if get_layer_scale is not None:\n",
    "                scale = get_layer_scale(layer_id)\n",
    "            else:\n",
    "                # 아닐 경우는 1로 사용\n",
    "                scale = 1.\n",
    "            \n",
    "            parameter_group_names[group_name] = {\n",
    "                \"weight_decay\": this_weight_decay,\n",
    "                \"params\": [],\n",
    "                \"lr_scale\": scale\n",
    "            }\n",
    "            parameter_group_vars[group_name] = {\n",
    "                \"weight_decay\": this_weight_decay,\n",
    "                \"params\": [],\n",
    "                \"lr_scale\": scale\n",
    "            }\n",
    "\n",
    "        parameter_group_names[group_name][\"params\"].append(name)\n",
    "        parameter_group_vars[group_name][\"params\"].append(param)\n",
    "    return list(parameter_group_vars.values()) # 각 파라미터의 감쇠율을 list로 wrapping된 dictionary 형태로 반환\n",
    "\n",
    "def get_num_layer_for_videomamba(var_name, num_max_layer):\n",
    "    if var_name in (\"cls_token\", \"pos_embed\", \"temporal_pos_embedding\"):\n",
    "        return 0\n",
    "    elif var_name.startswith(\"patch_embed\") or var_name.startswith(\"head\") or var_name.startswith(\"norm_f\"):\n",
    "        return 0\n",
    "    elif var_name.startswith(\"layers\"): # for VideoMamba\n",
    "        layer_id = int(var_name.split('.')[1])\n",
    "        if 'mixer' in var_name:\n",
    "            return layer_id + 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return num_max_layer\n",
    "\n",
    "class LayerDecayValueAssigner(object):\n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "\n",
    "    def get_scale(self, layer_id):\n",
    "        return self.values[layer_id]\n",
    "\n",
    "    def get_layer_id(self, var_name):\n",
    "        return get_num_layer_for_videomamba(var_name, len(self.values))\n",
    "\n",
    "import math\n",
    "\n",
    "def wd_scheduler(base_value, final_value, start_epoch, epochs, warmup_epochs=0, start_warmup_wd=0.):\n",
    "    \"\"\"\n",
    "    base_value: 최대값\n",
    "    final_value: 최종값\n",
    "\n",
    "    warmup과 관련된 parameter에 값이 전달 되면 lr, 아니면 wd\n",
    "    \"\"\"\n",
    "    warmup_schedule = np.array([])\n",
    "    if start_warmup_wd != 0:\n",
    "        print(\"Set warmup steps = %d\" % warmup_epochs)\n",
    "    else:\n",
    "        pass\n",
    "    if warmup_epochs > 0:\n",
    "        # warmup의 처음 lr에서 base_value까지를 선형으로 설정\n",
    "        warmup_schedule = np.linspace(start_warmup_wd, base_value, warmup_epochs)\n",
    "\n",
    "    # warmup을 제외한 본 학습의 step 수\n",
    "    iters = np.arange(epochs - warmup_epochs)\n",
    "\n",
    "    # 본 학습의 schedule\n",
    "    # 진폭: 0.5 * (base_value - final_value), 주기: 2 * pi * n_iters\n",
    "    schedule = np.array(\n",
    "        [final_value + 0.5 * (base_value - final_value) * (1 + math.cos(math.pi * i / (len(iters)))) for i in iters]\n",
    "    )\n",
    "\n",
    "    # 전체 학습의 schedule\n",
    "    schedule = np.concatenate((warmup_schedule, schedule))\n",
    "\n",
    "    assert len(schedule) == epochs # 유효성 확인\n",
    "    return np.asarray(schedule[start_epoch:epochs + 1])\n",
    "\n",
    "class CosineAnnealingWarmUpRestarts():\n",
    "    def __init__(self,base_lr, max_lr, T_0, T_mul, T_up, gamma, n_iters_per_epoch, last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mul < 1 or not isinstance(T_mul, int):\n",
    "            raise ValueError(\"Expected integer T_mul >= 1, but got {}\".format(T_mul))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        \n",
    "        self.T_0 = T_0\n",
    "        self.T_mul = T_mul\n",
    "        self.base_max_lr = max_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        self.base_lr = base_lr\n",
    "        self.n_iter_per_epoch = n_iters_per_epoch\n",
    "        self.last_epoch = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__()\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lr\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return (self.max_lr - self.base_lr) * self.T_cur / self.T_up + self.base_lr \n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = self.T_0 * self.T_mul ** self.cycle\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mul == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mul - 1) + 1), self.T_mul))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mul ** n - 1) / (self.T_mul - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mul ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "    \n",
    "    def get_lrs(self, last_epoch, epochs):\n",
    "        scheduler = []\n",
    "        for _ in range(epochs):\n",
    "            self.step()\n",
    "            scheduler.append(self.get_lr())\n",
    "        \n",
    "        return scheduler[(last_epoch + 1) * self.n_iter_per_epoch:(epochs + 1) * self.n_iter_per_epoch]\n",
    "\n",
    "\n",
    "assigner = LayerDecayValueAssigner(list(.9 ** i for i in range(32 + 1)))\n",
    "param_groups = get_parameter_groups(model, 0.1, model.no_weight_decay(), assigner.get_layer_id, assigner.get_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "update_freq = 64\n",
    "n_samples = 2\n",
    "n_frames = 1\n",
    "lr = 6e-7 * batch_size * update_freq * 2 * n_samples / 256\n",
    "min_lr = 1e-8 * batch_size * update_freq * 2 * n_samples / 256\n",
    "warmup_lr = 1e-7 * batch_size * update_freq * 2 * n_samples / 256\n",
    "\n",
    "\n",
    "lr_scheduler = CosineAnnealingWarmUpRestarts(warmup_lr, lr, 20, 2, 5, 0.5, 30, -1)\n",
    "lr_schedule_values = lr_scheduler.get_lrs(-1, 120)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(lr_schedule_values)), lr_schedule_values)\n",
    "plt.title(\"Cosine annealing scheduler\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4e-07,\n",
       " 8e-07,\n",
       " 1.2e-06,\n",
       " 1.6e-06,\n",
       " 2e-06,\n",
       " 2.4e-06,\n",
       " 2.3781476007338054e-06,\n",
       " 2.3135454576426007e-06,\n",
       " 2.2090169943749476e-06,\n",
       " 2.069130606358858e-06,\n",
       " 1.9e-06,\n",
       " 1.7090169943749473e-06,\n",
       " 1.5045284632676535e-06,\n",
       " 1.2954715367323466e-06,\n",
       " 1.0909830056250526e-06,\n",
       " 9.000000000000002e-07,\n",
       " 7.30869393641142e-07,\n",
       " 5.909830056250526e-07,\n",
       " 4.86454542357399e-07,\n",
       " 4.218523992661943e-07,\n",
       " 4e-07,\n",
       " 5.599999999999999e-07,\n",
       " 7.2e-07,\n",
       " 8.799999999999999e-07,\n",
       " 1.04e-06,\n",
       " 1.2e-06,\n",
       " 1.1983897175980956e-06,\n",
       " 1.1935718354394518e-06,\n",
       " 1.1855851442783412e-06,\n",
       " 1.1744939482558948e-06,\n",
       " 1.1603875471609676e-06,\n",
       " 1.1433795174407465e-06,\n",
       " 1.123606797749979e-06,\n",
       " 1.1012285864014444e-06,\n",
       " 1.0764250595947458e-06,\n",
       " 1.0493959207434934e-06,\n",
       " 1.020358792580841e-06,\n",
       " 9.895474649891994e-07,\n",
       " 9.572100126615694e-07,\n",
       " 9.23606797749979e-07,\n",
       " 8.890083735825257e-07,\n",
       " 8.536933063270621e-07,\n",
       " 8.17945932140206e-07,\n",
       " 7.820540678597941e-07,\n",
       " 7.463066936729378e-07,\n",
       " 7.109916264174742e-07,\n",
       " 6.76393202250021e-07,\n",
       " 6.427899873384306e-07,\n",
       " 6.104525350108005e-07,\n",
       " 5.79641207419159e-07,\n",
       " 5.506040792565066e-07,\n",
       " 5.235749404052541e-07,\n",
       " 4.987714135985557e-07,\n",
       " 4.7639320225002106e-07,\n",
       " 4.5662048255925353e-07,\n",
       " 4.3961245283903235e-07,\n",
       " 4.255060517441051e-07,\n",
       " 4.144148557216587e-07,\n",
       " 4.064281645605481e-07,\n",
       " 4.0161028240190435e-07,\n",
       " 4e-07,\n",
       " 4.3999999999999997e-07,\n",
       " 4.8e-07,\n",
       " 5.2e-07,\n",
       " 5.599999999999999e-07,\n",
       " 6e-07,\n",
       " 5.999122830098858e-07,\n",
       " 5.996492859249504e-07,\n",
       " 5.992114701314478e-07,\n",
       " 5.985996037070505e-07,\n",
       " 5.978147600733806e-07,\n",
       " 5.968583161128631e-07,\n",
       " 5.957319497532067e-07,\n",
       " 5.944376370237481e-07,\n",
       " 5.929776485888251e-07,\n",
       " 5.913545457642601e-07,\n",
       " 5.895711760239413e-07,\n",
       " 5.876306680043863e-07,\n",
       " 5.855364260160506e-07,\n",
       " 5.8329212407101e-07,\n",
       " 5.809016994374948e-07,\n",
       " 5.78369345732584e-07,\n",
       " 5.756995055651756e-07,\n",
       " 5.728968627421412e-07,\n",
       " 5.699663340513366e-07,\n",
       " 5.669130606358858e-07,\n",
       " 5.637423989748689e-07,\n",
       " 5.604599114862375e-07,\n",
       " 5.570713567684431e-07,\n",
       " 5.535826794978997e-07,\n",
       " 5.5e-07,\n",
       " 5.463296035119862e-07,\n",
       " 5.425779291565072e-07,\n",
       " 5.387515586452103e-07,\n",
       " 5.348572047321816e-07,\n",
       " 5.309016994374947e-07,\n",
       " 5.268919820615265e-07,\n",
       " 5.228350870110655e-07,\n",
       " 5.187381314585725e-07,\n",
       " 5.146083028562411e-07,\n",
       " 5.104528463267654e-07,\n",
       " 5.062790519529313e-07,\n",
       " 5.020942419883357e-07,\n",
       " 4.979057580116643e-07,\n",
       " 4.937209480470687e-07,\n",
       " 4.895471536732347e-07,\n",
       " 4.853916971437589e-07,\n",
       " 4.812618685414275e-07,\n",
       " 4.771649129889344e-07,\n",
       " 4.731080179384734e-07,\n",
       " 4.690983005625052e-07,\n",
       " 4.651427952678185e-07,\n",
       " 4.612484413547897e-07,\n",
       " 4.5742207084349274e-07,\n",
       " 4.536703964880138e-07,\n",
       " 4.5e-07,\n",
       " 4.4641732050210034e-07,\n",
       " 4.4292864323155685e-07,\n",
       " 4.395400885137625e-07,\n",
       " 4.36257601025131e-07]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_schedule_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4e-06, 120)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lr_schedule_values), len(lr_schedule_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set warmup steps = 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGxCAYAAABBZ+3pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABXFElEQVR4nO3dd3hUVcIG8HdKZiZ1SJ0U0mmBUBNESiiKQZoL4oKgoAuuH5aVIrtSdHWxxFVXWVcBZcHVVYRVBBUQCVKkBJGQANJLGiE9JJM6KXO+P5KZOCZAJpkGeX/PMw/kzpk7Z04g981pVyKEECAiIiJyYFJ7V4CIiIjoZhhYiIiIyOExsBAREZHDY2AhIiIih8fAQkRERA6PgYWIiIgcHgMLEREROTwGFiIiInJ4DCxERETk8BhYiK7jyy+/hEQiwcaNG5s917dvX0gkEnz//ffNnouMjMSAAQPMeq9HH30UYWFhbarnSy+9BIlEgsLCwpuWfe2117Bly5Y2vY9Beno6JBIJ/vOf/7TrPLcLiUSCp59+2urvs3fvXkgkEuzdu9fs1/J7RrcDBhai6xg5ciQkEgn27Nljcry4uBgnT56Eq6trs+euXLmCy5cvY9SoUWa91wsvvIDNmze3u843Y4nAQkRkD3J7V4DIUfn4+CA6OrrZb7T79u2DXC7HnDlzmgUWw9fmBpbIyMh21ZXIlmprayGRSCCX8xJCtsMeFqIbGDVqFM6dO4ecnBzjsb1792LgwIEYN24ckpOTUVZWZvKcTCZDXFwcAEAIgZUrV6Jfv35wdnaGp6cnHnjgAVy+fNnkfVoaEiopKcGcOXPg5eUFNzc3jB8/HpcvX4ZEIsFLL73UrK55eXmYPn061Go1NBoNZs+ejdLSUuPzEokEFRUV+PjjjyGRSCCRSDBy5Mgbfv6rV69i6tSpcHd3h1qtxrRp05Cbm9ti2aNHj+K+++6Dl5cXVCoV+vfvj//973/NymVnZ+Pxxx9HcHAwFAoFAgMD8cADDyAvLw8AUF1djWeffRb9+vWDWq2Gl5cXBg8ejK+//trkPHfffTd69OiB396/VQiBLl26YPz48Tf8bLt378bIkSPh7e0NZ2dnhISEYMqUKaisrDSW0el0WL58OaKioqBSqeDt7Y1Ro0bh0KFDzc733//+F1FRUXBxcUHfvn2xdevWZmUuXLiAGTNmwM/PD0qlElFRUXj//feblTt79izuvfdeuLi4wMfHB3PnzjX5d2YQFhaGRx99tNnxkSNH3vR729r6GIai/vvf/+LZZ59FUFAQlEolLl68eNPzE1kSAwvRDRh6Sn7dy7Jnzx6MGDECQ4cOhUQiwf79+02eGzBgANRqNQDg//7v/zB//nyMHj0aW7ZswcqVK3Hq1CkMGTLEeIFuiV6vx8SJE7F+/Xo899xz2Lx5MwYNGoR77733uq+ZMmUKunXrhk2bNmHx4sVYv349FixYYHw+KSkJzs7OGDduHJKSkpCUlISVK1de93xVVVUYPXo0du7ciYSEBHzxxRfw9/fHtGnTmpXds2cPhg4dipKSEqxevRpff/01+vXrh2nTppnMm8jOzsbAgQOxefNmLFy4EN999x1WrFgBtVqNa9euAWgICcXFxVi0aBG2bNmCzz//HMOGDcP999+PTz75xHiuefPm4dy5c/jhhx9M6vLdd9/h0qVLeOqpp6772dLT0zF+/HgoFAqsW7cOO3bswOuvvw5XV1fU1NQAAOrq6jB27Fi8/PLLmDBhAjZv3oz//Oc/GDJkCDIzM03Ot23bNrz33ntYvnw5Nm3aBC8vL0yePNkkmJ4+fRoDBw7EL7/8gn/84x/YunUrxo8fj2eeeQZ/+9vfjOXy8vIwYsQI/PLLL1i5ciX++9//ory83OLzZFpbH4MlS5YgMzMTq1evxrfffgs/Pz+L1ofopgQRXVdxcbGQSqXi8ccfF0IIUVhYKCQSidixY4cQQog77rhDLFq0SAghRGZmpgAg/vKXvwghhEhKShIAxD/+8Q+Tc2ZlZQlnZ2djOSGEeOSRR0RoaKjx623btgkAYtWqVSavTUhIEADEiy++aDz24osvCgDijTfeMCn75JNPCpVKJfR6vfGYq6ureOSRR1r12VetWiUAiK+//trk+B//+EcBQHz00UfGYz169BD9+/cXtbW1JmUnTJggAgICRH19vRBCiNmzZwsnJydx+vTpVtVBCCHq6upEbW2tmDNnjujfv7/xeH19vYiIiBC/+93vTMqPHTtWREZGmnzu3/ryyy8FAJGamnrdMp988okAINasWXPD+gEQGo1GaLVa47Hc3FwhlUpFQkKC8diYMWNE586dRWlpqcnrn376aaFSqURxcbEQQojnnntOSCSSZnW75557BACxZ88e47HQ0NAWv58jRowQI0aMMH6dlpbW7HvW2vrs2bNHABDDhw+/YTsQWRt7WIhuwNPTE3379jX2sOzbtw8ymQxDhw4FAIwYMcI4b+W381e2bt0KiUSChx9+GHV1dcaHv7+/yTlbsm/fPgDA1KlTTY5Pnz79uq+57777TL7u06cPqqurkZ+f3/oP/Ct79uyBu7t7s/POmDHD5OuLFy/i7NmzeOihhwDA5LOOGzcOOTk5OHfuHICG3o9Ro0YhKirqhu/9xRdfYOjQoXBzc4NcLoeTkxPWrl2LM2fOGMtIpVI8/fTT2Lp1q7HH49KlS9ixYweefPJJSCSS656/X79+UCgUePzxx/Hxxx83G6Iz1FWlUmH27Nk3rCvQ8D13d3c3fq3RaODn54eMjAwADcNcP/zwAyZPngwXF5dmbVRdXY3Dhw8DaGj3Xr16oW/fvibv8dt2bw9z6mMwZcoUi70/UVswsBDdxKhRo3D+/HlcvXoVe/bsQUxMDNzc3AA0BJaUlBSUlpZiz549kMvlGDZsGICGrn0hBDQaDZycnEwehw8fvuEy5KKiIsjlcnh5eZkc12g0132Nt7e3yddKpRJAw9BOWxQVFbX4fv7+/iZfG4a2Fi1a1OxzPvnkkwBg/KwFBQXo3LnzDd/3q6++wtSpUxEUFIRPP/0USUlJ+PnnnzF79mxUV1eblJ09ezacnZ2xevVqAMD7778PZ2fnm4aMyMhI7Nq1C35+fnjqqacQGRmJyMhI/POf/zSWKSgoQGBgIKTSm/+Y/G3bAw3tb2j7oqIi1NXV4V//+lezNho3bhyApjYqKipq1sZA83ZvD3PqYxAQEGCx9ydqC07xJrqJUaNG4e2338bevXuxd+9e4w90AMZw8uOPPxon4xrCjI+Pj3GOiyE8/FpLxwy8vb1RV1eH4uJik9ByvQmv1uDt7Y0jR440O/7bOvj4+ABomONw//33t3iu7t27AwB8fX1x5cqVG77vp59+ivDwcGzcuNGkl0Sn0zUrq1ar8cgjj+Df//43Fi1ahI8++ggzZsxAp06dbvgeABAXF4e4uDjU19fj6NGj+Ne//oX58+dDo9HgwQcfhK+vLw4cOAC9Xt+q0HIjnp6ekMlkmDlz5nXn1oSHhwNoaPeWvs8tHVOpVC22S2FhofH70t76GNyox4rIFtjDQnQTw4cPh0wmw5dffolTp06ZrL5Qq9Xo168fPv74Y6Snp5ssZ54wYQKEEMjOzkZsbGyzR+/eva/7niNGjACAZpvWbdiwoV2f5de/9d/MqFGjUFZWhm+++cbk+Pr1602+7t69O7p27Yrjx4+3+DljY2ONwyVjx47Fnj17jENELZFIJFAoFCYXyNzc3GarhAyeeeYZFBYW4oEHHkBJSYnZk1NlMhkGDRpkXB1z7NgxY12rq6ststmai4sLRo0ahZSUFPTp06fFNjL00owaNQqnTp3C8ePHTc7x23YHGlYJnThxwuTY+fPnb9i+5taHyFGwh4XoJjw8PDBgwABs2bIFUqnUOH/FYMSIEVixYgUA0/1Xhg4discffxx/+MMfcPToUQwfPhyurq7IycnBgQMH0Lt3bzzxxBMtvue9996LoUOH4tlnn4VWq0VMTAySkpKMq2Ta+ht/7969sXfvXnz77bcICAiAu7u7sffjt2bNmoV33nkHs2bNwquvvoquXbti+/btLe7u+8EHH2Ds2LEYM2YMHn30UQQFBaG4uBhnzpzBsWPH8MUXXwAAli9fju+++w7Dhw/H0qVL0bt3b5SUlGDHjh1YuHAhevTogQkTJuCrr77Ck08+iQceeABZWVl4+eWXERAQgAsXLjR7727duuHee+/Fd999h2HDhjWb+9GS1atXY/fu3Rg/fjxCQkJQXV2NdevWAQBGjx4NoGG+0EcffYS5c+fi3LlzGDVqFPR6PX766SdERUXhwQcfbHW7A8A///lPDBs2DHFxcXjiiScQFhaGsrIyXLx4Ed9++y12794NAJg/fz7WrVuH8ePH45VXXoFGo8Fnn32Gs2fPNjvnzJkz8fDDD+PJJ5/ElClTkJGRgTfeeAO+vr4Wqw+Rw7D3rF+iW8Ff/vIXAUDExsY2e27Lli0CgFAoFKKioqLZ8+vWrRODBg0Srq6uwtnZWURGRopZs2aJo0ePGsv8dpWQEA0rlP7whz+ITp06CRcXF3HPPfeIw4cPCwDin//8p7GcYZVQQUGByes/+ugjAUCkpaUZj6WmpoqhQ4cKFxcXAcBkJUlLrly5IqZMmSLc3NyEu7u7mDJlijh06FCzFSdCCHH8+HExdepU4efnJ5ycnIS/v7+46667xOrVq03KZWVlidmzZwt/f3/h5OQkAgMDxdSpU0VeXp6xzOuvvy7CwsKEUqkUUVFRYs2aNcbP2ZL//Oc/AoDYsGHDDT+PQVJSkpg8ebIIDQ0VSqVSeHt7ixEjRohvvvnGpFxVVZX461//Krp27SoUCoXw9vYWd911lzh06JCxDADx1FNPNXuPllbwpKWlidmzZ4ugoCDh5OQkfH19xZAhQ8Qrr7xiUu706dPinnvuESqVSnh5eYk5c+aIr7/+utkqIb1eL9544w0REREhVCqViI2NFbt3727VKqHW1sewSuiLL75oVdsSWYtEiN/sukREDmv9+vV46KGHcPDgQQwZMsTe1XEYU6ZMweHDh5Geng4nJyd7V4eIrIBDQkQO6vPPP0d2djZ69+4NqVSKw4cP480338Tw4cMZVtAwCffYsWM4cuQINm/ejLfffpthheg2xh4WIge1detWvPTSS7h48SIqKioQEBCASZMm4ZVXXoGHh4e9q2d36enpCA8Ph4eHB2bMmIH33nsPMpnM3tUiIithYCEiIiKHx2XNRERE5PAYWIiIiMjhMbAQERGRw7ttVgnp9XpcvXoV7u7u3EKaiIjoFiGEQFlZ2U3v3XXbBJarV68iODjY3tUgIiKiNsjKyrrhzVFvm8BiuFdJVlYWl3wSERHdIrRaLYKDg43X8eu5bQKLYRjIw8ODgYWIiOgWc7PpHJx0S0RERA6PgYWIiIgcHgMLEREROTwGFiIiInJ4DCxERETk8BhYiIiIyOExsBAREZHDY2AhIiIih8fAQkRERA6PgYWIiIgcHgMLEREROTwGFiIiInJ4t83NDx1RdkkVPj2cgeraepPjEkggkQASADKpBHKZBHKpFE4yCZxkUijlUijkMijlUjgrZHB2ksFZIYOLQgY3pbzhoZLD2Ul205tFERER3Q4YWKxo1d6L+PRwptXOL5UAHs5OUP/q4eWqgKdLw8PLTQFfNwW83ZTwcVPCz10JVyW/5UREdOvh1cuKiitqAADDu/mid5AHAEAIQDT+qRcCer1AnV6gTq9HXb1ATb0eujo9auoa/qyuqUdlbR2qaupRWVOPcl0dynV1ja8HSiprUVJZ2+o6uSpk0Hio4OehRIDaGf5qFQLVKgSonRHk2fDwUDlZozmIiIjajIHFiip0DUNBE/sE4PexwRY7rxACVbX10FbVQVtdC21VLUqrGoLLtcoaXKusQXFFLYrKdSiqqEFhuQ6FZTpU1NSjoqYelwsrcLmw4rrn91DJEezlgpDGR7CXC8K8XRHm44JAtTOkUg5DERGRbTGwWFFVTUNgcVFYtpklEglcFHK4KOTwV6ta/boKXR3yy3TI01YjT1uNnNJq5JZW42pJFa6WViH7WhWuVdZCW12HU1e1OHVV2+wcCrkUYd4uiPBxQ6SfKyJ93dDFzw2Rvm4cbiIiIqvhFcaKKmrqAAAuSpmda9LAVSlHuFKOcB/X65ap0NUhu6QKWcWVyDQ8iiqRVlSBrOJK1NTpcT6vHOfzyoFTpq/t7OmMrn5u6Obvjh7+7ujh74FIXzco5FyMRkRE7cPAYkXGHhYnxwgsreGqlKObxh3dNO7Nnqur1+NqSTUuF5bjckEFLhWU41JBOS7ml6OwvAZXrlXhyrUq7DlXYHyNXCpBFz839AzwQM/AhkevADXULpwnQ0RErcfAYkWGHpbbZahELpMixNsFId4uGNnd9LniihpcyCvD+fxynM8tw9lcLc7mlqGsug5nc8twNrcMX6VkG8uHersgOkiN3kFq9Onc8Kc7J/sSEdF13B5XUgdV2djD4qy4dXpY2srLVYFBEd4YFOFtPCaEwNXSapxpnA9zOqcUp65qceVaFTKKKpFRVIltJ3IAABIJ0MXXDX2DO6F/SCf0D/ZEN40b5DIOJxEREQOL1QghjIHF1cKTbm8VEokEQZ2cEdTJGaN7aozHSypr8Eu2FiezS3EyuwTHs0qRXVKFC/nluJBfji+TrwAAXBQy9OmsRmyoF2LCPDEgxBNqZ/bCEBF1RB3zSmoDNfV61OsFgI7Rw2KOTi4KDOvqg2FdfYzHCst1OJ5VgtSsEqRkNvxZrqvD4cvFOHy5GEBDL0x3jTvuCPfCwDAv3BHuBY1H61dJERHRrYuBxUoqdU3b8bswsNyUj5sSd0dpcHdUQ09MvV7gYn45kjOu4WhGMY5lXEN6UaVxPswnSRkAgHAfVwwK98KdEd64M8LbrGXeRER062BgsRLDhFuFXAonzsMwm0wqQXd/d3T3d8eMQSEAgIIyHY6mF+OntGL8nF6M0zlapBVWIK2wAht+zgIARPi4YnCkN4ZE+mBwpDe8XBX2/BhERGQhDCxW0rRpHHtXLMXXXYmxvQMwtncAAEBbXYuj6cWNw0ZF+CW71LiL72c/ZUIiAXoFemBoFx/EdfFFbJgnVLfQEnMiImrCwGIlFR18wq0teKiccFcPDe7q0TCMVFpViyNpxTh4sRCHLhXifF45fsnW4pdsLT7YdxlKuRSDIrwxvKsPRnTzRRc/N97tmojoFsGrqZVUNg4JccKt7aidnXBPTw3uaVyRlF9WjYMXC7H/QiEOXChEfpkOP54vwI/nC/DKtjMI6uSMEd19MbKbL4Z28blt9sshIrod8Se0lRgm3boysNiNn7sKk/t3xuT+nSGEwPm88obAcqEAP6UVI7ukCut/ysT6nzLhJJNgULg37urhh7t6+CHsBrcvICIi22NgsZLK2o6zadytQCJpmsT7x+ERqKqpx+HLRdhzLh97zuUjq7gKBy4W4sDFQizfehoRvq64J0qD0T01GBDiCRnvUE1EZFcMLFZSqWvclp9zWBySs0KGUT38MKqHH4QQuFRQgT1n87H7bD5+Ti/G5YIKfFBwGR/8eBlergqM6u6H+F4aDO/qyxBKRGQHvJpaSUfalv9WJ5E03KCxi58b/jg8AtrqWvx4vgA/nGkIMMUVNdh07Ao2HbsClZMUw7r4YkwvDUZHaeDJZdNERDbBwGIlhkm37GG59XionDChTyAm9AlEXb0eP6dfw64zefj+VC6uXKvCrjN52HUmDzKpBHdGeOHeXv6I7+XPXXeJiKyIV1MrMfSwuCjZw3Irk8ukGBzpjcGR3nh+fBTO5pbh+1O5+P5UHs7kaHHwYhEOXizCX785hdhQT4yNDsC90f4I7ORs76oTEd1W2rQF68qVKxEeHg6VSoWYmBjs37//umVzcnIwY8YMdO/eHVKpFPPnz7/huTds2ACJRIJJkya1pWoOo5Ibx912JBIJogI8MH90N3w3Lw77/jwSS8f1QL/gThAC+Dn9GpZvPY0hr+/G/SsPYu2BNOSUVtm72kREtwWzA8vGjRsxf/58LFu2DCkpKYiLi8PYsWORmZnZYnmdTgdfX18sW7YMffv2veG5MzIysGjRIsTFxZlbLYdT0Tjp1oVDQretUG9XPD48ElueGopDi+/CXyf0xB1hXpBIgGOZJXh562kMTtiNB1Ydwn8OpiG/rNreVSYiumVJhBDCnBcMGjQIAwYMwKpVq4zHoqKiMGnSJCQkJNzwtSNHjkS/fv2wYsWKZs/V19djxIgR+MMf/oD9+/ejpKQEW7Zsue65dDoddDqd8WutVovg4GCUlpbCw8PDnI9kFU+tP4ZtJ3Lw4sSe+MPQcHtXh2woT1uN707mYNvJHBzNuAbD/zCpBLgzwhsT+gRiXG9/dHLhhF0iIq1WC7VafdPrt1k9LDU1NUhOTkZ8fLzJ8fj4eBw6dKhtNW20fPly+Pr6Ys6cOa0qn5CQALVabXwEBwe36/0tjcuaOy6NhwqPDg3HF3OHIGnx3fjrhJ7oH9IJegEculSEpZtPYuCru/DYxz/j69Rs4wRtIiK6PrOupoWFhaivr4dGozE5rtFokJub2+ZKHDx4EGvXrkVqamqrX7NkyRIsXLjQ+LWhh8VRcFkzAYC/WoXZw8Ixe1g4soor8e2Jq/j2eA7O5Gix60w+dp3Jh4tChjG9/DGpfxCGRnpDzrt7ExE106Zf/397wzghRJtvIldWVoaHH34Ya9asgY+PT6tfp1QqoVQq2/SetmAILK5cJUSNgr1c8OTILnhyZBdcyCvDN8ev4uvUq8gsrsTmlGxsTsmGj5sSE/sG4P7+nREd5MGbMxIRNTIrsPj4+EAmkzXrTcnPz2/W69Jaly5dQnp6OiZOnGg8ptfrGyonl+PcuXOIjIxs07ntyXjzQycOCVFzXTXueDa+Oxbe0w0pWSX4OiUb357IQWG5Dh8dTMdHB9PRxc8Nk/sHYXL/IC6TJqIOz6yrqUKhQExMDBITEzF58mTj8cTERPzud79rUwV69OiBkydPmhx7/vnnUVZWhn/+858ONcxjDvawUGtIJBIMCPHEgBBPPD+hJ/ZfKMBXx7KReDoPF/PL8eb35/DWznMYEumN+/t3xr3R/ryrNBF1SGb/5Fu4cCFmzpyJ2NhYDB48GB9++CEyMzMxd+5cAA1zS7Kzs/HJJ58YX2OYm1JeXo6CggKkpqZCoVCgZ8+eUKlUiI6ONnmPTp06AUCz47eSpn1YeHGh1nGSSXFXDw3u6qGBtroWO37JxVfHruDw5WLjBnUvfP0LxvUOwAMxnXFHmBekvCkjEXUQZl9Np02bhqKiIixfvhw5OTmIjo7G9u3bERoaCqBho7jf7snSv39/49+Tk5Oxfv16hIaGIj09vX21d2CGISFuHEdt4aFywtTYYEyNDUZWcSW2pGRj07ErSC+qxJfJV/Bl8hUEezljyoDOeCCmMzp7uti7ykREVmX2PiyOqrXruG2hpk6Pbs9/BwA4/td4qF2c7Fofuj0IIZCccQ1fJl/B1hM5KG9cOi+RAEMjffD72M4Y08sfKieGZCK6dbT2+s3xCiuoahwOArismSxHIpEgNswLsWFeeHFiL+w4lYMvjl7BoUtFOHCxEAcuFsJDJcek/kGYGhuM6CC1vatMRGQxDCxWUNE4HOQkk0Ah554aZHnOChkm9++Myf07I6u4aZgou6QKnyRl4JOkDPQM8MCDdwTjd/2CoHZmLx8R3do4JGQFF/PLMfrtffBQyXHipTF2rQt1HHq9wMFLhdj4cxZ2nspDTX3D9gBKuRTjewdg2sBg3BHuxb1diMihcEjIjgwTbrn8lGxJKpUgrqsv4rr64lpFDbakZmPDkSycyyvDVynZ+ColGxG+rpg+MARTYjrDy5X3MiKiWwevqFbAbfnJ3jxdFfjD0HA8OiQMqVkl2HAkC9+euIrLBRV4dfsZvPn9OcT30mDGoBAMjvBmrwsROTwGFisw9rBwDxayM4lEgv4hnugf4okXJvbEN6lX8fmRTJzMLsXWEznYeiIH4T6umH5HMB6ICWavCxE5LF5RraBp0zj2sJDjcFPKMWNQCGYMCsEv2aVYfyQTX6dkI62wAq9tP4u3vj+Pcb398dCdoYgN9WSvCxE5FAYWK6jUMbCQY4sOUuO1yb2xbFwUvjl+Fet/auh12ZJ6FVtSr6KrnxseGhSC+2M6w0PFFUZEZH8MLFZg3OWWk27Jwbkq5Zh+Rwim3xGCE1dKsP6nTHydehUX8svx0ren8fcd5/C7foF4aFAoenfmvi5EZD+8olpBhWFIiDuO0i2kT+dO6NO5E5aOj8LmY9n47KcMnM8rx4afs7Dh5yz0De6EmXeGYkKfAO6mS0Q2x8BiBVzWTLcyD5UTHhkShlmDQ/Fz+jV89lMGtp/MwfGsEhzPKsEr207j9zGd8dCgUIT5uNq7ukTUQfCKagVc1ky3A4lEgjvCvXBHuBdemNAT/zuahc8OZyK7pApr9qdhzf40jOjmi1mDQzGyux9kvHM0EVkRA4sVGCbdujKw0G3Cx02JJ0d2wf8Nj8Tec/n47+EM7D1XgH3nGx6dPZ3x8J2hmBYbDE8ujSYiK2BgsYLKWkMPC5uXbi8yqQR3R2lwd5QGGUUV+PRwBv539AquXKvC69+dxTuJ5zGxbyAeGRzGSbpEZFG8olpBpc6wcRx7WOj2FertimXje2LhPd3x7fGr+ORwOn7J1hpvxNg/pBMeGRyGsb39oZTz/wIRtQ8DixUYN47jpFvqAJwVMkwdGIzfx3ZGSlYJPjmUjm0nc5CSWYKUzFS8sk2B6XeE4KFBofBXq+xdXSK6RfGKagXGfVi49JM6EIlEggEhnhgQ4oll43tiw5FMfPZTJnK11fjX7otYtfcSxkT745HBYRgYxp10icg8DCxW0NTDwsBCHZOvuxJ/ursr5o6MxM5Tefg4KR1H0oqx7UQOtp3IQc8ADzwyJBS/6xfEPV2IqFWk9q7A7ajpXkLMg9SxOcmkGN8nAP/7v8HY/kwcHhwYDKVcitM5Wjy36STuTPgBr393FtklVfauKhE5OAYWK2i6WzN/cyQy6Bnogden9MFPS+/GkrE9ENTJGSWVtVi97xLi/r4bc/+bjMOXiyCEsHdVicgBsQvACiq4cRzRdXVyUeD/RkTisbgI/HCmYbjo4MUi7DiVix2nctHD3x1/GBrG4SIiMsHAYmF19XrU1OkBAK4cEiK6LplUgvhe/ojv5Y9zuWX4OCkdXx27grO5ZXhu00m8/t1ZPHhHCGbeGYrATs72ri4R2RmHhCzMsGkcwB4Wotbq7u+O1yb3xk9LRmPpuIbhomuVtVi19xLi3tiDpz47hp/TizlcRNSBsQvAwgzb8sukEijlzINE5lC7OOHx4ZGYMywCu87k4aODaTh8uRjbTuZg28kc9Ar0wKNDwjCxbyCHi4g6GF5RLcy4B4tCxn0miNpIJpVgTC9/bHh8MHbMb1pddOqqFn/+8gSGvr4b/9h5DnnaantXlYhshIHFwpqWNPO3PyJL6OHfsLro8JK78Zd7uyNArUJRRQ3+tfsihr6+G898noKUzGv2riYRWRmHhCzMEFg44ZbIsjxdFXhyZBc8HheB7081DBcdzbiGb45fxTfHr6JfcCf8YWgYxvUOgJOMv4sR3W74v9rCKhqHhDjhlsg65I2b0X35xBB8+/Qw3D8gCAqZFKlZJZi3IRXD/r4b7+2+gKJynb2rSkQWxMBiYVXsYSGymd6d1Xh7aj8cXHwXFozuBl93JfK0Ory18zwGv74bf/7iOE5dLbV3NYnIAnhVtbAKHXtYiGzN112JeaO74omRkdh28io+OpiOE1dK8UXyFXyRfAV3hHth9tAwjI7SQM7hIqJbEgOLhVU17sPiyhsfEtmcQi7F5P6dMalfEI5lXsNHB9Px3S+5OJJWjCNpxQjq5IxHhoRiWmwI1C5O9q4uEZmBgcXCKhr3YXF2YtMS2YtEIkFMqBdiQr2QU1qFTw9nYP1PmcguqcJr28/incQLuH9AEB4dEoauGnd7V5eIWoF9oxZmvPEhe1iIHEKA2hl/HtMDSUvuxhtT+qCHvzuqauvx2U+ZuOedHzFz7U/44Uwe9HruokvkyNgNYGGVvPEhkUNSOckwdWAwfh/bGT+lFeOjg2lIPJ2H/RcKsf9CIUK9XfDI4DA8ENsZHioOFxE5GgYWCzP2sHCVEJFDkkgkuDPCG3dGeCOruBL/PZyBDUcykVFUieVbT+MfO8/hgZjOmDUkDJG+bvauLhE14pCQhXGnW6JbR7CXC5aOi8LhpXfj1cnR6OrnhoqaenyclIG7/7EPj6w7gj1n8zlcROQA2A1gYYZJty7sYSG6Zbgo5HhoUChm3BGCQ5eK8NHBNPxwNh/7zhdg3/kChHm7YBaHi4jsqk09LCtXrkR4eDhUKhViYmKwf//+65bNycnBjBkz0L17d0ilUsyfP79ZmTVr1iAuLg6enp7w9PTE6NGjceTIkbZUze6qajnpluhWJZFIMLSLD/79yEDsWzQKjw0Lh7tKjvTG4aLBr/2AF7b8gov5ZfauKlGHY3Zg2bhxI+bPn49ly5YhJSUFcXFxGDt2LDIzM1ssr9Pp4Ovri2XLlqFv374tltm7dy+mT5+OPXv2ICkpCSEhIYiPj0d2dra51bO7pmXNDCxEt7IQbxc8P6EnDi+5Gy9PikaXxuGi/x7OwOi3G1YXJZ7OQz2Hi4hsQiKEMOt/26BBgzBgwACsWrXKeCwqKgqTJk1CQkLCDV87cuRI9OvXDytWrLhhufr6enh6euK9997DrFmzWiyj0+mg0zXdK0Sr1SI4OBilpaXw8PBo/QeysDHv/IhzeWX47LFBGNrFx271ICLLEkI0Dhel44ezeTD85Az2csbMO0MxNTYYnVwU9q0k0S1Iq9VCrVbf9PptVg9LTU0NkpOTER8fb3I8Pj4ehw4daltNW1BZWYna2lp4eXldt0xCQgLUarXxERwcbLH3bw/e/JDo9tQ0XBSLH/88Cv83PAJqZydkFTdsRndnwg9YvOkE711EZCVmBZbCwkLU19dDo9GYHNdoNMjNzbVYpRYvXoygoCCMHj36umWWLFmC0tJS4yMrK8ti798elbz5IdFtL9jLBUvGReHwkrvx9ym9ERXggepaPTb8nIXx7x7AA6sO4ZvjV1FTp7d3VYluG226qkokEpOvhRDNjrXVG2+8gc8//xx79+6FSqW6bjmlUgmlUmmR97Qkwz4sXNZMdPtzVsgwbWAIpsYG42jGNXx8KB07fsnF0YxrOJpxDb7uSky/IwQPDQqBxuP6P8+I6ObMCiw+Pj6QyWTNelPy8/Ob9bq0xVtvvYXXXnsNu3btQp8+fdp9Plur1wtU1zb8RsXAQtRxSCQSDAzzwsAwL+Rpq7H+p0ysP5KJgjId3v3hAt7fcxFjemkw884w3BnhZbFf8Ig6ErOGhBQKBWJiYpCYmGhyPDExEUOGDGlXRd588028/PLL2LFjB2JjY9t1Lnsx3KkZAFyVHBIi6og0HiosuKcbDj53F/41vT8GhnmiXi+w/WQupq85jPh3fsQnSekoq661d1WJbilmX1UXLlyImTNnIjY2FoMHD8aHH36IzMxMzJ07F0DD3JLs7Gx88sknxtekpqYCAMrLy1FQUIDU1FQoFAr07NkTQMMw0AsvvID169cjLCzM2IPj5uYGN7dbZ2vsSl3DcJBEAijl3ESYqCNTyKWY2DcQE/sG4kyOFp8ezsDmlGxcyC/HX78+hde/O4tJ/YPw8KBQ9Ay038pGoluF2cuagYaN49544w3k5OQgOjoa77zzDoYPHw4AePTRR5Geno69e/c2vUkL3Z+hoaFIT08HAISFhSEjI6NZmRdffBEvvfRSq+rU2mVR1pReWIGRb+2Fm1KOX/42xi51ICLHpa2uxVfJV/DpT5m4mF9uPB4T6omH7wzB2OgAqLiHE3Uwrb1+tymwOCJHCCynrpZi/LsH4OuuxM/Lrr/CiYg6NiEEDl8uxqc/ZeD7X3JR17j5nKeLE6bGBmP6HSEI83G1cy2JbKO1129OtLCgKuOSZv6GRETXJ5FIMDjSG4MjvZGvrcbGn7Pw+ZFMXC2txgc/XsYHP15GXFcfPDQoBHdHaeAk4xAzEQOLBVU0BhZn7sFCRK3k56HCn+7uiidGRmLPuQJ8ejgDP14owP4Lhdh/oRB+7kpMjQ3Gg3cEo7Oni72rS2Q3vLJaUFXjHizsYSEic8llUtzTU4N7emqQVVyJz49k4n9Hs5BfpsN7ey7i/b0XMaKbL2bcEYK7evhBzl4X6mAYWCzIeONDBhYiaodgLxf85d4emD+6GxJP52H9kQwcvFiEvecKsPdcATQeSvw+JhjTBgYj2Iu9LtQxMLBYEHe5JSJLUsilGN8nAOP7BCCtsAIbjmTiy+QryNM29boM6+KDBweG4J6eGii4nQLdxhhYLMh4HyFuGkdEFhbu44ol46LwbHx3JJ7Ow4afM43zXPZfKISXqwJTBgRh2sBgdPFzt3d1iSyOV1YLMky6ZQ8LEVnLr3tdMosq8b+jWfgiOQt5Wh3W7E/Dmv1pGBDSCdMGBmNCn0D+AkW3Df5LtqCmSbdsViKyvhBvFywa0x3zR3fFvvMF+PxIFvacy8exzBIcyyzB3749jfG9AzB1YDBiQz15DyO6pfHKakFNy5rZw0JEtiOXSXF3lAZ3R2mQr63GpmPZ+N/RLKQVVuCL5Cv4IvkKwn1c8UBMZ9w/IAgBamd7V5nIbAwsFtS0cRyblYjsw89DhSdGRmLuiAgczbiGL45mYeuJHKQVVuDN78/hrZ3nMKyLDx6I6Ywxvfx5KwC6ZfDKakEVjTc/ZA8LEdmbRCLBwDAvDAzzwosTe2HbyRx8mXwFR9KKjRN13VVyTOgTgPsHdOaQETk8BhYLqqo1rBJiYCEix+GqlGNqbDCmxgYjo6gCm5KvYNOxbGSXVOHzI1n4/EgWQr1dMLl/ECb3D0KoN+9jRI6HgcWCjD0sTmxWInJMod6uWBjfHfNHd8PhtCJ8dSwb20/mIKOoEit2XcCKXRcQE+qJyf2DMKFPADq5KOxdZSIADCwW1bQPC3tYiMixSaUSDIn0wZBIHyz/XS98fyoXXx3LxsGLhUjOuIbkjGv427enMLK7Hyb1C8LdUX6c70J2xcBiQZXch4WIbkEuCjkm9++Myf07I09bja9Ts7E55SrO5GiReDoPiafz4K6UY0y0P+7rG4ghkd68lxHZHAOLBTVtzc9mJaJbk8ZDhceHR+Lx4ZE4l1uGLanZ+Cb1KrJLqvBl8hV8mXwFPm4KjO8dgIl9AzEgxBNSKSfrkvVJhBDC3pWwBK1WC7VajdLSUnh4eNilDj3/ugOVNfX48c+jEOLNG5IR0e1Brxc4mnEN3xzPxrYTObhWWWt8LlCtwoS+gZjQJwC9g9RcaURma+31m4HFQvR6gYil2wEAPy8bDV93pc3rQERkbbX1ehy4UIhvj1/FztN5KG9cbAAAwV7OGN+7Ibz0CvRgeKFWae31m2MXFlJdV2/8OyfdEtHtykkmxagefhjVww/VtfXYe64A3564it1n8pFVXIXV+y5h9b5LCPFywdje/hgXHYA+ndnzQu3HwGIhFbqmwKKSM7AQ0e1P5STDvdH+uDfaH5U1ddhztgDbTl7F7rP5yCyuxAf7LuODfZcR1MkZY3o1lIsJ9YSMc16oDRhYLKTqVyuEOAGNiDoaF4XceBfpypo67D1XgO0nc7D7bD6yS6qw7mAa1h1Mg4+bAvf01CC+lz+GRHpDyV/wqJUYWCykwrhCiP/5iKhjc1HIMa53AMb1DkB1bT32nS/A96dyset0HgrLa4y767oqZBjZww/xPTUY2c0Pahcne1edHBgDi4U07cHCJiUiMlA5yTCmlz/G9PJHbb0eSZeKsPN0LnaeykN+mQ7bTuRg24kcyKQS3BHmhbuj/DA6SoMwH94egEzx6mohlexhISK6ISeZFMO7+WJ4N18svy8aJ7JLsfNULnadycP5vHIkXS5C0uUivLLtDCJ8XXF34+TegWFecOJGdR0eA4uFcJdbIqLWk0ol6BfcCf2CO+Ev9/ZARlEFdp3Jx67Tefg5vRiXCypwuSANa/anwV0px9AuPhjZ3Rcju/vBX62yd/XJDhhYLMTQw+KqZJMSEZkr1NsVc4aFY86wcGira7H/fCF2n83H3nP5KKqowY5TudhxKhcA0F3jjuHdfDC8my8GhnnxHkcdBK+uFmJY1uzM/zhERO3ioXIyrjjS6wVOZpdiz7l87D1XgONXSnAurwzn8sqwZn8aVE5SDAzzQlxXHwzr4ose/u5cqXmbYmCxkCrjnZrZpEREliKVStA3uBP6BnfC/NHdUFxRgwMXC/Hj+QLsv1CAPK0O+y8UYv+FQgBn4e2qwJ2R3hga6YMhkd4I9XbhpnW3CV5dLcSwrNmZc1iIiKzGy1WB+/oG4r6+gRBC4EJ+OfZfKMTBi4U4fLkIRRU1xpVHABCgVuHOCG/cGeGFOyO8EeLFAHOrYmCxEGMPCwMLEZFNSCQSdNO4o5vGHXOGhaOmTo/jV0pw6GIRDl0qREpmCXJKq7E5JRubU7IBABoPJQaGeWFQuBcGhnuhmx+HkG4VDCwW0tTDwiYlIrIHhbxhPsvAMC/MG90VVTX1OJZ5DYcvF+Hw5SKkZpUgT6vD1hM52NrYA+OukmNAiCdiQz0RE+qJPsGd4MahfYfE74qFVLKHhYjIoTgrZBjaxQdDu/gAaOgJT80qwc/pxTiSVoxjmddQVl2HfecLsO98AQBAKgG6adzRP8QT/UM6oW/nTuji58b7HzkABhYLqdRxHxYiIkfmrJBhcKQ3Bkd6AwDq6vU4m1uGo+nFOJpxDSmZJcguqcLZ3DKczS3D50cyATT8XI8OUqNPkBq9O6sRHaRGuLcrh5JsjIHFQipruTU/EdGtRC6TIjqoIYA8OjQcAJCnrUZKZglSMq8hNasEv2SXoqKmHkfSGnplDNyUcvQM8EDPQA/jn1383LgnjBXx6mohlTpuzU9EdKvTeKhwb7Q/7o32BwDU6wUuFZQbw8vJ7FKcvqpFua4OR9KLcSS9KcTIpBKEebugR4AHumvc0U3jhq4ad4R6uUDOWwu0GwOLhVQYtubnZC0iotuGTNq0EmlqbDCAhqGkSwUVOJ1TilPZWpzOaXiUVNbiUkEFLhVUYBtyjOdQyKQI93FFpJ8rIn3dEOnrhnAfV4T5uELtzDtUtxavrhZSZdianz0sRES3NblMiu7+7uju747J/RuOCSGQX6ZrmP+So8X5vHJcyC/DhbxyVNXWG3fn/S0vVwXCvF0Q6u2KYC8XhDQ+gjyd4e+h4mTfX2lTYFm5ciXefPNN5OTkoFevXlixYgXi4uJaLJuTk4Nnn30WycnJuHDhAp555hmsWLGiWblNmzbhhRdewKVLlxAZGYlXX30VkydPbkv17MLQw8KN44iIOh6JRAKNhwoaDxVGdPM1HtfrBbJLqnCxoByX8ssbemDyy5FWVIGCMh2KK2pQXFGDY5klzc4pl0rgr1YhqJMzAtQqBDT+qfFQwc9dCY2HCj5uSijkHWO4yezAsnHjRsyfPx8rV67E0KFD8cEHH2Ds2LE4ffo0QkJCmpXX6XTw9fXFsmXL8M4777R4zqSkJEybNg0vv/wyJk+ejM2bN2Pq1Kk4cOAABg0aZP6nsoOmjePYaUVERA2kUgmCvVwQ7OWCUd39TJ4r19UhvbACGUWVyCyuRGZxReOflcgpqUadXuDKtSpcuVZ1w/fo5OIEHzclfNwU8HZTwstFAU8XJ3i6KtDJxQlq54aHh8oJHs5OcFXK4eIku+VWOUmEEMKcFwwaNAgDBgzAqlWrjMeioqIwadIkJCQk3PC1I0eORL9+/Zr1sEybNg1arRbfffed8di9994LT09PfP755y2eS6fTQafTGb/WarUIDg5GaWkpPDw8zPlI7SaEQMTS7RACOLL0bvh58NbnRETUdvV6gfyyaly5VoWrJVXIKa1Gbmk1rpZUIa9MhwJtNQrKdaitN+sSbiSRNPyC7aKQwUUhg8qp4U+lXAalkxQKmRQKuRROMinkUgnkMgnkUin+GBeBEG8Xi35WrVYLtVp90+u3Wd0BNTU1SE5OxuLFi02Ox8fH49ChQ22rKRp6WBYsWGBybMyYMS0OHRkkJCTgb3/7W5vf05J0dXoYYh8n3RIRUXvJpBIEqJ0RoHa+bhm9XuBaZQ2KKmpQWKZDYeOfJZU1KK6swbXKWpRU1kBbVYfSqlqUVtWiXFeHer2AEA09POWNK1xba/KAIIsHltYy6+paWFiI+vp6aDQak+MajQa5ubltrkRubq7Z51yyZAkWLlxo/NrQw2IPFb/6hjtzDT4REdmAVCqBt5sS3m5KdNO4t+o1QghU1+pRrqtDWXUtKmvqUV1bj8qaelTV1kNXp0dNnR66unroavWo1wvU6QXq6vWo1QsE3iBAWVubugN+e6dLIUS7735p7jmVSiWUSmW73tNSDNvyq5yknNFNREQOSyKRwFkhg7NCBl93x7iGtpZZU4t9fHwgk8ma9Xzk5+c36yExh7+/v8XPaUuGwMJdbomIiKzDrMCiUCgQExODxMREk+OJiYkYMmRImysxePDgZufcuXNnu85pS5U13OWWiIjImszuEli4cCFmzpyJ2NhYDB48GB9++CEyMzMxd+5cAA1zS7Kzs/HJJ58YX5OamgoAKC8vR0FBAVJTU6FQKNCzZ08AwLx58zB8+HD8/e9/x+9+9zt8/fXX2LVrFw4cOGCBj2h9TT0sDCxERETWYHZgmTZtGoqKirB8+XLk5OQgOjoa27dvR2hoKICGjeIyMzNNXtO/f3/j35OTk7F+/XqEhoYiPT0dADBkyBBs2LABzz//PF544QVERkZi48aNt8weLBXG+whxSIiIiMgazN6HxVG1dh23NXydmo15G1IxtIs3PnvsTpu+NxER0a2stdfvjrGfr5VV6Bq35XdiDwsREZE1MLBYgGHSrauSc1iIiIisgYHFAjjploiIyLoYWCyA+7AQERFZFwOLBXAfFiIiIutiYLEA9rAQERFZFwOLBbCHhYiIyLoYWCyAk26JiIisi4HFAip1HBIiIiKyJgYWC6gwDAlxHxYiIiKrYGCxgKrGISFX9rAQERFZBQOLBVRw0i0REZFVMbBYACfdEhERWRcDSzsJIbgPCxERkZUxsLRTTb0e9XoBgJNuiYiIrIWBpZ0MS5oBwMWJgYWIiMgaGFjaqbK2IbAo5FLIZWxOIiIia+AVtp0qdVwhREREZG0MLO1UyT1YiIiIrI6BpZ24BwsREZH1MbC0U9N9hBhYiIiIrIWBpZ0Mk265BwsREZH1MLC0EyfdEhERWR8DSzsZd7lVsoeFiIjIWhhY2qnSMOmWm8YRERFZDQNLOzX1sDCwEBERWQsDSzvxTs1ERETWx8DSTsYhIa4SIiIishoGlnaqYA8LERGR1TGwtJNhWTO35iciIrIeBpZ24qRbIiIi62NgaSdOuiUiIrI+BpZ24qRbIiIi62NgaSf2sBAREVkfA0s7NQUW9rAQERFZCwNLOzUNCbGHhYiIyFoYWNqhpk6P2noBgMuaiYiIrKlNgWXlypUIDw+HSqVCTEwM9u/ff8Py+/btQ0xMDFQqFSIiIrB69epmZVasWIHu3bvD2dkZwcHBWLBgAaqrq9tSPZupahwOAgBn9rAQERFZjdmBZePGjZg/fz6WLVuGlJQUxMXFYezYscjMzGyxfFpaGsaNG4e4uDikpKRg6dKleOaZZ7Bp0yZjmc8++wyLFy/Giy++iDNnzmDt2rXYuHEjlixZ0vZPZgOVtQ3DQU4yCRRydlYRERFZi9njGG+//TbmzJmDxx57DEBDz8j333+PVatWISEhoVn51atXIyQkBCtWrAAAREVF4ejRo3jrrbcwZcoUAEBSUhKGDh2KGTNmAADCwsIwffp0HDly5Lr10Ol00Ol0xq+1Wq25H6XdKnQNPSzOTuxdISIisiazugVqamqQnJyM+Ph4k+Px8fE4dOhQi69JSkpqVn7MmDE4evQoamtrAQDDhg1DcnKyMaBcvnwZ27dvx/jx469bl4SEBKjVauMjODjYnI9iEdyDhYiIyDbMCiyFhYWor6+HRqMxOa7RaJCbm9via3Jzc1ssX1dXh8LCQgDAgw8+iJdffhnDhg2Dk5MTIiMjMWrUKCxevPi6dVmyZAlKS0uNj6ysLHM+ikUYljS7clt+IiIiq2pT14BEIjH5WgjR7NjNyv/6+N69e/Hqq69i5cqVGDRoEC5evIh58+YhICAAL7zwQovnVCqVUCqVbam+xbCHhYiIyDbMutL6+PhAJpM1603Jz89v1oti4O/v32J5uVwOb29vAMALL7yAmTNnGufF9O7dGxUVFXj88cexbNkySKWOOaGVu9wSERHZhllJQKFQICYmBomJiSbHExMTMWTIkBZfM3jw4Gbld+7cidjYWDg5OQEAKisrm4USmUwGIYSxN8YRVeoYWIiIiGzB7K6LhQsX4t///jfWrVuHM2fOYMGCBcjMzMTcuXMBNMwtmTVrlrH83LlzkZGRgYULF+LMmTNYt24d1q5di0WLFhnLTJw4EatWrcKGDRuQlpaGxMREvPDCC7jvvvsgkzluGDAOCSk5JERERGRNZl9pp02bhqKiIixfvhw5OTmIjo7G9u3bERoaCgDIyckx2ZMlPDwc27dvx4IFC/D+++8jMDAQ7777rnFJMwA8//zzkEgkeP7555GdnQ1fX19MnDgRr776qgU+ovVUGIaEuKyZiIjIqiTCkcdczKDVaqFWq1FaWgoPDw+bvOdb35/De3su4tEhYXjpvl42eU8iIqLbSWuv3445m/UWUdE4JMRt+YmIiKyLgaUdDPcScmVgISIisioGlnYwzGFx5j4sREREVsXA0g6VuoYhIfawEBERWRcDSzsYN47jsmYiIiKrYmBpB+M+LFzWTEREZFUMLO3Q1MPCwEJERGRNDCzt0HQvIQ4JERERWRMDSzsYhoQ46ZaIiMi6GFjaoWlZMwMLERGRNTGwtFFdvR41dXoAgCuHhIiIiKyKgaWNKmvrjX9nDwsREZF1MbC0kWFbfplUAqWczUhERGRNvNK2UUXjLrcuChkkEomda0NERHR7Y2Bpo6YlzRwOIiIisjYGljaqNN6pmRNuiYiIrI2BpY0qGvdg4YRbIiIi62NgaaMq9rAQERHZDANLGxkm3bKHhYiIyPoYWNqoqnEfFlfe+JCIiMjqGFjaqELXuC2/E4eEiIiIrI2BpY2qDDc+ZA8LERGR1TGwtBFvfEhERGQ7DCxtVGnoYeEqISIiIqtjYGkj7nRLRERkOwwsbWSYdOvCHhYiIiKrY2Bpo6paTrolIiKyFQaWNmpa1szAQkREZG0MLG1k3JpfySEhIiIia2NgaSPe/JCIiMh2GFjaiDc/JCIish0GljYy9LBwWTMREZH1MbC0Qb1eoLpWD4CBhYiIyBYYWNrAcKdmgPuwEBER2QIDSxtU6hqGgyQSQOXEJiQiIrI2Xm3boPJXE24lEomda0NERHT7Y2BpAy5pJiIisq02BZaVK1ciPDwcKpUKMTEx2L9//w3L79u3DzExMVCpVIiIiMDq1aublSkpKcFTTz2FgIAAqFQqREVFYfv27W2pntU1LWlmYCEiIrIFswPLxo0bMX/+fCxbtgwpKSmIi4vD2LFjkZmZ2WL5tLQ0jBs3DnFxcUhJScHSpUvxzDPPYNOmTcYyNTU1uOeee5Ceno4vv/wS586dw5o1axAUFNT2T2ZFFY2BxZkTbomIiGzC7Cvu22+/jTlz5uCxxx4DAKxYsQLff/89Vq1ahYSEhGblV69ejZCQEKxYsQIAEBUVhaNHj+Ktt97ClClTAADr1q1DcXExDh06BCcnJwBAaGjoDeuh0+mg0+mMX2u1WnM/SptVNQ4JsYeFiIjINszqYampqUFycjLi4+NNjsfHx+PQoUMtviYpKalZ+TFjxuDo0aOora0FAHzzzTcYPHgwnnrqKWg0GkRHR+O1115DfX19S6cEACQkJECtVhsfwcHB5nyUdjHe+JCBhYiIyCbMCiyFhYWor6+HRqMxOa7RaJCbm9via3Jzc1ssX1dXh8LCQgDA5cuX8eWXX6K+vh7bt2/H888/j3/84x949dVXr1uXJUuWoLS01PjIysoy56O0S2Utt+UnIiKypTZdcX+7lFcIccPlvS2V//VxvV4PPz8/fPjhh5DJZIiJicHVq1fx5ptv4q9//WuL51QqlVAqlW2pfrsZ9mHhLrdERES2YVZg8fHxgUwma9abkp+f36wXxcDf37/F8nK5HN7e3gCAgIAAODk5QSZrCgBRUVHIzc1FTU0NFAqFOdW0OsM+LC5KBhYiIiJbMGtISKFQICYmBomJiSbHExMTMWTIkBZfM3jw4Gbld+7cidjYWOME26FDh+LixYvQ6/XGMufPn0dAQIDDhRUAqDTe+JBDQkRERLZg9rLmhQsX4t///jfWrVuHM2fOYMGCBcjMzMTcuXMBNMwtmTVrlrH83LlzkZGRgYULF+LMmTNYt24d1q5di0WLFhnLPPHEEygqKsK8efNw/vx5bNu2Da+99hqeeuopC3xEyzMsa+aQEBERkW2Y3UUwbdo0FBUVYfny5cjJyUF0dDS2b99uXIack5NjsidLeHg4tm/fjgULFuD9999HYGAg3n33XeOSZgAIDg7Gzp07sWDBAvTp0wdBQUGYN28ennvuOQt8RMurquGkWyIiIluSCMMM2FucVquFWq1GaWkpPDw8rPpej39yFDtP5+GVSdF4+M4b7xdDRERE19fa6zfvJdQGVYZlzZx0S0REZBMMLG1Q0bis2dmJQ0JERES2wMDSBoZlzexhISIisg0Gljao5CohIiIim2JgaYOmwMIhISIiIltgYGmDpo3j2MNCRERkCwwsZtLrhXGVEHtYiIiIbIOBxUzVdfUw7FzDSbdERES2wcBipgpdvfHvKjkDCxERkS0wsJip6lcrhKRSiZ1rQ0RE1DEwsJipghNuiYiIbI6BxUxc0kxERGR7DCxm4pJmIiIi22NgMRN3uSUiIrI9BhYzNfWwcEiIiIjIVhhYzMQeFiIiIttjYDFTpY6BhYiIyNYYWMxkXNas5JAQERGRrTCwmMmwcZwre1iIiIhshoHFTIYeFmdOuiUiIrIZBhYzVbKHhYiIyOYYWMzESbdERES2x8Bipspabs1PRERkawwsZqrUcWt+IiIiW2NgMZNx4zguayYiIrIZBhYz8eaHREREtsfAYiZuzU9ERGR7DCxmagosHBIiIiKyFQYWMwghOCRERERkBwwsZtDV6aEXDX935aRbIiIim2FgMUNF45JmAHB2Yg8LERGRrTCwmMEwf0XlJIVMKrFzbYiIiDoOBhYzcMItERGRfTCwmIETbomIiOyDgcUM3IOFiIjIPhhYzMAhISIiIvtgYDEDh4SIiIjso02BZeXKlQgPD4dKpUJMTAz2799/w/L79u1DTEwMVCoVIiIisHr16uuW3bBhAyQSCSZNmtSWqlkVe1iIiIjsw+zAsnHjRsyfPx/Lli1DSkoK4uLiMHbsWGRmZrZYPi0tDePGjUNcXBxSUlKwdOlSPPPMM9i0aVOzshkZGVi0aBHi4uLM/yQ2YNiHhT0sREREtmV2YHn77bcxZ84cPPbYY4iKisKKFSsQHByMVatWtVh+9erVCAkJwYoVKxAVFYXHHnsMs2fPxltvvWVSrr6+Hg899BD+9re/ISIi4qb10Ol00Gq1Jg9rM/SwuCoZWIiIiGzJrMBSU1OD5ORkxMfHmxyPj4/HoUOHWnxNUlJSs/JjxozB0aNHUVtbazy2fPly+Pr6Ys6cOa2qS0JCAtRqtfERHBxszkdpEw4JERER2YdZgaWwsBD19fXQaDQmxzUaDXJzc1t8TW5ubovl6+rqUFhYCAA4ePAg1q5dizVr1rS6LkuWLEFpaanxkZWVZc5HaRNOuiUiIrKPNnUVSCSm29ILIZodu1l5w/GysjI8/PDDWLNmDXx8fFpdB6VSCaVSaUat2489LERERPZh1pXXx8cHMpmsWW9Kfn5+s14UA39//xbLy+VyeHt749SpU0hPT8fEiRONz+v1+obKyeU4d+4cIiMjzamm1bCHhYiIyD7MGhJSKBSIiYlBYmKiyfHExEQMGTKkxdcMHjy4WfmdO3ciNjYWTk5O6NGjB06ePInU1FTj47777sOoUaOQmppqk7kprcWdbomIiOzD7LGNhQsXYubMmYiNjcXgwYPx4YcfIjMzE3PnzgXQMLckOzsbn3zyCQBg7ty5eO+997Bw4UL88Y9/RFJSEtauXYvPP/8cAKBSqRAdHW3yHp06dQKAZsftrVLHISEiIiJ7MPvKO23aNBQVFWH58uXIyclBdHQ0tm/fjtDQUABATk6OyZ4s4eHh2L59OxYsWID3338fgYGBePfddzFlyhTLfQobqaxtHBLismYiIiKbkgjDDNhbnFarhVqtRmlpKTw8PKzyHne9tReXCyuw8fE7MSjC2yrvQURE1JG09vrNewmZoWnjOA4JERER2RIDixkqGlcJOXPSLRERkU0xsLSSEKKph4WTbomIiGyKgaWVaur1qNc3TPfhpFsiIiLbYmBpJcOSZgBwcWJgISIisiUGllaqrG0ILAq5FHIZm42IiMiWeOVtpUodt+UnIiKyFwaWVuKEWyIiIvthYGklLmkmIiKyHwaWVqoy9rAwsBAREdkaA0srVTQGFvawEBER2R4DSytVNQ4JcQ4LERGR7TGwtFJF4z4sLryPEBERkc0xsLRSZWMPCzeNIyIisj0GllYyLGvmtvxERES2x8DSSsbAwkm3RERENsfA0krGISFOuiUiIrI5BpZWqmAPCxERkd0wsLRSFbfmJyIishsGllaq0HFrfiIiInthYGmlqtrGHhauEiIiIrI5BpZWMvawOHFIiIiIyNYYWFrJsKyZPSxERES2x8DSSk37sLCHhYiIyNYYWFqpaR8W9rAQERHZGgNLK9TU6VFbLwBwWTMREZE9MLC0gmEPFoDLmomIiOyBgaUVKmsbhoOcZBIo5GwyIiIiW+PVtxUqdA09LM5O7F0hIiKyBwaWVjBuy6/k/BUiIiJ7YGBphYoabstPRERkTwwsrcAbHxIREdkXA0srsIeFiIjIvhhYWqFSZ+hhYWAhIiKyBwaWVjDucstJt0RERHbBwNIKFYb7CHFZMxERkV0wsLQClzUTERHZV5sCy8qVKxEeHg6VSoWYmBjs37//huX37duHmJgYqFQqREREYPXq1SbPr1mzBnFxcfD09ISnpydGjx6NI0eOtKVqVsFJt0RERPZldmDZuHEj5s+fj2XLliElJQVxcXEYO3YsMjMzWyyflpaGcePGIS4uDikpKVi6dCmeeeYZbNq0yVhm7969mD59Ovbs2YOkpCSEhIQgPj4e2dnZbf9kFtS0rJmBhYiIyB4kQghhzgsGDRqEAQMGYNWqVcZjUVFRmDRpEhISEpqVf+655/DNN9/gzJkzxmNz587F8ePHkZSU1OJ71NfXw9PTE++99x5mzZrVYhmdTgedTmf8WqvVIjg4GKWlpfDw8DDnI93Unz5PwbfHr+KFCT0xZ1i4Rc9NRETUkWm1WqjV6ptev83qYampqUFycjLi4+NNjsfHx+PQoUMtviYpKalZ+TFjxuDo0aOora1t8TWVlZWora2Fl5fXdeuSkJAAtVptfAQHB5vzUcxS1TgkxB4WIiIi+zArsBQWFqK+vh4ajcbkuEajQW5ubouvyc3NbbF8XV0dCgsLW3zN4sWLERQUhNGjR1+3LkuWLEFpaanxkZWVZc5HMYvx5ocMLERERHbRpmUvEonE5GshRLNjNyvf0nEAeOONN/D5559j7969UKlU1z2nUqmEUqk0p9ptVlnLrfmJiIjsyawrsI+PD2QyWbPelPz8/Ga9KAb+/v4tlpfL5fD29jY5/tZbb+G1117Drl270KdPH3OqZlWVusaN49jDQkREZBdmDQkpFArExMQgMTHR5HhiYiKGDBnS4msGDx7crPzOnTsRGxsLJycn47E333wTL7/8Mnbs2IHY2FhzqmV1lYaN47gPCxERkV2Yvax54cKF+Pe//41169bhzJkzWLBgATIzMzF37lwADXNLfr2yZ+7cucjIyMDChQtx5swZrFu3DmvXrsWiRYuMZd544w08//zzWLduHcLCwpCbm4vc3FyUl5db4CO2XyUn3RIREdmV2V0G06ZNQ1FREZYvX46cnBxER0dj+/btCA0NBQDk5OSY7MkSHh6O7du3Y8GCBXj//fcRGBiId999F1OmTDGWWblyJWpqavDAAw+YvNeLL76Il156qY0fzXIMW/Nz0i0REZF9mL0Pi6Nq7Tpuc9XV69Fl2XcAgJQX7oGnq8Ji5yYiIurorLIPS0dkWCEEsIeFiIjIXhhYbsKwLb9MKoFSzuYiIiKyB16Bb6LCsKTZSXbDvWaIiIjIehhYbqJpSTOHg4iIiOyFgeUmjIGFu9wSERHZDQPLTRj2YOEut0RERPbDwHITTT0sDCxERET2wsByE8ZJtxwSIiIishsGlpuoMtypmZNuiYiI7IaB5SYqdI3b8juxh4WIiMheGFhuospw40P2sBAREdkNA8tN8MaHRERE9sfAchOGVUKunHRLRERkNwwsN8F9WIiIiOyPgeUmuNMtERGR/TGw3AR7WIiIiOyPgeUmuNMtERGR/XGc4yZ+HxOMQeHeiPB1s3dViIiIOiwGlpuYMSjE3lUgIiLq8DgkRERERA6PgYWIiIgcHgMLEREROTwGFiIiInJ4DCxERETk8BhYiIiIyOExsBAREZHDY2AhIiIih8fAQkRERA6PgYWIiIgcHgMLEREROTwGFiIiInJ4DCxERETk8G6buzULIQAAWq3WzjUhIiKi1jJctw3X8eu5bQJLWVkZACA4ONjONSEiIiJzlZWVQa1WX/d5ibhZpLlF6PV6XL16Fe7u7pBIJBY7r1arRXBwMLKysuDh4WGx896u2F7mYXuZh+3Vemwr87C9zGPJ9hJCoKysDIGBgZBKrz9T5bbpYZFKpejcubPVzu/h4cF/xGZge5mH7WUetlfrsa3Mw/Yyj6Xa60Y9KwacdEtEREQOj4GFiIiIHB4Dy00olUq8+OKLUCqV9q7KLYHtZR62l3nYXq3HtjIP28s89miv22bSLREREd2+2MNCREREDo+BhYiIiBweAwsRERE5PAYWIiIicngMLEREROTwGFhuYuXKlQgPD4dKpUJMTAz2799v7yrZXUJCAgYOHAh3d3f4+flh0qRJOHfunEkZIQReeuklBAYGwtnZGSNHjsSpU6fsVGPHkpCQAIlEgvnz5xuPsb1MZWdn4+GHH4a3tzdcXFzQr18/JCcnG59nezWpq6vD888/j/DwcDg7OyMiIgLLly+HXq83lumo7fXjjz9i4sSJCAwMhEQiwZYtW0yeb0276HQ6/OlPf4KPjw9cXV1x33334cqVKzb8FLZzo/aqra3Fc889h969e8PV1RWBgYGYNWsWrl69anIOq7aXoOvasGGDcHJyEmvWrBGnT58W8+bNE66uriIjI8PeVbOrMWPGiI8++kj88ssvIjU1VYwfP16EhISI8vJyY5nXX39duLu7i02bNomTJ0+KadOmiYCAAKHVau1Yc/s7cuSICAsLE3369BHz5s0zHmd7NSkuLhahoaHi0UcfFT/99JNIS0sTu3btEhcvXjSWYXs1eeWVV4S3t7fYunWrSEtLE1988YVwc3MTK1asMJbpqO21fft2sWzZMrFp0yYBQGzevNnk+da0y9y5c0VQUJBITEwUx44dE6NGjRJ9+/YVdXV1Nv401nej9iopKRGjR48WGzduFGfPnhVJSUli0KBBIiYmxuQc1mwvBpYbuOOOO8TcuXNNjvXo0UMsXrzYTjVyTPn5+QKA2LdvnxBCCL1eL/z9/cXrr79uLFNdXS3UarVYvXq1vappd2VlZaJr164iMTFRjBgxwhhY2F6mnnvuOTFs2LDrPs/2MjV+/Hgxe/Zsk2P333+/ePjhh4UQbC+D316AW9MuJSUlwsnJSWzYsMFYJjs7W0ilUrFjxw6b1d0eWgp4v3XkyBEBwPhLvLXbi0NC11FTU4Pk5GTEx8ebHI+Pj8ehQ4fsVCvHVFpaCgDw8vICAKSlpSE3N9ek7ZRKJUaMGNGh2+6pp57C+PHjMXr0aJPjbC9T33zzDWJjY/H73/8efn5+6N+/P9asWWN8nu1latiwYfjhhx9w/vx5AMDx48dx4MABjBs3DgDb63pa0y7Jycmora01KRMYGIjo6OgO3XYGpaWlkEgk6NSpEwDrt9dtc7dmSyssLER9fT00Go3JcY1Gg9zcXDvVyvEIIbBw4UIMGzYM0dHRAGBsn5baLiMjw+Z1dAQbNmzAsWPH8PPPPzd7ju1l6vLly1i1ahUWLlyIpUuX4siRI3jmmWegVCoxa9YsttdvPPfccygtLUWPHj0gk8lQX1+PV199FdOnTwfAf1/X05p2yc3NhUKhgKenZ7MyHf06UF1djcWLF2PGjBnGuzVbu70YWG5CIpGYfC2EaHasI3v66adx4sQJHDhwoNlzbLsGWVlZmDdvHnbu3AmVSnXdcmyvBnq9HrGxsXjttdcAAP3798epU6ewatUqzJo1y1iO7dVg48aN+PTTT7F+/Xr06tULqampmD9/PgIDA/HII48Yy7G9WtaWdunobVdbW4sHH3wQer0eK1euvGl5S7UXh4Suw8fHBzKZrFkqzM/Pb5bIO6o//elP+Oabb7Bnzx507tzZeNzf3x8A2HaNkpOTkZ+fj5iYGMjlcsjlcuzbtw/vvvsu5HK5sU3YXg0CAgLQs2dPk2NRUVHIzMwEwH9fv/XnP/8ZixcvxoMPPojevXtj5syZWLBgARISEgCwva6nNe3i7++PmpoaXLt27bplOpra2lpMnToVaWlpSExMNPauANZvLwaW61AoFIiJiUFiYqLJ8cTERAwZMsROtXIMQgg8/fTT+Oqrr7B7926Eh4ebPB8eHg5/f3+TtqupqcG+ffs6ZNvdfffdOHnyJFJTU42P2NhYPPTQQ0hNTUVERATb61eGDh3abJn8+fPnERoaCoD/vn6rsrISUqnpj3KZTGZc1sz2allr2iUmJgZOTk4mZXJycvDLL790yLYzhJULFy5g165d8Pb2Nnne6u3V7mm7tzHDsua1a9eK06dPi/nz5wtXV1eRnp5u76rZ1RNPPCHUarXYu3evyMnJMT4qKyuNZV5//XWhVqvFV199JU6ePCmmT5/eIZZRttavVwkJwfb6tSNHjgi5XC5effVVceHCBfHZZ58JFxcX8emnnxrLsL2aPPLIIyIoKMi4rPmrr74SPj4+4i9/+YuxTEdtr7KyMpGSkiJSUlIEAPH222+LlJQU46qW1rTL3LlzRefOncWuXbvEsWPHxF133XXbLmu+UXvV1taK++67T3Tu3Fmkpqaa/OzX6XTGc1izvRhYbuL9998XoaGhQqFQiAEDBhiX7nZkAFp8fPTRR8Yyer1evPjii8Lf318olUoxfPhwcfLkSftV2sH8NrCwvUx9++23Ijo6WiiVStGjRw/x4YcfmjzP9mqi1WrFvHnzREhIiFCpVCIiIkIsW7bM5CLSUdtrz549Lf6seuSRR4QQrWuXqqoq8fTTTwsvLy/h7OwsJkyYIDIzM+3waazvRu2VlpZ23Z/9e/bsMZ7Dmu0lEUKI9vfTEBEREVkP57AQERGRw2NgISIiIofHwEJEREQOj4GFiIiIHB4DCxERETk8BhYiIiJyeAwsRERE5PAYWIiIiMjhMbAQERGRw2NgISIiIofHwEJEREQO7/8BgkUWuK95TukAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wd_schedule_values = wd_scheduler(0.15, 0.1, 0, 120, 5, 0.01)\n",
    "plt.plot(range(len(wd_schedule_values)), wd_schedule_values)\n",
    "plt.title(\"Weight decay scheduler\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.rand(768, 3, 16, 16)\n",
    "spatial_dims = (80, 80)  # 모든 공간 차원의 크기를 가져옴\n",
    "\n",
    "t = torch.nn.functional.interpolate(\n",
    "    t, size=spatial_dims, mode='bilinear', align_corners=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 3, 80, 80])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use chcekpoint: False\n",
      "Checkpoint number: 32\n",
      "Load pretrained params\n",
      "\n",
      "Interpolating pos_embed, torch.Size([1, 197, 768]) => torch.Size([1, 1591, 768])\n",
      "\n",
      "\n",
      "Interpolating patch_embed.proj.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])\n",
      "\n",
      "Init center: True\n",
      "Inflate: patch_embed.proj.weight, torch.Size([768, 3, 1, 16, 16]) => torch.Size([768, 3, 1, 16, 16])\n",
      "Ignore: head.weight\n",
      "Ignore: head.bias\n",
      "_IncompatibleKeys(missing_keys=['temporal_pos_embedding', 'head.weight', 'head.bias'], unexpected_keys=['distill_head.0.weight', 'distill_head.1.weight', 'distill_head.1.bias'])\n",
      "Use chcekpoint: False\n",
      "Checkpoint number: 32\n"
     ]
    }
   ],
   "source": [
    "from videomamba import videomamba_base\n",
    "\n",
    "pretrained_model = videomamba_base(\n",
    "    pretrained=True, height=480, width=854, n_classes=2, fc_drop_rate=.3, drop_path_rate=.3, kernel_size=1,\n",
    "    n_frames=2, use_checkpoint=False, checkpoint_num=32\n",
    ")\n",
    "model = videomamba_base(\n",
    "    pretrained=False, height=480, width=854, n_classes=2, fc_drop_rate=.3, drop_path_rate=.3, kernel_size=1,\n",
    "    n_frames=2, use_checkpoint=False, checkpoint_num=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token                                torch.Size([1, 1, 768])\n",
      "pos_embed                                torch.Size([1, 1591, 768])\n",
      "temporal_pos_embedding                   torch.Size([1, 2, 768])\n",
      "patch_embed.proj.weight                  torch.Size([768, 3, 1, 16, 16])\n",
      "patch_embed.proj.bias                    torch.Size([768])\n",
      "head.weight                              torch.Size([2, 768])\n",
      "head.bias                                torch.Size([2])\n",
      "layers.0.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.0.mixer.D                         torch.Size([1536])\n",
      "layers.0.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.0.mixer.D_b                       torch.Size([1536])\n",
      "layers.0.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.0.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.0.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.0.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.0.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.0.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.0.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.0.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.0.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.0.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.0.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.0.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.0.norm.weight                     torch.Size([768])\n",
      "layers.1.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.1.mixer.D                         torch.Size([1536])\n",
      "layers.1.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.1.mixer.D_b                       torch.Size([1536])\n",
      "layers.1.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.1.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.1.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.1.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.1.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.1.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.1.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.1.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.1.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.1.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.1.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.1.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.1.norm.weight                     torch.Size([768])\n",
      "layers.2.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.2.mixer.D                         torch.Size([1536])\n",
      "layers.2.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.2.mixer.D_b                       torch.Size([1536])\n",
      "layers.2.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.2.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.2.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.2.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.2.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.2.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.2.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.2.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.2.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.2.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.2.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.2.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.2.norm.weight                     torch.Size([768])\n",
      "layers.3.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.3.mixer.D                         torch.Size([1536])\n",
      "layers.3.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.3.mixer.D_b                       torch.Size([1536])\n",
      "layers.3.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.3.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.3.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.3.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.3.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.3.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.3.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.3.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.3.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.3.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.3.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.3.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.3.norm.weight                     torch.Size([768])\n",
      "layers.4.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.4.mixer.D                         torch.Size([1536])\n",
      "layers.4.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.4.mixer.D_b                       torch.Size([1536])\n",
      "layers.4.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.4.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.4.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.4.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.4.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.4.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.4.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.4.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.4.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.4.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.4.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.4.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.4.norm.weight                     torch.Size([768])\n",
      "layers.5.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.5.mixer.D                         torch.Size([1536])\n",
      "layers.5.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.5.mixer.D_b                       torch.Size([1536])\n",
      "layers.5.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.5.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.5.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.5.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.5.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.5.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.5.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.5.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.5.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.5.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.5.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.5.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.5.norm.weight                     torch.Size([768])\n",
      "layers.6.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.6.mixer.D                         torch.Size([1536])\n",
      "layers.6.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.6.mixer.D_b                       torch.Size([1536])\n",
      "layers.6.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.6.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.6.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.6.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.6.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.6.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.6.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.6.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.6.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.6.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.6.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.6.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.6.norm.weight                     torch.Size([768])\n",
      "layers.7.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.7.mixer.D                         torch.Size([1536])\n",
      "layers.7.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.7.mixer.D_b                       torch.Size([1536])\n",
      "layers.7.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.7.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.7.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.7.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.7.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.7.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.7.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.7.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.7.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.7.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.7.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.7.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.7.norm.weight                     torch.Size([768])\n",
      "layers.8.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.8.mixer.D                         torch.Size([1536])\n",
      "layers.8.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.8.mixer.D_b                       torch.Size([1536])\n",
      "layers.8.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.8.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.8.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.8.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.8.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.8.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.8.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.8.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.8.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.8.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.8.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.8.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.8.norm.weight                     torch.Size([768])\n",
      "layers.9.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.9.mixer.D                         torch.Size([1536])\n",
      "layers.9.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.9.mixer.D_b                       torch.Size([1536])\n",
      "layers.9.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.9.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.9.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.9.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.9.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.9.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.9.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.9.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.9.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.9.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.9.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.9.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.9.norm.weight                     torch.Size([768])\n",
      "layers.10.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.10.mixer.D                        torch.Size([1536])\n",
      "layers.10.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.10.mixer.D_b                      torch.Size([1536])\n",
      "layers.10.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.10.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.10.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.10.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.10.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.10.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.10.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.10.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.10.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.10.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.10.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.10.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.10.norm.weight                    torch.Size([768])\n",
      "layers.11.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.11.mixer.D                        torch.Size([1536])\n",
      "layers.11.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.11.mixer.D_b                      torch.Size([1536])\n",
      "layers.11.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.11.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.11.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.11.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.11.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.11.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.11.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.11.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.11.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.11.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.11.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.11.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.11.norm.weight                    torch.Size([768])\n",
      "layers.12.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.12.mixer.D                        torch.Size([1536])\n",
      "layers.12.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.12.mixer.D_b                      torch.Size([1536])\n",
      "layers.12.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.12.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.12.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.12.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.12.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.12.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.12.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.12.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.12.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.12.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.12.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.12.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.12.norm.weight                    torch.Size([768])\n",
      "layers.13.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.13.mixer.D                        torch.Size([1536])\n",
      "layers.13.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.13.mixer.D_b                      torch.Size([1536])\n",
      "layers.13.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.13.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.13.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.13.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.13.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.13.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.13.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.13.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.13.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.13.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.13.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.13.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.13.norm.weight                    torch.Size([768])\n",
      "layers.14.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.14.mixer.D                        torch.Size([1536])\n",
      "layers.14.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.14.mixer.D_b                      torch.Size([1536])\n",
      "layers.14.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.14.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.14.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.14.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.14.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.14.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.14.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.14.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.14.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.14.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.14.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.14.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.14.norm.weight                    torch.Size([768])\n",
      "layers.15.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.15.mixer.D                        torch.Size([1536])\n",
      "layers.15.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.15.mixer.D_b                      torch.Size([1536])\n",
      "layers.15.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.15.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.15.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.15.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.15.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.15.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.15.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.15.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.15.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.15.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.15.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.15.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.15.norm.weight                    torch.Size([768])\n",
      "layers.16.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.16.mixer.D                        torch.Size([1536])\n",
      "layers.16.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.16.mixer.D_b                      torch.Size([1536])\n",
      "layers.16.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.16.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.16.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.16.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.16.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.16.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.16.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.16.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.16.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.16.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.16.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.16.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.16.norm.weight                    torch.Size([768])\n",
      "layers.17.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.17.mixer.D                        torch.Size([1536])\n",
      "layers.17.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.17.mixer.D_b                      torch.Size([1536])\n",
      "layers.17.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.17.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.17.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.17.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.17.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.17.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.17.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.17.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.17.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.17.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.17.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.17.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.17.norm.weight                    torch.Size([768])\n",
      "layers.18.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.18.mixer.D                        torch.Size([1536])\n",
      "layers.18.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.18.mixer.D_b                      torch.Size([1536])\n",
      "layers.18.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.18.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.18.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.18.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.18.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.18.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.18.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.18.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.18.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.18.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.18.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.18.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.18.norm.weight                    torch.Size([768])\n",
      "layers.19.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.19.mixer.D                        torch.Size([1536])\n",
      "layers.19.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.19.mixer.D_b                      torch.Size([1536])\n",
      "layers.19.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.19.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.19.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.19.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.19.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.19.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.19.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.19.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.19.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.19.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.19.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.19.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.19.norm.weight                    torch.Size([768])\n",
      "layers.20.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.20.mixer.D                        torch.Size([1536])\n",
      "layers.20.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.20.mixer.D_b                      torch.Size([1536])\n",
      "layers.20.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.20.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.20.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.20.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.20.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.20.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.20.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.20.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.20.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.20.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.20.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.20.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.20.norm.weight                    torch.Size([768])\n",
      "layers.21.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.21.mixer.D                        torch.Size([1536])\n",
      "layers.21.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.21.mixer.D_b                      torch.Size([1536])\n",
      "layers.21.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.21.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.21.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.21.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.21.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.21.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.21.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.21.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.21.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.21.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.21.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.21.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.21.norm.weight                    torch.Size([768])\n",
      "layers.22.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.22.mixer.D                        torch.Size([1536])\n",
      "layers.22.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.22.mixer.D_b                      torch.Size([1536])\n",
      "layers.22.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.22.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.22.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.22.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.22.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.22.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.22.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.22.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.22.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.22.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.22.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.22.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.22.norm.weight                    torch.Size([768])\n",
      "layers.23.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.23.mixer.D                        torch.Size([1536])\n",
      "layers.23.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.23.mixer.D_b                      torch.Size([1536])\n",
      "layers.23.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.23.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.23.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.23.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.23.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.23.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.23.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.23.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.23.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.23.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.23.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.23.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.23.norm.weight                    torch.Size([768])\n",
      "norm_f.weight                            torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, val in pretrained_model.named_parameters():\n",
    "    print(f\"{name:<40} {val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token                                torch.Size([1, 1, 768])\n",
      "pos_embed                                torch.Size([1, 1591, 768])\n",
      "temporal_pos_embedding                   torch.Size([1, 2, 768])\n",
      "patch_embed.proj.weight                  torch.Size([768, 3, 1, 16, 16])\n",
      "patch_embed.proj.bias                    torch.Size([768])\n",
      "head.weight                              torch.Size([2, 768])\n",
      "head.bias                                torch.Size([2])\n",
      "layers.0.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.0.mixer.D                         torch.Size([1536])\n",
      "layers.0.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.0.mixer.D_b                       torch.Size([1536])\n",
      "layers.0.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.0.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.0.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.0.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.0.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.0.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.0.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.0.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.0.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.0.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.0.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.0.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.0.norm.weight                     torch.Size([768])\n",
      "layers.1.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.1.mixer.D                         torch.Size([1536])\n",
      "layers.1.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.1.mixer.D_b                       torch.Size([1536])\n",
      "layers.1.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.1.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.1.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.1.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.1.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.1.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.1.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.1.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.1.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.1.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.1.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.1.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.1.norm.weight                     torch.Size([768])\n",
      "layers.2.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.2.mixer.D                         torch.Size([1536])\n",
      "layers.2.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.2.mixer.D_b                       torch.Size([1536])\n",
      "layers.2.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.2.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.2.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.2.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.2.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.2.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.2.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.2.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.2.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.2.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.2.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.2.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.2.norm.weight                     torch.Size([768])\n",
      "layers.3.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.3.mixer.D                         torch.Size([1536])\n",
      "layers.3.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.3.mixer.D_b                       torch.Size([1536])\n",
      "layers.3.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.3.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.3.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.3.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.3.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.3.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.3.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.3.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.3.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.3.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.3.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.3.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.3.norm.weight                     torch.Size([768])\n",
      "layers.4.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.4.mixer.D                         torch.Size([1536])\n",
      "layers.4.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.4.mixer.D_b                       torch.Size([1536])\n",
      "layers.4.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.4.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.4.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.4.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.4.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.4.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.4.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.4.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.4.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.4.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.4.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.4.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.4.norm.weight                     torch.Size([768])\n",
      "layers.5.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.5.mixer.D                         torch.Size([1536])\n",
      "layers.5.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.5.mixer.D_b                       torch.Size([1536])\n",
      "layers.5.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.5.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.5.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.5.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.5.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.5.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.5.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.5.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.5.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.5.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.5.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.5.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.5.norm.weight                     torch.Size([768])\n",
      "layers.6.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.6.mixer.D                         torch.Size([1536])\n",
      "layers.6.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.6.mixer.D_b                       torch.Size([1536])\n",
      "layers.6.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.6.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.6.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.6.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.6.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.6.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.6.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.6.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.6.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.6.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.6.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.6.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.6.norm.weight                     torch.Size([768])\n",
      "layers.7.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.7.mixer.D                         torch.Size([1536])\n",
      "layers.7.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.7.mixer.D_b                       torch.Size([1536])\n",
      "layers.7.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.7.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.7.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.7.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.7.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.7.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.7.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.7.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.7.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.7.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.7.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.7.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.7.norm.weight                     torch.Size([768])\n",
      "layers.8.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.8.mixer.D                         torch.Size([1536])\n",
      "layers.8.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.8.mixer.D_b                       torch.Size([1536])\n",
      "layers.8.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.8.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.8.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.8.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.8.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.8.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.8.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.8.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.8.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.8.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.8.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.8.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.8.norm.weight                     torch.Size([768])\n",
      "layers.9.mixer.A_log                     torch.Size([1536, 16])\n",
      "layers.9.mixer.D                         torch.Size([1536])\n",
      "layers.9.mixer.A_b_log                   torch.Size([1536, 16])\n",
      "layers.9.mixer.D_b                       torch.Size([1536])\n",
      "layers.9.mixer.in_proj.weight            torch.Size([3072, 768])\n",
      "layers.9.mixer.conv1d.weight             torch.Size([1536, 1, 4])\n",
      "layers.9.mixer.conv1d.bias               torch.Size([1536])\n",
      "layers.9.mixer.x_proj.weight             torch.Size([80, 1536])\n",
      "layers.9.mixer.dt_proj.weight            torch.Size([1536, 48])\n",
      "layers.9.mixer.dt_proj.bias              torch.Size([1536])\n",
      "layers.9.mixer.conv1d_b.weight           torch.Size([1536, 1, 4])\n",
      "layers.9.mixer.conv1d_b.bias             torch.Size([1536])\n",
      "layers.9.mixer.x_proj_b.weight           torch.Size([80, 1536])\n",
      "layers.9.mixer.dt_proj_b.weight          torch.Size([1536, 48])\n",
      "layers.9.mixer.dt_proj_b.bias            torch.Size([1536])\n",
      "layers.9.mixer.out_proj.weight           torch.Size([768, 1536])\n",
      "layers.9.norm.weight                     torch.Size([768])\n",
      "layers.10.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.10.mixer.D                        torch.Size([1536])\n",
      "layers.10.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.10.mixer.D_b                      torch.Size([1536])\n",
      "layers.10.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.10.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.10.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.10.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.10.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.10.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.10.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.10.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.10.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.10.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.10.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.10.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.10.norm.weight                    torch.Size([768])\n",
      "layers.11.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.11.mixer.D                        torch.Size([1536])\n",
      "layers.11.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.11.mixer.D_b                      torch.Size([1536])\n",
      "layers.11.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.11.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.11.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.11.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.11.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.11.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.11.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.11.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.11.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.11.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.11.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.11.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.11.norm.weight                    torch.Size([768])\n",
      "layers.12.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.12.mixer.D                        torch.Size([1536])\n",
      "layers.12.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.12.mixer.D_b                      torch.Size([1536])\n",
      "layers.12.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.12.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.12.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.12.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.12.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.12.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.12.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.12.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.12.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.12.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.12.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.12.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.12.norm.weight                    torch.Size([768])\n",
      "layers.13.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.13.mixer.D                        torch.Size([1536])\n",
      "layers.13.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.13.mixer.D_b                      torch.Size([1536])\n",
      "layers.13.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.13.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.13.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.13.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.13.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.13.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.13.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.13.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.13.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.13.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.13.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.13.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.13.norm.weight                    torch.Size([768])\n",
      "layers.14.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.14.mixer.D                        torch.Size([1536])\n",
      "layers.14.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.14.mixer.D_b                      torch.Size([1536])\n",
      "layers.14.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.14.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.14.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.14.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.14.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.14.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.14.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.14.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.14.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.14.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.14.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.14.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.14.norm.weight                    torch.Size([768])\n",
      "layers.15.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.15.mixer.D                        torch.Size([1536])\n",
      "layers.15.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.15.mixer.D_b                      torch.Size([1536])\n",
      "layers.15.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.15.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.15.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.15.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.15.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.15.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.15.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.15.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.15.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.15.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.15.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.15.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.15.norm.weight                    torch.Size([768])\n",
      "layers.16.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.16.mixer.D                        torch.Size([1536])\n",
      "layers.16.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.16.mixer.D_b                      torch.Size([1536])\n",
      "layers.16.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.16.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.16.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.16.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.16.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.16.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.16.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.16.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.16.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.16.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.16.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.16.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.16.norm.weight                    torch.Size([768])\n",
      "layers.17.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.17.mixer.D                        torch.Size([1536])\n",
      "layers.17.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.17.mixer.D_b                      torch.Size([1536])\n",
      "layers.17.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.17.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.17.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.17.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.17.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.17.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.17.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.17.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.17.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.17.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.17.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.17.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.17.norm.weight                    torch.Size([768])\n",
      "layers.18.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.18.mixer.D                        torch.Size([1536])\n",
      "layers.18.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.18.mixer.D_b                      torch.Size([1536])\n",
      "layers.18.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.18.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.18.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.18.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.18.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.18.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.18.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.18.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.18.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.18.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.18.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.18.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.18.norm.weight                    torch.Size([768])\n",
      "layers.19.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.19.mixer.D                        torch.Size([1536])\n",
      "layers.19.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.19.mixer.D_b                      torch.Size([1536])\n",
      "layers.19.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.19.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.19.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.19.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.19.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.19.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.19.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.19.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.19.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.19.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.19.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.19.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.19.norm.weight                    torch.Size([768])\n",
      "layers.20.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.20.mixer.D                        torch.Size([1536])\n",
      "layers.20.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.20.mixer.D_b                      torch.Size([1536])\n",
      "layers.20.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.20.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.20.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.20.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.20.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.20.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.20.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.20.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.20.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.20.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.20.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.20.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.20.norm.weight                    torch.Size([768])\n",
      "layers.21.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.21.mixer.D                        torch.Size([1536])\n",
      "layers.21.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.21.mixer.D_b                      torch.Size([1536])\n",
      "layers.21.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.21.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.21.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.21.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.21.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.21.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.21.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.21.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.21.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.21.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.21.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.21.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.21.norm.weight                    torch.Size([768])\n",
      "layers.22.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.22.mixer.D                        torch.Size([1536])\n",
      "layers.22.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.22.mixer.D_b                      torch.Size([1536])\n",
      "layers.22.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.22.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.22.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.22.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.22.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.22.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.22.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.22.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.22.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.22.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.22.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.22.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.22.norm.weight                    torch.Size([768])\n",
      "layers.23.mixer.A_log                    torch.Size([1536, 16])\n",
      "layers.23.mixer.D                        torch.Size([1536])\n",
      "layers.23.mixer.A_b_log                  torch.Size([1536, 16])\n",
      "layers.23.mixer.D_b                      torch.Size([1536])\n",
      "layers.23.mixer.in_proj.weight           torch.Size([3072, 768])\n",
      "layers.23.mixer.conv1d.weight            torch.Size([1536, 1, 4])\n",
      "layers.23.mixer.conv1d.bias              torch.Size([1536])\n",
      "layers.23.mixer.x_proj.weight            torch.Size([80, 1536])\n",
      "layers.23.mixer.dt_proj.weight           torch.Size([1536, 48])\n",
      "layers.23.mixer.dt_proj.bias             torch.Size([1536])\n",
      "layers.23.mixer.conv1d_b.weight          torch.Size([1536, 1, 4])\n",
      "layers.23.mixer.conv1d_b.bias            torch.Size([1536])\n",
      "layers.23.mixer.x_proj_b.weight          torch.Size([80, 1536])\n",
      "layers.23.mixer.dt_proj_b.weight         torch.Size([1536, 48])\n",
      "layers.23.mixer.dt_proj_b.bias           torch.Size([1536])\n",
      "layers.23.mixer.out_proj.weight          torch.Size([768, 1536])\n",
      "layers.23.norm.weight                    torch.Size([768])\n",
      "norm_f.weight                            torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, val in model.named_parameters():\n",
    "    print(f\"{name:<40} {val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use chcekpoint: True\n",
      "Checkpoint number: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kks/anaconda3/envs/video_mamba/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from model import Model\n",
    "\n",
    "model = Model(n_frames=2, tubelet_size=1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_encoder.cls_token -1\n",
      "video_encoder.pos_embed -1\n",
      "video_encoder.temporal_pos_embedding -1\n",
      "0\n",
      "0\n",
      "video_encoder.layers.0.mixer.A_log -1\n",
      "video_encoder.layers.0.mixer.D -1\n",
      "video_encoder.layers.0.mixer.A_b_log -1\n",
      "video_encoder.layers.0.mixer.D_b -1\n",
      "video_encoder.layers.0.mixer.in_proj.weight -1\n",
      "video_encoder.layers.0.mixer.conv1d.weight -1\n",
      "video_encoder.layers.0.mixer.conv1d.bias -1\n",
      "video_encoder.layers.0.mixer.x_proj.weight -1\n",
      "video_encoder.layers.0.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.0.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.0.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.0.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.0.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.0.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.0.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.0.mixer.out_proj.weight -1\n",
      "video_encoder.layers.0.norm.weight -1\n",
      "video_encoder.layers.1.mixer.A_log -1\n",
      "video_encoder.layers.1.mixer.D -1\n",
      "video_encoder.layers.1.mixer.A_b_log -1\n",
      "video_encoder.layers.1.mixer.D_b -1\n",
      "video_encoder.layers.1.mixer.in_proj.weight -1\n",
      "video_encoder.layers.1.mixer.conv1d.weight -1\n",
      "video_encoder.layers.1.mixer.conv1d.bias -1\n",
      "video_encoder.layers.1.mixer.x_proj.weight -1\n",
      "video_encoder.layers.1.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.1.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.1.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.1.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.1.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.1.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.1.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.1.mixer.out_proj.weight -1\n",
      "video_encoder.layers.1.norm.weight -1\n",
      "video_encoder.layers.2.mixer.A_log -1\n",
      "video_encoder.layers.2.mixer.D -1\n",
      "video_encoder.layers.2.mixer.A_b_log -1\n",
      "video_encoder.layers.2.mixer.D_b -1\n",
      "video_encoder.layers.2.mixer.in_proj.weight -1\n",
      "video_encoder.layers.2.mixer.conv1d.weight -1\n",
      "video_encoder.layers.2.mixer.conv1d.bias -1\n",
      "video_encoder.layers.2.mixer.x_proj.weight -1\n",
      "video_encoder.layers.2.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.2.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.2.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.2.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.2.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.2.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.2.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.2.mixer.out_proj.weight -1\n",
      "video_encoder.layers.2.norm.weight -1\n",
      "video_encoder.layers.3.mixer.A_log -1\n",
      "video_encoder.layers.3.mixer.D -1\n",
      "video_encoder.layers.3.mixer.A_b_log -1\n",
      "video_encoder.layers.3.mixer.D_b -1\n",
      "video_encoder.layers.3.mixer.in_proj.weight -1\n",
      "video_encoder.layers.3.mixer.conv1d.weight -1\n",
      "video_encoder.layers.3.mixer.conv1d.bias -1\n",
      "video_encoder.layers.3.mixer.x_proj.weight -1\n",
      "video_encoder.layers.3.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.3.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.3.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.3.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.3.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.3.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.3.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.3.mixer.out_proj.weight -1\n",
      "video_encoder.layers.3.norm.weight -1\n",
      "video_encoder.layers.4.mixer.A_log -1\n",
      "video_encoder.layers.4.mixer.D -1\n",
      "video_encoder.layers.4.mixer.A_b_log -1\n",
      "video_encoder.layers.4.mixer.D_b -1\n",
      "video_encoder.layers.4.mixer.in_proj.weight -1\n",
      "video_encoder.layers.4.mixer.conv1d.weight -1\n",
      "video_encoder.layers.4.mixer.conv1d.bias -1\n",
      "video_encoder.layers.4.mixer.x_proj.weight -1\n",
      "video_encoder.layers.4.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.4.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.4.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.4.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.4.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.4.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.4.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.4.mixer.out_proj.weight -1\n",
      "video_encoder.layers.4.norm.weight -1\n",
      "video_encoder.layers.5.mixer.A_log -1\n",
      "video_encoder.layers.5.mixer.D -1\n",
      "video_encoder.layers.5.mixer.A_b_log -1\n",
      "video_encoder.layers.5.mixer.D_b -1\n",
      "video_encoder.layers.5.mixer.in_proj.weight -1\n",
      "video_encoder.layers.5.mixer.conv1d.weight -1\n",
      "video_encoder.layers.5.mixer.conv1d.bias -1\n",
      "video_encoder.layers.5.mixer.x_proj.weight -1\n",
      "video_encoder.layers.5.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.5.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.5.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.5.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.5.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.5.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.5.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.5.mixer.out_proj.weight -1\n",
      "video_encoder.layers.5.norm.weight -1\n",
      "video_encoder.layers.6.mixer.A_log -1\n",
      "video_encoder.layers.6.mixer.D -1\n",
      "video_encoder.layers.6.mixer.A_b_log -1\n",
      "video_encoder.layers.6.mixer.D_b -1\n",
      "video_encoder.layers.6.mixer.in_proj.weight -1\n",
      "video_encoder.layers.6.mixer.conv1d.weight -1\n",
      "video_encoder.layers.6.mixer.conv1d.bias -1\n",
      "video_encoder.layers.6.mixer.x_proj.weight -1\n",
      "video_encoder.layers.6.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.6.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.6.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.6.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.6.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.6.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.6.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.6.mixer.out_proj.weight -1\n",
      "video_encoder.layers.6.norm.weight -1\n",
      "video_encoder.layers.7.mixer.A_log -1\n",
      "video_encoder.layers.7.mixer.D -1\n",
      "video_encoder.layers.7.mixer.A_b_log -1\n",
      "video_encoder.layers.7.mixer.D_b -1\n",
      "video_encoder.layers.7.mixer.in_proj.weight -1\n",
      "video_encoder.layers.7.mixer.conv1d.weight -1\n",
      "video_encoder.layers.7.mixer.conv1d.bias -1\n",
      "video_encoder.layers.7.mixer.x_proj.weight -1\n",
      "video_encoder.layers.7.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.7.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.7.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.7.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.7.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.7.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.7.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.7.mixer.out_proj.weight -1\n",
      "video_encoder.layers.7.norm.weight -1\n",
      "video_encoder.layers.8.mixer.A_log -1\n",
      "video_encoder.layers.8.mixer.D -1\n",
      "video_encoder.layers.8.mixer.A_b_log -1\n",
      "video_encoder.layers.8.mixer.D_b -1\n",
      "video_encoder.layers.8.mixer.in_proj.weight -1\n",
      "video_encoder.layers.8.mixer.conv1d.weight -1\n",
      "video_encoder.layers.8.mixer.conv1d.bias -1\n",
      "video_encoder.layers.8.mixer.x_proj.weight -1\n",
      "video_encoder.layers.8.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.8.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.8.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.8.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.8.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.8.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.8.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.8.mixer.out_proj.weight -1\n",
      "video_encoder.layers.8.norm.weight -1\n",
      "video_encoder.layers.9.mixer.A_log -1\n",
      "video_encoder.layers.9.mixer.D -1\n",
      "video_encoder.layers.9.mixer.A_b_log -1\n",
      "video_encoder.layers.9.mixer.D_b -1\n",
      "video_encoder.layers.9.mixer.in_proj.weight -1\n",
      "video_encoder.layers.9.mixer.conv1d.weight -1\n",
      "video_encoder.layers.9.mixer.conv1d.bias -1\n",
      "video_encoder.layers.9.mixer.x_proj.weight -1\n",
      "video_encoder.layers.9.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.9.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.9.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.9.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.9.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.9.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.9.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.9.mixer.out_proj.weight -1\n",
      "video_encoder.layers.9.norm.weight -1\n",
      "video_encoder.layers.10.mixer.A_log -1\n",
      "video_encoder.layers.10.mixer.D -1\n",
      "video_encoder.layers.10.mixer.A_b_log -1\n",
      "video_encoder.layers.10.mixer.D_b -1\n",
      "video_encoder.layers.10.mixer.in_proj.weight -1\n",
      "video_encoder.layers.10.mixer.conv1d.weight -1\n",
      "video_encoder.layers.10.mixer.conv1d.bias -1\n",
      "video_encoder.layers.10.mixer.x_proj.weight -1\n",
      "video_encoder.layers.10.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.10.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.10.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.10.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.10.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.10.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.10.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.10.mixer.out_proj.weight -1\n",
      "video_encoder.layers.10.norm.weight -1\n",
      "video_encoder.layers.11.mixer.A_log -1\n",
      "video_encoder.layers.11.mixer.D -1\n",
      "video_encoder.layers.11.mixer.A_b_log -1\n",
      "video_encoder.layers.11.mixer.D_b -1\n",
      "video_encoder.layers.11.mixer.in_proj.weight -1\n",
      "video_encoder.layers.11.mixer.conv1d.weight -1\n",
      "video_encoder.layers.11.mixer.conv1d.bias -1\n",
      "video_encoder.layers.11.mixer.x_proj.weight -1\n",
      "video_encoder.layers.11.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.11.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.11.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.11.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.11.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.11.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.11.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.11.mixer.out_proj.weight -1\n",
      "video_encoder.layers.11.norm.weight -1\n",
      "video_encoder.layers.12.mixer.A_log -1\n",
      "video_encoder.layers.12.mixer.D -1\n",
      "video_encoder.layers.12.mixer.A_b_log -1\n",
      "video_encoder.layers.12.mixer.D_b -1\n",
      "video_encoder.layers.12.mixer.in_proj.weight -1\n",
      "video_encoder.layers.12.mixer.conv1d.weight -1\n",
      "video_encoder.layers.12.mixer.conv1d.bias -1\n",
      "video_encoder.layers.12.mixer.x_proj.weight -1\n",
      "video_encoder.layers.12.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.12.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.12.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.12.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.12.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.12.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.12.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.12.mixer.out_proj.weight -1\n",
      "video_encoder.layers.12.norm.weight -1\n",
      "video_encoder.layers.13.mixer.A_log -1\n",
      "video_encoder.layers.13.mixer.D -1\n",
      "video_encoder.layers.13.mixer.A_b_log -1\n",
      "video_encoder.layers.13.mixer.D_b -1\n",
      "video_encoder.layers.13.mixer.in_proj.weight -1\n",
      "video_encoder.layers.13.mixer.conv1d.weight -1\n",
      "video_encoder.layers.13.mixer.conv1d.bias -1\n",
      "video_encoder.layers.13.mixer.x_proj.weight -1\n",
      "video_encoder.layers.13.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.13.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.13.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.13.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.13.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.13.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.13.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.13.mixer.out_proj.weight -1\n",
      "video_encoder.layers.13.norm.weight -1\n",
      "video_encoder.layers.14.mixer.A_log -1\n",
      "video_encoder.layers.14.mixer.D -1\n",
      "video_encoder.layers.14.mixer.A_b_log -1\n",
      "video_encoder.layers.14.mixer.D_b -1\n",
      "video_encoder.layers.14.mixer.in_proj.weight -1\n",
      "video_encoder.layers.14.mixer.conv1d.weight -1\n",
      "video_encoder.layers.14.mixer.conv1d.bias -1\n",
      "video_encoder.layers.14.mixer.x_proj.weight -1\n",
      "video_encoder.layers.14.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.14.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.14.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.14.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.14.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.14.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.14.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.14.mixer.out_proj.weight -1\n",
      "video_encoder.layers.14.norm.weight -1\n",
      "video_encoder.layers.15.mixer.A_log -1\n",
      "video_encoder.layers.15.mixer.D -1\n",
      "video_encoder.layers.15.mixer.A_b_log -1\n",
      "video_encoder.layers.15.mixer.D_b -1\n",
      "video_encoder.layers.15.mixer.in_proj.weight -1\n",
      "video_encoder.layers.15.mixer.conv1d.weight -1\n",
      "video_encoder.layers.15.mixer.conv1d.bias -1\n",
      "video_encoder.layers.15.mixer.x_proj.weight -1\n",
      "video_encoder.layers.15.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.15.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.15.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.15.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.15.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.15.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.15.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.15.mixer.out_proj.weight -1\n",
      "video_encoder.layers.15.norm.weight -1\n",
      "video_encoder.layers.16.mixer.A_log -1\n",
      "video_encoder.layers.16.mixer.D -1\n",
      "video_encoder.layers.16.mixer.A_b_log -1\n",
      "video_encoder.layers.16.mixer.D_b -1\n",
      "video_encoder.layers.16.mixer.in_proj.weight -1\n",
      "video_encoder.layers.16.mixer.conv1d.weight -1\n",
      "video_encoder.layers.16.mixer.conv1d.bias -1\n",
      "video_encoder.layers.16.mixer.x_proj.weight -1\n",
      "video_encoder.layers.16.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.16.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.16.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.16.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.16.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.16.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.16.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.16.mixer.out_proj.weight -1\n",
      "video_encoder.layers.16.norm.weight -1\n",
      "video_encoder.layers.17.mixer.A_log -1\n",
      "video_encoder.layers.17.mixer.D -1\n",
      "video_encoder.layers.17.mixer.A_b_log -1\n",
      "video_encoder.layers.17.mixer.D_b -1\n",
      "video_encoder.layers.17.mixer.in_proj.weight -1\n",
      "video_encoder.layers.17.mixer.conv1d.weight -1\n",
      "video_encoder.layers.17.mixer.conv1d.bias -1\n",
      "video_encoder.layers.17.mixer.x_proj.weight -1\n",
      "video_encoder.layers.17.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.17.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.17.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.17.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.17.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.17.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.17.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.17.mixer.out_proj.weight -1\n",
      "video_encoder.layers.17.norm.weight -1\n",
      "video_encoder.layers.18.mixer.A_log -1\n",
      "video_encoder.layers.18.mixer.D -1\n",
      "video_encoder.layers.18.mixer.A_b_log -1\n",
      "video_encoder.layers.18.mixer.D_b -1\n",
      "video_encoder.layers.18.mixer.in_proj.weight -1\n",
      "video_encoder.layers.18.mixer.conv1d.weight -1\n",
      "video_encoder.layers.18.mixer.conv1d.bias -1\n",
      "video_encoder.layers.18.mixer.x_proj.weight -1\n",
      "video_encoder.layers.18.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.18.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.18.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.18.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.18.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.18.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.18.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.18.mixer.out_proj.weight -1\n",
      "video_encoder.layers.18.norm.weight -1\n",
      "video_encoder.layers.19.mixer.A_log -1\n",
      "video_encoder.layers.19.mixer.D -1\n",
      "video_encoder.layers.19.mixer.A_b_log -1\n",
      "video_encoder.layers.19.mixer.D_b -1\n",
      "video_encoder.layers.19.mixer.in_proj.weight -1\n",
      "video_encoder.layers.19.mixer.conv1d.weight -1\n",
      "video_encoder.layers.19.mixer.conv1d.bias -1\n",
      "video_encoder.layers.19.mixer.x_proj.weight -1\n",
      "video_encoder.layers.19.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.19.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.19.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.19.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.19.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.19.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.19.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.19.mixer.out_proj.weight -1\n",
      "video_encoder.layers.19.norm.weight -1\n",
      "video_encoder.layers.20.mixer.A_log -1\n",
      "video_encoder.layers.20.mixer.D -1\n",
      "video_encoder.layers.20.mixer.A_b_log -1\n",
      "video_encoder.layers.20.mixer.D_b -1\n",
      "video_encoder.layers.20.mixer.in_proj.weight -1\n",
      "video_encoder.layers.20.mixer.conv1d.weight -1\n",
      "video_encoder.layers.20.mixer.conv1d.bias -1\n",
      "video_encoder.layers.20.mixer.x_proj.weight -1\n",
      "video_encoder.layers.20.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.20.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.20.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.20.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.20.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.20.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.20.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.20.mixer.out_proj.weight -1\n",
      "video_encoder.layers.20.norm.weight -1\n",
      "video_encoder.layers.21.mixer.A_log -1\n",
      "video_encoder.layers.21.mixer.D -1\n",
      "video_encoder.layers.21.mixer.A_b_log -1\n",
      "video_encoder.layers.21.mixer.D_b -1\n",
      "video_encoder.layers.21.mixer.in_proj.weight -1\n",
      "video_encoder.layers.21.mixer.conv1d.weight -1\n",
      "video_encoder.layers.21.mixer.conv1d.bias -1\n",
      "video_encoder.layers.21.mixer.x_proj.weight -1\n",
      "video_encoder.layers.21.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.21.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.21.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.21.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.21.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.21.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.21.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.21.mixer.out_proj.weight -1\n",
      "video_encoder.layers.21.norm.weight -1\n",
      "video_encoder.layers.22.mixer.A_log -1\n",
      "video_encoder.layers.22.mixer.D -1\n",
      "video_encoder.layers.22.mixer.A_b_log -1\n",
      "video_encoder.layers.22.mixer.D_b -1\n",
      "video_encoder.layers.22.mixer.in_proj.weight -1\n",
      "video_encoder.layers.22.mixer.conv1d.weight -1\n",
      "video_encoder.layers.22.mixer.conv1d.bias -1\n",
      "video_encoder.layers.22.mixer.x_proj.weight -1\n",
      "video_encoder.layers.22.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.22.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.22.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.22.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.22.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.22.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.22.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.22.mixer.out_proj.weight -1\n",
      "video_encoder.layers.22.norm.weight -1\n",
      "video_encoder.layers.23.mixer.A_log -1\n",
      "video_encoder.layers.23.mixer.D -1\n",
      "video_encoder.layers.23.mixer.A_b_log -1\n",
      "video_encoder.layers.23.mixer.D_b -1\n",
      "video_encoder.layers.23.mixer.in_proj.weight -1\n",
      "video_encoder.layers.23.mixer.conv1d.weight -1\n",
      "video_encoder.layers.23.mixer.conv1d.bias -1\n",
      "video_encoder.layers.23.mixer.x_proj.weight -1\n",
      "video_encoder.layers.23.mixer.dt_proj.weight -1\n",
      "video_encoder.layers.23.mixer.dt_proj.bias -1\n",
      "video_encoder.layers.23.mixer.conv1d_b.weight -1\n",
      "video_encoder.layers.23.mixer.conv1d_b.bias -1\n",
      "video_encoder.layers.23.mixer.x_proj_b.weight -1\n",
      "video_encoder.layers.23.mixer.dt_proj_b.weight -1\n",
      "video_encoder.layers.23.mixer.dt_proj_b.bias -1\n",
      "video_encoder.layers.23.mixer.out_proj.weight -1\n",
      "video_encoder.layers.23.norm.weight -1\n",
      "0\n",
      "0\n",
      "text_encoder.layers.0.mixer.A_log -1\n",
      "text_encoder.layers.0.mixer.D -1\n",
      "text_encoder.layers.0.mixer.A_b_log -1\n",
      "text_encoder.layers.0.mixer.D_b -1\n",
      "text_encoder.layers.0.mixer.in_proj.weight -1\n",
      "text_encoder.layers.0.mixer.conv1d.weight -1\n",
      "text_encoder.layers.0.mixer.conv1d.bias -1\n",
      "text_encoder.layers.0.mixer.x_proj.weight -1\n",
      "text_encoder.layers.0.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.0.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.0.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.0.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.0.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.0.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.0.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.0.mixer.out_proj.weight -1\n",
      "text_encoder.layers.0.norm.weight -1\n",
      "text_encoder.layers.1.mixer.A_log -1\n",
      "text_encoder.layers.1.mixer.D -1\n",
      "text_encoder.layers.1.mixer.A_b_log -1\n",
      "text_encoder.layers.1.mixer.D_b -1\n",
      "text_encoder.layers.1.mixer.in_proj.weight -1\n",
      "text_encoder.layers.1.mixer.conv1d.weight -1\n",
      "text_encoder.layers.1.mixer.conv1d.bias -1\n",
      "text_encoder.layers.1.mixer.x_proj.weight -1\n",
      "text_encoder.layers.1.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.1.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.1.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.1.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.1.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.1.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.1.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.1.mixer.out_proj.weight -1\n",
      "text_encoder.layers.1.norm.weight -1\n",
      "text_encoder.layers.2.mixer.A_log -1\n",
      "text_encoder.layers.2.mixer.D -1\n",
      "text_encoder.layers.2.mixer.A_b_log -1\n",
      "text_encoder.layers.2.mixer.D_b -1\n",
      "text_encoder.layers.2.mixer.in_proj.weight -1\n",
      "text_encoder.layers.2.mixer.conv1d.weight -1\n",
      "text_encoder.layers.2.mixer.conv1d.bias -1\n",
      "text_encoder.layers.2.mixer.x_proj.weight -1\n",
      "text_encoder.layers.2.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.2.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.2.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.2.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.2.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.2.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.2.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.2.mixer.out_proj.weight -1\n",
      "text_encoder.layers.2.norm.weight -1\n",
      "text_encoder.layers.3.mixer.A_log -1\n",
      "text_encoder.layers.3.mixer.D -1\n",
      "text_encoder.layers.3.mixer.A_b_log -1\n",
      "text_encoder.layers.3.mixer.D_b -1\n",
      "text_encoder.layers.3.mixer.in_proj.weight -1\n",
      "text_encoder.layers.3.mixer.conv1d.weight -1\n",
      "text_encoder.layers.3.mixer.conv1d.bias -1\n",
      "text_encoder.layers.3.mixer.x_proj.weight -1\n",
      "text_encoder.layers.3.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.3.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.3.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.3.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.3.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.3.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.3.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.3.mixer.out_proj.weight -1\n",
      "text_encoder.layers.3.norm.weight -1\n",
      "text_encoder.layers.4.mixer.A_log -1\n",
      "text_encoder.layers.4.mixer.D -1\n",
      "text_encoder.layers.4.mixer.A_b_log -1\n",
      "text_encoder.layers.4.mixer.D_b -1\n",
      "text_encoder.layers.4.mixer.in_proj.weight -1\n",
      "text_encoder.layers.4.mixer.conv1d.weight -1\n",
      "text_encoder.layers.4.mixer.conv1d.bias -1\n",
      "text_encoder.layers.4.mixer.x_proj.weight -1\n",
      "text_encoder.layers.4.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.4.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.4.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.4.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.4.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.4.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.4.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.4.mixer.out_proj.weight -1\n",
      "text_encoder.layers.4.norm.weight -1\n",
      "text_encoder.layers.5.mixer.A_log -1\n",
      "text_encoder.layers.5.mixer.D -1\n",
      "text_encoder.layers.5.mixer.A_b_log -1\n",
      "text_encoder.layers.5.mixer.D_b -1\n",
      "text_encoder.layers.5.mixer.in_proj.weight -1\n",
      "text_encoder.layers.5.mixer.conv1d.weight -1\n",
      "text_encoder.layers.5.mixer.conv1d.bias -1\n",
      "text_encoder.layers.5.mixer.x_proj.weight -1\n",
      "text_encoder.layers.5.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.5.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.5.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.5.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.5.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.5.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.5.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.5.mixer.out_proj.weight -1\n",
      "text_encoder.layers.5.norm.weight -1\n",
      "text_encoder.layers.6.mixer.A_log -1\n",
      "text_encoder.layers.6.mixer.D -1\n",
      "text_encoder.layers.6.mixer.A_b_log -1\n",
      "text_encoder.layers.6.mixer.D_b -1\n",
      "text_encoder.layers.6.mixer.in_proj.weight -1\n",
      "text_encoder.layers.6.mixer.conv1d.weight -1\n",
      "text_encoder.layers.6.mixer.conv1d.bias -1\n",
      "text_encoder.layers.6.mixer.x_proj.weight -1\n",
      "text_encoder.layers.6.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.6.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.6.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.6.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.6.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.6.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.6.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.6.mixer.out_proj.weight -1\n",
      "text_encoder.layers.6.norm.weight -1\n",
      "text_encoder.layers.7.mixer.A_log -1\n",
      "text_encoder.layers.7.mixer.D -1\n",
      "text_encoder.layers.7.mixer.A_b_log -1\n",
      "text_encoder.layers.7.mixer.D_b -1\n",
      "text_encoder.layers.7.mixer.in_proj.weight -1\n",
      "text_encoder.layers.7.mixer.conv1d.weight -1\n",
      "text_encoder.layers.7.mixer.conv1d.bias -1\n",
      "text_encoder.layers.7.mixer.x_proj.weight -1\n",
      "text_encoder.layers.7.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.7.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.7.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.7.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.7.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.7.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.7.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.7.mixer.out_proj.weight -1\n",
      "text_encoder.layers.7.norm.weight -1\n",
      "text_encoder.layers.8.mixer.A_log -1\n",
      "text_encoder.layers.8.mixer.D -1\n",
      "text_encoder.layers.8.mixer.A_b_log -1\n",
      "text_encoder.layers.8.mixer.D_b -1\n",
      "text_encoder.layers.8.mixer.in_proj.weight -1\n",
      "text_encoder.layers.8.mixer.conv1d.weight -1\n",
      "text_encoder.layers.8.mixer.conv1d.bias -1\n",
      "text_encoder.layers.8.mixer.x_proj.weight -1\n",
      "text_encoder.layers.8.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.8.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.8.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.8.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.8.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.8.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.8.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.8.mixer.out_proj.weight -1\n",
      "text_encoder.layers.8.norm.weight -1\n",
      "text_encoder.layers.9.mixer.A_log -1\n",
      "text_encoder.layers.9.mixer.D -1\n",
      "text_encoder.layers.9.mixer.A_b_log -1\n",
      "text_encoder.layers.9.mixer.D_b -1\n",
      "text_encoder.layers.9.mixer.in_proj.weight -1\n",
      "text_encoder.layers.9.mixer.conv1d.weight -1\n",
      "text_encoder.layers.9.mixer.conv1d.bias -1\n",
      "text_encoder.layers.9.mixer.x_proj.weight -1\n",
      "text_encoder.layers.9.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.9.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.9.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.9.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.9.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.9.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.9.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.9.mixer.out_proj.weight -1\n",
      "text_encoder.layers.9.norm.weight -1\n",
      "text_encoder.layers.10.mixer.A_log -1\n",
      "text_encoder.layers.10.mixer.D -1\n",
      "text_encoder.layers.10.mixer.A_b_log -1\n",
      "text_encoder.layers.10.mixer.D_b -1\n",
      "text_encoder.layers.10.mixer.in_proj.weight -1\n",
      "text_encoder.layers.10.mixer.conv1d.weight -1\n",
      "text_encoder.layers.10.mixer.conv1d.bias -1\n",
      "text_encoder.layers.10.mixer.x_proj.weight -1\n",
      "text_encoder.layers.10.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.10.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.10.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.10.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.10.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.10.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.10.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.10.mixer.out_proj.weight -1\n",
      "text_encoder.layers.10.norm.weight -1\n",
      "text_encoder.layers.11.mixer.A_log -1\n",
      "text_encoder.layers.11.mixer.D -1\n",
      "text_encoder.layers.11.mixer.A_b_log -1\n",
      "text_encoder.layers.11.mixer.D_b -1\n",
      "text_encoder.layers.11.mixer.in_proj.weight -1\n",
      "text_encoder.layers.11.mixer.conv1d.weight -1\n",
      "text_encoder.layers.11.mixer.conv1d.bias -1\n",
      "text_encoder.layers.11.mixer.x_proj.weight -1\n",
      "text_encoder.layers.11.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.11.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.11.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.11.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.11.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.11.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.11.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.11.mixer.out_proj.weight -1\n",
      "text_encoder.layers.11.norm.weight -1\n",
      "text_encoder.layers.12.mixer.A_log -1\n",
      "text_encoder.layers.12.mixer.D -1\n",
      "text_encoder.layers.12.mixer.A_b_log -1\n",
      "text_encoder.layers.12.mixer.D_b -1\n",
      "text_encoder.layers.12.mixer.in_proj.weight -1\n",
      "text_encoder.layers.12.mixer.conv1d.weight -1\n",
      "text_encoder.layers.12.mixer.conv1d.bias -1\n",
      "text_encoder.layers.12.mixer.x_proj.weight -1\n",
      "text_encoder.layers.12.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.12.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.12.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.12.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.12.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.12.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.12.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.12.mixer.out_proj.weight -1\n",
      "text_encoder.layers.12.norm.weight -1\n",
      "text_encoder.layers.13.mixer.A_log -1\n",
      "text_encoder.layers.13.mixer.D -1\n",
      "text_encoder.layers.13.mixer.A_b_log -1\n",
      "text_encoder.layers.13.mixer.D_b -1\n",
      "text_encoder.layers.13.mixer.in_proj.weight -1\n",
      "text_encoder.layers.13.mixer.conv1d.weight -1\n",
      "text_encoder.layers.13.mixer.conv1d.bias -1\n",
      "text_encoder.layers.13.mixer.x_proj.weight -1\n",
      "text_encoder.layers.13.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.13.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.13.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.13.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.13.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.13.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.13.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.13.mixer.out_proj.weight -1\n",
      "text_encoder.layers.13.norm.weight -1\n",
      "text_encoder.layers.14.mixer.A_log -1\n",
      "text_encoder.layers.14.mixer.D -1\n",
      "text_encoder.layers.14.mixer.A_b_log -1\n",
      "text_encoder.layers.14.mixer.D_b -1\n",
      "text_encoder.layers.14.mixer.in_proj.weight -1\n",
      "text_encoder.layers.14.mixer.conv1d.weight -1\n",
      "text_encoder.layers.14.mixer.conv1d.bias -1\n",
      "text_encoder.layers.14.mixer.x_proj.weight -1\n",
      "text_encoder.layers.14.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.14.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.14.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.14.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.14.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.14.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.14.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.14.mixer.out_proj.weight -1\n",
      "text_encoder.layers.14.norm.weight -1\n",
      "text_encoder.layers.15.mixer.A_log -1\n",
      "text_encoder.layers.15.mixer.D -1\n",
      "text_encoder.layers.15.mixer.A_b_log -1\n",
      "text_encoder.layers.15.mixer.D_b -1\n",
      "text_encoder.layers.15.mixer.in_proj.weight -1\n",
      "text_encoder.layers.15.mixer.conv1d.weight -1\n",
      "text_encoder.layers.15.mixer.conv1d.bias -1\n",
      "text_encoder.layers.15.mixer.x_proj.weight -1\n",
      "text_encoder.layers.15.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.15.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.15.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.15.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.15.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.15.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.15.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.15.mixer.out_proj.weight -1\n",
      "text_encoder.layers.15.norm.weight -1\n",
      "text_encoder.layers.16.mixer.A_log -1\n",
      "text_encoder.layers.16.mixer.D -1\n",
      "text_encoder.layers.16.mixer.A_b_log -1\n",
      "text_encoder.layers.16.mixer.D_b -1\n",
      "text_encoder.layers.16.mixer.in_proj.weight -1\n",
      "text_encoder.layers.16.mixer.conv1d.weight -1\n",
      "text_encoder.layers.16.mixer.conv1d.bias -1\n",
      "text_encoder.layers.16.mixer.x_proj.weight -1\n",
      "text_encoder.layers.16.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.16.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.16.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.16.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.16.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.16.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.16.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.16.mixer.out_proj.weight -1\n",
      "text_encoder.layers.16.norm.weight -1\n",
      "text_encoder.layers.17.mixer.A_log -1\n",
      "text_encoder.layers.17.mixer.D -1\n",
      "text_encoder.layers.17.mixer.A_b_log -1\n",
      "text_encoder.layers.17.mixer.D_b -1\n",
      "text_encoder.layers.17.mixer.in_proj.weight -1\n",
      "text_encoder.layers.17.mixer.conv1d.weight -1\n",
      "text_encoder.layers.17.mixer.conv1d.bias -1\n",
      "text_encoder.layers.17.mixer.x_proj.weight -1\n",
      "text_encoder.layers.17.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.17.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.17.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.17.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.17.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.17.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.17.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.17.mixer.out_proj.weight -1\n",
      "text_encoder.layers.17.norm.weight -1\n",
      "text_encoder.layers.18.mixer.A_log -1\n",
      "text_encoder.layers.18.mixer.D -1\n",
      "text_encoder.layers.18.mixer.A_b_log -1\n",
      "text_encoder.layers.18.mixer.D_b -1\n",
      "text_encoder.layers.18.mixer.in_proj.weight -1\n",
      "text_encoder.layers.18.mixer.conv1d.weight -1\n",
      "text_encoder.layers.18.mixer.conv1d.bias -1\n",
      "text_encoder.layers.18.mixer.x_proj.weight -1\n",
      "text_encoder.layers.18.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.18.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.18.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.18.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.18.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.18.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.18.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.18.mixer.out_proj.weight -1\n",
      "text_encoder.layers.18.norm.weight -1\n",
      "text_encoder.layers.19.mixer.A_log -1\n",
      "text_encoder.layers.19.mixer.D -1\n",
      "text_encoder.layers.19.mixer.A_b_log -1\n",
      "text_encoder.layers.19.mixer.D_b -1\n",
      "text_encoder.layers.19.mixer.in_proj.weight -1\n",
      "text_encoder.layers.19.mixer.conv1d.weight -1\n",
      "text_encoder.layers.19.mixer.conv1d.bias -1\n",
      "text_encoder.layers.19.mixer.x_proj.weight -1\n",
      "text_encoder.layers.19.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.19.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.19.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.19.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.19.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.19.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.19.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.19.mixer.out_proj.weight -1\n",
      "text_encoder.layers.19.norm.weight -1\n",
      "text_encoder.layers.20.mixer.A_log -1\n",
      "text_encoder.layers.20.mixer.D -1\n",
      "text_encoder.layers.20.mixer.A_b_log -1\n",
      "text_encoder.layers.20.mixer.D_b -1\n",
      "text_encoder.layers.20.mixer.in_proj.weight -1\n",
      "text_encoder.layers.20.mixer.conv1d.weight -1\n",
      "text_encoder.layers.20.mixer.conv1d.bias -1\n",
      "text_encoder.layers.20.mixer.x_proj.weight -1\n",
      "text_encoder.layers.20.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.20.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.20.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.20.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.20.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.20.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.20.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.20.mixer.out_proj.weight -1\n",
      "text_encoder.layers.20.norm.weight -1\n",
      "text_encoder.layers.21.mixer.A_log -1\n",
      "text_encoder.layers.21.mixer.D -1\n",
      "text_encoder.layers.21.mixer.A_b_log -1\n",
      "text_encoder.layers.21.mixer.D_b -1\n",
      "text_encoder.layers.21.mixer.in_proj.weight -1\n",
      "text_encoder.layers.21.mixer.conv1d.weight -1\n",
      "text_encoder.layers.21.mixer.conv1d.bias -1\n",
      "text_encoder.layers.21.mixer.x_proj.weight -1\n",
      "text_encoder.layers.21.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.21.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.21.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.21.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.21.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.21.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.21.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.21.mixer.out_proj.weight -1\n",
      "text_encoder.layers.21.norm.weight -1\n",
      "text_encoder.layers.22.mixer.A_log -1\n",
      "text_encoder.layers.22.mixer.D -1\n",
      "text_encoder.layers.22.mixer.A_b_log -1\n",
      "text_encoder.layers.22.mixer.D_b -1\n",
      "text_encoder.layers.22.mixer.in_proj.weight -1\n",
      "text_encoder.layers.22.mixer.conv1d.weight -1\n",
      "text_encoder.layers.22.mixer.conv1d.bias -1\n",
      "text_encoder.layers.22.mixer.x_proj.weight -1\n",
      "text_encoder.layers.22.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.22.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.22.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.22.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.22.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.22.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.22.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.22.mixer.out_proj.weight -1\n",
      "text_encoder.layers.22.norm.weight -1\n",
      "text_encoder.layers.23.mixer.A_log -1\n",
      "text_encoder.layers.23.mixer.D -1\n",
      "text_encoder.layers.23.mixer.A_b_log -1\n",
      "text_encoder.layers.23.mixer.D_b -1\n",
      "text_encoder.layers.23.mixer.in_proj.weight -1\n",
      "text_encoder.layers.23.mixer.conv1d.weight -1\n",
      "text_encoder.layers.23.mixer.conv1d.bias -1\n",
      "text_encoder.layers.23.mixer.x_proj.weight -1\n",
      "text_encoder.layers.23.mixer.dt_proj.weight -1\n",
      "text_encoder.layers.23.mixer.dt_proj.bias -1\n",
      "text_encoder.layers.23.mixer.conv1d_b.weight -1\n",
      "text_encoder.layers.23.mixer.conv1d_b.bias -1\n",
      "text_encoder.layers.23.mixer.x_proj_b.weight -1\n",
      "text_encoder.layers.23.mixer.dt_proj_b.weight -1\n",
      "text_encoder.layers.23.mixer.dt_proj_b.bias -1\n",
      "text_encoder.layers.23.mixer.out_proj.weight -1\n",
      "text_encoder.layers.23.norm.weight -1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for name, val in model.named_parameters():\n",
    "    splited = splited\n",
    "    if splited[1] in (\"cls_token\", \"pos_embed\", \"temporal_pos_embedding\"):\n",
    "        print(0) \n",
    "    elif splited[1] == (\"patch_embed\") or splited[1] == (\"embedding\") or splited[1] == (\"head\") or splited[1] == (\"norm_f\"):\n",
    "        print(0) \n",
    "    elif name.startswith(\"layers\"): # for model\n",
    "        layer_id = int(splited[2])\n",
    "        if 'mixer' in name:\n",
    "            print(layer_id + 1) \n",
    "        else:\n",
    "            print(0) \n",
    "    else:\n",
    "        print(name, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
